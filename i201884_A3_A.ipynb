{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"credit_card_fraud_detection.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1h2kAcLR15FWadjGP_qr1ZeEnn8ZakkNJ\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "credit_card_data = pd.read_csv('creditcard.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(credit_card_data.head())\n",
        "\n",
        "# Display summary statistics of the dataset\n",
        "print(credit_card_data.describe())\n",
        "\n",
        "# Display information about the dataset\n",
        "print(credit_card_data.info())\n",
        "\n",
        "# Check for missing data\n",
        "print(\"Null Values:\", credit_card_data.isnull().sum())\n",
        "\n",
        "# Check for duplicates\n",
        "print(\"Duplicate Values:\", credit_card_data.duplicated().sum())\n",
        "\n",
        "# Drop duplicate and missing values\n",
        "credit_card_data = credit_card_data.drop_duplicates().dropna()\n",
        "\n",
        "# Normalize the data\n",
        "data_normalized = (credit_card_data - credit_card_data.mean()) / credit_card_data.std()\n",
        "\n",
        "# Print the shape of the normalized data\n",
        "print(\"Shape of normalized data:\", data_normalized.shape)\n",
        "\n",
        "# Install PyTorch\n",
        "!pip install torch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class TransformerAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads):\n",
        "        super(TransformerAutoencoder, self).__init__()\n",
        "\n",
        "        assert input_dim % num_heads == 0, \"input_dim must be divisible by num_heads\"\n",
        "\n",
        "        # Transformer encoder and decoder layers\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads)\n",
        "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=input_dim, nhead=num_heads)\n",
        "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
        "        self.linear = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        encoded = self.encoder(x)\n",
        "        # Decoder\n",
        "        decoded = self.decoder(encoded, encoded)  # Using encoded output as memory\n",
        "        # Linear layer\n",
        "        reconstructed = self.linear(decoded)\n",
        "        return reconstructed\n",
        "\n",
        "# Model parameters\n",
        "input_dim = 31\n",
        "hidden_dim = 64\n",
        "num_layers = 2\n",
        "num_heads = 1\n",
        "num_epochs = 5\n",
        "batch_size = 8\n",
        "\n",
        "# Initialize model\n",
        "model = TransformerAutoencoder(input_dim, hidden_dim, num_layers, num_heads)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Data preparation\n",
        "data_normalized_tensor = torch.tensor(data_normalized.values, dtype=torch.float32)\n",
        "data_loader = DataLoader(data_normalized_tensor, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Lists to store results\n",
        "epoch_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    batch_losses = []\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed = model(batch)\n",
        "        loss = criterion(reconstructed, batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_losses.append(loss.item())\n",
        "    epoch_loss = sum(batch_losses) / len(batch_losses)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the training losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epoch_losses, marker='o', linestyle='-')\n",
        "plt.title('Training Loss Per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Optionally save the model\n",
        "torch.save(model.state_dict(), 'transformer_autoencoder.pth')\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, autoencoder_model):\n",
        "        super(Generator, self).__init__()\n",
        "        # Use the saved TransformerAutoencoder model as the generator\n",
        "        self.autoencoder = autoencoder_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Generator generates new data instances\n",
        "        return self.autoencoder(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)  # Adjust input_dim accordingly\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))  # Outputting a single value representing the probability of being real\n",
        "        return x\n",
        "\n",
        "# Model parameters\n",
        "input_dim = 31\n",
        "# Instantiate the Generator\n",
        "generator = Generator(model)\n",
        "\n",
        "# Instantiate the Discriminator\n",
        "discriminator = Discriminator(input_dim)\n",
        "\n",
        "# Loss function and optimizer for the discriminator\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "\n",
        "# Loss function and optimizer for the generator (optional)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "\n",
        "import torch\n",
        "\n",
        "def generate_geometric_mask(batch_size, length, p):\n",
        "    \"\"\"\n",
        "    Generate a mask for a batch of data with a geometric distribution.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): Number of samples in the batch.\n",
        "        length (int): Length of each sample.\n",
        "        p (float): Probability parameter for the geometric distribution.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A boolean tensor mask of shape [batch_size, length].\n",
        "    \"\"\"\n",
        "    mask = torch.rand(batch_size, length) < p\n",
        "    return mask.type(torch.bool)\n",
        "\n",
        "def apply_mask(data, mask):\n",
        "    masked_data = data.clone()\n",
        "    masked_data[mask] = 0  # Masking\n",
        "    return masked_data\n",
        "\n",
        "class AugmentedDataLoader:\n",
        "    def __init__(self, data, batch_size, p):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.p = p  # Probability for the geometric mask\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.data), self.batch_size):\n",
        "            batch = self.data[i:i+self.batch_size]\n",
        "            mask = generate_geometric_mask(batch.shape[1], self.p)\n",
        "            masked_batch = apply_mask(batch, mask)\n",
        "            yield masked_batch\n",
        "\n",
        "    # Compute summary statistics\n",
        "summary_statistics = data_normalized.describe()\n",
        "print(summary_statistics)\n",
        "\n",
        "num_classes = len(data_normalized['Class'].unique())\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "# Define the Transformer Autoencoder class with updated parameter names and comments\n",
        "class TransformerAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads):\n",
        "        super(TransformerAutoencoder, self).__init__()\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=input_dim, nhead=num_heads, batch_first=True)\n",
        "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
        "        self.linear = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded, encoded)\n",
        "        return self.linear(decoded)\n",
        "\n",
        "# Define the ContrastiveLoss class with updated comments and parameter names\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss_contrastive\n",
        "\n",
        "# Instantiate models and optimizers with updated variable names\n",
        "model = TransformerAutoencoder(input_dim=31, hidden_dim=64, num_layers=2, num_heads=1)\n",
        "generator = Generator(model)\n",
        "hidden_size = 128\n",
        "discriminator = Discriminator(input_dim=31)\n",
        "\n",
        "# Adjust the learning rates and optimizers accordingly\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "ae_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop with updated variable names and comments\n",
        "for epoch in range(num_epochs):\n",
        "    for data in data_loader:\n",
        "        batch_size, sequence_length = data.shape\n",
        "        mask = generate_geometric_mask(batch_size, sequence_length, p=0.1)\n",
        "        positive_data = apply_mask(data, mask)\n",
        "        negative_data = torch.roll(data, shifts=1, dims=0)  # Simple shift for negative sample\n",
        "\n",
        "        real_output = discriminator(data)\n",
        "        real_loss = criterion(real_output, torch.ones_like(real_output))\n",
        "        fake_data = generator(data)\n",
        "        fake_output = discriminator(fake_data.detach())\n",
        "        fake_loss = criterion(fake_output, torch.zeros_like(fake_output))\n",
        "        d_loss = real_loss + fake_loss\n",
        "        d_optimizer.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        g_optimizer.zero_grad()\n",
        "        trick_output = discriminator(fake_data)\n",
        "        g_loss = criterion(trick_output, torch.ones_like(trick_output))\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        ae_optimizer.zero_grad()\n",
        "        original_recon = model(data)\n",
        "        positive_recon = model(positive_data)\n",
        "        negative_recon = model(negative_data)\n",
        "        pos_loss = contrastive_loss(original_recon, positive_recon, torch.ones(data.size(0), device=data.device))\n",
        "        neg_loss = contrastive_loss(original_recon, negative_recon, torch.zeros(data.size(0), device=data.device))\n",
        "        ae_loss = pos_loss + neg_loss\n",
        "        ae_loss.backward()\n",
        "        ae_optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}, AE Loss: {ae_loss.item():.4f}')\n",
        "\n",
        "# Function to calculate evaluation metrics\n",
        "def calculate_metrics(predicted, actual, threshold=0.1):\n",
        "    mse = torch.mean((predicted - actual) ** 2)\n",
        "    rmse = torch.sqrt(mse)\n",
        "    mae = torch.mean(torch.abs(predicted - actual))\n",
        "    mse = mse.item()\n",
        "    rmse = rmse.item()\n",
        "    mae = mae.item()\n",
        "    correct_predictions = torch.abs(predicted - actual) <= threshold\n",
        "    accuracy = torch.mean(correct_predictions.float()).item()\n",
        "    return {\"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"Accuracy\": accuracy}\n",
        "\n",
        "# Evaluation loop\n",
        "for epoch in range(num_epochs):\n",
        "    predicted_all = []\n",
        "    actual_all = []\n",
        "    for data in data_loader:\n",
        "        with torch.no_grad():\n",
        "            predicted = model(data)\n",
        "            actual = data\n",
        "            predicted_all.append(predicted)\n",
        "            actual_all.append(actual)\n",
        "\n",
        "    predicted_tensor = torch.cat(predicted_all, 0)\n",
        "    actual_tensor = torch.cat(actual_all, 0)\n",
        "\n",
        "    metrics = calculate_metrics(predicted_tensor, actual_tensor)\n",
        "    print(f\"Epoch {epoch+1} Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "duLQMNqfXmZR",
        "outputId": "28d1a2ac-ba1d-4e84-cd7f-475d0d489ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
            "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
            "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
            "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "                Time             V1             V2             V3  \\\n",
            "count  114962.000000  114962.000000  114962.000000  114962.000000   \n",
            "mean    46081.803161      -0.254307      -0.014474       0.680756   \n",
            "std     18497.491852       1.840512       1.635453       1.299923   \n",
            "min         0.000000     -56.407510     -72.715728     -33.680984   \n",
            "25%     35135.000000      -1.021267      -0.588758       0.175474   \n",
            "50%     47926.000000      -0.262408       0.085671       0.755424   \n",
            "75%     61141.750000       1.155544       0.750077       1.377493   \n",
            "max     73691.000000       1.960497      18.902453       4.226108   \n",
            "\n",
            "                  V4             V5             V6             V7  \\\n",
            "count  114962.000000  114962.000000  114962.000000  114962.000000   \n",
            "mean        0.155588      -0.283222       0.093060      -0.115141   \n",
            "std         1.337298       1.336326       1.295536       1.195872   \n",
            "min        -5.172595     -42.147898     -26.160506     -31.764946   \n",
            "25%        -0.706585      -0.904592      -0.650548      -0.603510   \n",
            "50%         0.183498      -0.316178      -0.160504      -0.067892   \n",
            "75%         1.016309       0.243646       0.484423       0.411121   \n",
            "max        16.715537      34.801666      22.529298      36.677268   \n",
            "\n",
            "                  V8             V9  ...            V21            V22  \\\n",
            "count  114962.000000  114962.000000  ...  114961.000000  114961.000000   \n",
            "mean        0.059054      -0.069232  ...      -0.033882      -0.110877   \n",
            "std         1.228304       1.100380  ...       0.736144       0.638775   \n",
            "min       -73.216718      -9.283925  ...     -34.830382     -10.933144   \n",
            "25%        -0.133980      -0.702130  ...      -0.225051      -0.539090   \n",
            "50%         0.077774      -0.134436  ...      -0.057871      -0.088085   \n",
            "75%         0.369380       0.517444  ...       0.118275       0.309164   \n",
            "max        20.007208      10.392889  ...      27.202839      10.503090   \n",
            "\n",
            "                 V23            V24            V25            V26  \\\n",
            "count  114961.000000  114961.000000  114961.000000  114961.000000   \n",
            "mean       -0.036393       0.011090       0.132304       0.026724   \n",
            "std         0.615475       0.595142       0.438953       0.490939   \n",
            "min       -44.807735      -2.836627     -10.295397      -2.534330   \n",
            "25%        -0.175476      -0.324119      -0.131773      -0.323044   \n",
            "50%        -0.048507       0.067072       0.169540      -0.065767   \n",
            "75%         0.081435       0.408176       0.420138       0.293114   \n",
            "max        19.002942       4.016342       5.541598       3.517346   \n",
            "\n",
            "                 V27            V28         Amount          Class  \n",
            "count  114961.000000  114961.000000  114961.000000  114961.000000  \n",
            "mean        0.001019       0.002058      94.910872       0.002105  \n",
            "std         0.390720       0.317051     257.019966       0.045833  \n",
            "min        -9.390980      -9.617915       0.000000       0.000000  \n",
            "25%        -0.060932      -0.004723       6.950000       0.000000  \n",
            "50%         0.010666       0.023424      25.000000       0.000000  \n",
            "75%         0.084748       0.077098      85.440000       0.000000  \n",
            "max        12.152401      33.847808   19656.530000       1.000000  \n",
            "\n",
            "[8 rows x 31 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 114962 entries, 0 to 114961\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    114962 non-null  int64  \n",
            " 1   V1      114962 non-null  float64\n",
            " 2   V2      114962 non-null  float64\n",
            " 3   V3      114962 non-null  float64\n",
            " 4   V4      114962 non-null  float64\n",
            " 5   V5      114962 non-null  float64\n",
            " 6   V6      114962 non-null  float64\n",
            " 7   V7      114962 non-null  float64\n",
            " 8   V8      114962 non-null  float64\n",
            " 9   V9      114962 non-null  float64\n",
            " 10  V10     114962 non-null  float64\n",
            " 11  V11     114962 non-null  float64\n",
            " 12  V12     114961 non-null  float64\n",
            " 13  V13     114961 non-null  float64\n",
            " 14  V14     114961 non-null  float64\n",
            " 15  V15     114961 non-null  float64\n",
            " 16  V16     114961 non-null  float64\n",
            " 17  V17     114961 non-null  float64\n",
            " 18  V18     114961 non-null  float64\n",
            " 19  V19     114961 non-null  float64\n",
            " 20  V20     114961 non-null  float64\n",
            " 21  V21     114961 non-null  float64\n",
            " 22  V22     114961 non-null  float64\n",
            " 23  V23     114961 non-null  float64\n",
            " 24  V24     114961 non-null  float64\n",
            " 25  V25     114961 non-null  float64\n",
            " 26  V26     114961 non-null  float64\n",
            " 27  V27     114961 non-null  float64\n",
            " 28  V28     114961 non-null  float64\n",
            " 29  Amount  114961 non-null  float64\n",
            " 30  Class   114961 non-null  float64\n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 27.2 MB\n",
            "None\n",
            "Null Values: Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       1\n",
            "V13       1\n",
            "V14       1\n",
            "V15       1\n",
            "V16       1\n",
            "V17       1\n",
            "V18       1\n",
            "V19       1\n",
            "V20       1\n",
            "V21       1\n",
            "V22       1\n",
            "V23       1\n",
            "V24       1\n",
            "V25       1\n",
            "V26       1\n",
            "V27       1\n",
            "V28       1\n",
            "Amount    1\n",
            "Class     1\n",
            "dtype: int64\n",
            "Duplicate Values: 457\n",
            "Shape of normalized data: (114504, 31)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Average Loss: 0.2671\n",
            "Epoch [2/5], Average Loss: 0.1726\n",
            "Epoch [3/5], Average Loss: 0.1490\n",
            "Epoch [4/5], Average Loss: 0.1444\n",
            "Epoch [5/5], Average Loss: 0.1394\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Time            V1            V2            V3            V4  \\\n",
            "count  1.145040e+05  1.145040e+05  1.145040e+05  1.145040e+05  1.145040e+05   \n",
            "mean   4.765745e-17 -2.233943e-18 -2.085013e-17 -1.141793e-17  1.241079e-17   \n",
            "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
            "min   -2.491788e+00 -3.072147e+01 -4.462365e+01 -2.651423e+01 -3.984645e+00   \n",
            "25%   -5.917779e-01 -4.208138e-01 -3.511042e-01 -3.906758e-01 -6.441980e-01   \n",
            "50%    9.995953e-02 -6.615545e-03  6.321511e-02  5.666368e-02  2.082286e-02   \n",
            "75%    8.136513e-01  7.678133e-01  4.694344e-01  5.363882e-01  6.436911e-01   \n",
            "max    1.492978e+00  1.207980e+00  1.161447e+01  2.734584e+00  1.239145e+01   \n",
            "\n",
            "                 V5            V6            V7            V8            V9  \\\n",
            "count  1.145040e+05  1.145040e+05  1.145040e+05  1.145040e+05  1.145040e+05   \n",
            "mean  -1.216258e-17 -1.390009e-17  1.042507e-17  2.482159e-18  3.971454e-18   \n",
            "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
            "min   -3.134769e+01 -2.026000e+01 -2.662736e+01 -6.111847e+01 -8.410060e+00   \n",
            "25%   -4.657651e-01 -5.735546e-01 -4.107791e-01 -1.615960e-01 -5.765429e-01   \n",
            "50%   -2.551114e-02 -1.957247e-01  3.898062e-02  1.459397e-02 -5.798180e-02   \n",
            "75%    3.941093e-01  3.014375e-01  4.421135e-01  2.570015e-01  5.372197e-01   \n",
            "max    2.626837e+01  1.731594e+01  3.095122e+01  1.663781e+01  9.555054e+00   \n",
            "\n",
            "       ...           V21           V22           V23           V24  \\\n",
            "count  ...  1.145040e+05  1.145040e+05  1.145040e+05  1.145040e+05   \n",
            "mean   ... -2.978590e-18  1.985727e-18  1.538938e-17 -2.308408e-17   \n",
            "std    ...  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
            "min    ... -4.892137e+01 -1.700862e+01 -7.306588e+01 -4.784891e+00   \n",
            "25%    ... -2.669661e-01 -6.742777e-01 -2.270428e-01 -5.635510e-01   \n",
            "50%    ... -3.202474e-02  3.520224e-02 -1.999098e-02  9.391419e-02   \n",
            "75%    ...  2.156802e-01  6.595402e-01  1.920900e-01  6.670518e-01   \n",
            "max    ...  3.829572e+01  1.667946e+01  3.107150e+01  6.729822e+00   \n",
            "\n",
            "                V25           V26           V27           V28        Amount  \\\n",
            "count  1.145040e+05  1.145040e+05  1.145040e+05  1.145040e+05  1.145040e+05   \n",
            "mean   4.964317e-18 -9.680419e-18 -3.226806e-18  6.205397e-18 -7.942908e-18   \n",
            "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
            "min   -2.374756e+01 -5.215321e+00 -2.462178e+01 -3.077237e+01 -3.692718e-01   \n",
            "25%   -6.022998e-01 -7.121461e-01 -1.665259e-01 -2.365614e-02 -3.422303e-01   \n",
            "50%    8.520116e-02 -1.884019e-01  2.036392e-02  6.616942e-02 -2.721398e-01   \n",
            "75%    6.561080e-01  5.417421e-01  2.145220e-01  2.375589e-01 -3.610886e-02   \n",
            "max    1.231948e+01  7.106685e+00  3.184395e+01  1.082557e+02  7.600190e+01   \n",
            "\n",
            "              Class  \n",
            "count  1.145040e+05  \n",
            "mean  -1.836797e-17  \n",
            "std    1.000000e+00  \n",
            "min   -4.554198e-02  \n",
            "25%   -4.554198e-02  \n",
            "50%   -4.554198e-02  \n",
            "75%   -4.554198e-02  \n",
            "max    2.195757e+01  \n",
            "\n",
            "[8 rows x 31 columns]\n",
            "Number of classes: 2\n",
            "Epoch 1, D Loss: 1.3763, G Loss: 0.7077, AE Loss: 12.0439\n",
            "Epoch 1, D Loss: 1.4366, G Loss: 0.6469, AE Loss: 1.9095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 2, D Loss: 0.8938, G Loss: 2.0753, AE Loss: 0.6034\n",
            "Epoch 2, D Loss: 0.6798, G Loss: 2.2242, AE Loss: 0.6264\n",
            "Epoch 2, D Loss: 0.4974, G Loss: 2.2459, AE Loss: 0.5872\n",
            "Epoch 2, D Loss: 0.5886, G Loss: 2.0779, AE Loss: 0.5410\n",
            "Epoch 2, D Loss: 0.5231, G Loss: 2.0474, AE Loss: 0.5375\n",
            "Epoch 2, D Loss: 0.6622, G Loss: 2.1145, AE Loss: 0.8248\n",
            "Epoch 2, D Loss: 0.2973, G Loss: 1.9733, AE Loss: 0.7187\n",
            "Epoch 2, D Loss: 0.2246, G Loss: 2.2023, AE Loss: 0.5310\n",
            "Epoch 2, D Loss: 0.3062, G Loss: 2.0380, AE Loss: 0.4800\n",
            "Epoch 2, D Loss: 0.3209, G Loss: 2.2845, AE Loss: 0.6134\n",
            "Epoch 2, D Loss: 0.4429, G Loss: 2.1401, AE Loss: 0.5455\n",
            "Epoch 2, D Loss: 0.4092, G Loss: 2.0639, AE Loss: 0.5511\n",
            "Epoch 2, D Loss: 0.5416, G Loss: 2.1268, AE Loss: 0.6325\n",
            "Epoch 2, D Loss: 0.4964, G Loss: 2.2218, AE Loss: 0.7185\n",
            "Epoch 2, D Loss: 1.0858, G Loss: 2.0406, AE Loss: 0.5466\n",
            "Epoch 2, D Loss: 0.1954, G Loss: 2.3381, AE Loss: 0.4922\n",
            "Epoch 2, D Loss: 0.4385, G Loss: 1.8780, AE Loss: 0.5575\n",
            "Epoch 2, D Loss: 1.0099, G Loss: 1.9557, AE Loss: 0.5579\n",
            "Epoch 2, D Loss: 0.2749, G Loss: 2.4171, AE Loss: 0.5159\n",
            "Epoch 2, D Loss: 0.7382, G Loss: 2.3331, AE Loss: 0.5278\n",
            "Epoch 2, D Loss: 0.5962, G Loss: 2.0491, AE Loss: 0.5589\n",
            "Epoch 2, D Loss: 0.2764, G Loss: 2.0810, AE Loss: 0.6081\n",
            "Epoch 2, D Loss: 0.6251, G Loss: 2.0231, AE Loss: 0.4947\n",
            "Epoch 2, D Loss: 0.3273, G Loss: 1.9992, AE Loss: 0.5742\n",
            "Epoch 2, D Loss: 0.5147, G Loss: 1.9388, AE Loss: 0.5893\n",
            "Epoch 2, D Loss: 0.6529, G Loss: 1.8215, AE Loss: 0.5621\n",
            "Epoch 2, D Loss: 0.7483, G Loss: 2.1492, AE Loss: 0.5443\n",
            "Epoch 2, D Loss: 0.5986, G Loss: 2.1127, AE Loss: 0.4446\n",
            "Epoch 2, D Loss: 0.3827, G Loss: 1.7790, AE Loss: 0.5332\n",
            "Epoch 2, D Loss: 0.5503, G Loss: 1.9479, AE Loss: 0.6574\n",
            "Epoch 2, D Loss: 0.2589, G Loss: 1.9789, AE Loss: 0.6166\n",
            "Epoch 2, D Loss: 0.4684, G Loss: 1.9116, AE Loss: 0.5943\n",
            "Epoch 2, D Loss: 0.3346, G Loss: 1.9559, AE Loss: 0.5425\n",
            "Epoch 2, D Loss: 0.5858, G Loss: 1.9280, AE Loss: 0.5999\n",
            "Epoch 2, D Loss: 0.2092, G Loss: 2.0600, AE Loss: 0.6253\n",
            "Epoch 2, D Loss: 0.4553, G Loss: 2.0614, AE Loss: 0.5152\n",
            "Epoch 2, D Loss: 0.6416, G Loss: 2.0954, AE Loss: 0.5489\n",
            "Epoch 2, D Loss: 0.4363, G Loss: 2.0547, AE Loss: 0.6263\n",
            "Epoch 2, D Loss: 0.4057, G Loss: 2.0155, AE Loss: 0.7178\n",
            "Epoch 2, D Loss: 0.4843, G Loss: 1.8665, AE Loss: 0.5536\n",
            "Epoch 2, D Loss: 0.3796, G Loss: 2.0088, AE Loss: 0.4967\n",
            "Epoch 2, D Loss: 1.5462, G Loss: 1.8632, AE Loss: 0.5714\n",
            "Epoch 2, D Loss: 0.2183, G Loss: 2.1167, AE Loss: 0.4670\n",
            "Epoch 2, D Loss: 0.3890, G Loss: 1.8495, AE Loss: 0.5276\n",
            "Epoch 2, D Loss: 0.5710, G Loss: 2.0306, AE Loss: 0.4516\n",
            "Epoch 2, D Loss: 0.7676, G Loss: 1.9312, AE Loss: 0.5517\n",
            "Epoch 2, D Loss: 0.7423, G Loss: 1.7092, AE Loss: 0.5281\n",
            "Epoch 2, D Loss: 0.5231, G Loss: 1.7652, AE Loss: 0.7580\n",
            "Epoch 2, D Loss: 0.6479, G Loss: 1.7588, AE Loss: 0.4652\n",
            "Epoch 2, D Loss: 0.3343, G Loss: 1.8485, AE Loss: 0.6637\n",
            "Epoch 2, D Loss: 0.3963, G Loss: 1.9050, AE Loss: 0.4767\n",
            "Epoch 2, D Loss: 0.6175, G Loss: 1.8815, AE Loss: 0.4684\n",
            "Epoch 2, D Loss: 1.3706, G Loss: 1.5328, AE Loss: 0.7667\n",
            "Epoch 2, D Loss: 0.6195, G Loss: 1.7839, AE Loss: 0.5124\n",
            "Epoch 2, D Loss: 0.4399, G Loss: 1.7999, AE Loss: 0.4501\n",
            "Epoch 2, D Loss: 0.2634, G Loss: 1.8899, AE Loss: 0.6122\n",
            "Epoch 2, D Loss: 0.7473, G Loss: 2.1080, AE Loss: 0.5043\n",
            "Epoch 2, D Loss: 0.6066, G Loss: 1.9600, AE Loss: 0.5594\n",
            "Epoch 2, D Loss: 0.5696, G Loss: 1.9282, AE Loss: 0.5048\n",
            "Epoch 2, D Loss: 0.5137, G Loss: 1.9115, AE Loss: 0.5656\n",
            "Epoch 2, D Loss: 0.5359, G Loss: 1.6865, AE Loss: 0.7031\n",
            "Epoch 2, D Loss: 0.5607, G Loss: 1.8524, AE Loss: 0.5807\n",
            "Epoch 2, D Loss: 0.3416, G Loss: 1.9125, AE Loss: 0.4136\n",
            "Epoch 2, D Loss: 0.3269, G Loss: 1.8174, AE Loss: 0.6507\n",
            "Epoch 2, D Loss: 1.1764, G Loss: 1.5917, AE Loss: 0.6674\n",
            "Epoch 2, D Loss: 0.4844, G Loss: 1.8193, AE Loss: 0.6409\n",
            "Epoch 2, D Loss: 0.5571, G Loss: 1.9981, AE Loss: 0.5689\n",
            "Epoch 2, D Loss: 0.6693, G Loss: 1.6901, AE Loss: 0.5340\n",
            "Epoch 2, D Loss: 0.8572, G Loss: 1.8372, AE Loss: 0.5528\n",
            "Epoch 2, D Loss: 0.4916, G Loss: 1.5705, AE Loss: 0.5810\n",
            "Epoch 2, D Loss: 0.6858, G Loss: 1.5859, AE Loss: 0.6872\n",
            "Epoch 2, D Loss: 0.4487, G Loss: 1.8254, AE Loss: 0.6378\n",
            "Epoch 2, D Loss: 0.5052, G Loss: 1.6149, AE Loss: 0.4719\n",
            "Epoch 2, D Loss: 0.6779, G Loss: 1.6974, AE Loss: 0.6143\n",
            "Epoch 2, D Loss: 0.5672, G Loss: 1.5719, AE Loss: 0.5821\n",
            "Epoch 2, D Loss: 0.4027, G Loss: 1.5477, AE Loss: 0.5567\n",
            "Epoch 2, D Loss: 0.5449, G Loss: 1.5479, AE Loss: 0.5780\n",
            "Epoch 2, D Loss: 0.7465, G Loss: 1.6131, AE Loss: 0.5552\n",
            "Epoch 2, D Loss: 0.5795, G Loss: 1.5849, AE Loss: 0.5845\n",
            "Epoch 2, D Loss: 0.3181, G Loss: 1.7011, AE Loss: 0.4849\n",
            "Epoch 2, D Loss: 0.4736, G Loss: 1.8255, AE Loss: 0.5548\n",
            "Epoch 2, D Loss: 0.5661, G Loss: 1.7700, AE Loss: 0.5445\n",
            "Epoch 2, D Loss: 0.4208, G Loss: 1.7960, AE Loss: 0.4542\n",
            "Epoch 2, D Loss: 0.4561, G Loss: 1.6799, AE Loss: 0.4599\n",
            "Epoch 2, D Loss: 0.7572, G Loss: 1.7761, AE Loss: 0.5275\n",
            "Epoch 2, D Loss: 0.8192, G Loss: 2.0734, AE Loss: 0.6047\n",
            "Epoch 2, D Loss: 0.8147, G Loss: 1.5164, AE Loss: 0.5647\n",
            "Epoch 2, D Loss: 1.0770, G Loss: 1.8009, AE Loss: 0.5616\n",
            "Epoch 2, D Loss: 0.6754, G Loss: 1.9974, AE Loss: 0.6117\n",
            "Epoch 2, D Loss: 0.9689, G Loss: 1.8487, AE Loss: 0.4878\n",
            "Epoch 2, D Loss: 0.6679, G Loss: 1.5963, AE Loss: 0.6928\n",
            "Epoch 2, D Loss: 0.9161, G Loss: 1.7385, AE Loss: 0.5742\n",
            "Epoch 2, D Loss: 0.6427, G Loss: 1.8026, AE Loss: 0.4987\n",
            "Epoch 2, D Loss: 0.5381, G Loss: 1.5345, AE Loss: 0.6175\n",
            "Epoch 2, D Loss: 0.7589, G Loss: 1.6467, AE Loss: 0.4874\n",
            "Epoch 2, D Loss: 1.3689, G Loss: 1.5653, AE Loss: 0.5825\n",
            "Epoch 2, D Loss: 0.7315, G Loss: 1.7001, AE Loss: 0.4867\n",
            "Epoch 2, D Loss: 0.9814, G Loss: 1.3517, AE Loss: 0.5404\n",
            "Epoch 2, D Loss: 1.3355, G Loss: 1.3898, AE Loss: 0.5484\n",
            "Epoch 2, D Loss: 0.9533, G Loss: 1.3061, AE Loss: 0.5836\n",
            "Epoch 2, D Loss: 0.4885, G Loss: 1.3653, AE Loss: 0.5659\n",
            "Epoch 2, D Loss: 0.7755, G Loss: 1.2718, AE Loss: 0.6584\n",
            "Epoch 2, D Loss: 0.3587, G Loss: 1.4011, AE Loss: 0.5163\n",
            "Epoch 2, D Loss: 0.5467, G Loss: 1.1316, AE Loss: 0.6013\n",
            "Epoch 2, D Loss: 0.8335, G Loss: 1.3077, AE Loss: 0.6113\n",
            "Epoch 2, D Loss: 0.6713, G Loss: 1.1518, AE Loss: 0.5416\n",
            "Epoch 2, D Loss: 0.3695, G Loss: 1.4310, AE Loss: 0.7302\n",
            "Epoch 2, D Loss: 1.0967, G Loss: 1.2072, AE Loss: 0.6797\n",
            "Epoch 2, D Loss: 0.5856, G Loss: 1.3565, AE Loss: 0.4359\n",
            "Epoch 2, D Loss: 0.7855, G Loss: 1.3861, AE Loss: 0.5644\n",
            "Epoch 2, D Loss: 0.7879, G Loss: 1.2657, AE Loss: 0.5893\n",
            "Epoch 2, D Loss: 1.0844, G Loss: 1.6028, AE Loss: 0.4253\n",
            "Epoch 2, D Loss: 0.8469, G Loss: 1.5942, AE Loss: 0.5505\n",
            "Epoch 2, D Loss: 0.8081, G Loss: 1.5465, AE Loss: 0.5044\n",
            "Epoch 2, D Loss: 0.7735, G Loss: 1.2950, AE Loss: 0.4483\n",
            "Epoch 2, D Loss: 0.7352, G Loss: 1.2950, AE Loss: 0.5224\n",
            "Epoch 2, D Loss: 0.4089, G Loss: 1.3670, AE Loss: 0.4094\n",
            "Epoch 2, D Loss: 1.2169, G Loss: 1.3895, AE Loss: 0.5386\n",
            "Epoch 2, D Loss: 1.1944, G Loss: 1.3648, AE Loss: 0.6169\n",
            "Epoch 2, D Loss: 0.9892, G Loss: 1.0995, AE Loss: 0.5415\n",
            "Epoch 2, D Loss: 1.4210, G Loss: 1.2079, AE Loss: 0.5925\n",
            "Epoch 2, D Loss: 0.8395, G Loss: 1.1105, AE Loss: 0.5224\n",
            "Epoch 2, D Loss: 0.8494, G Loss: 1.2822, AE Loss: 0.6083\n",
            "Epoch 2, D Loss: 1.2419, G Loss: 1.3080, AE Loss: 0.5854\n",
            "Epoch 2, D Loss: 0.6507, G Loss: 1.1913, AE Loss: 0.5438\n",
            "Epoch 2, D Loss: 0.9263, G Loss: 1.0274, AE Loss: 0.5652\n",
            "Epoch 2, D Loss: 1.2297, G Loss: 1.0510, AE Loss: 0.4647\n",
            "Epoch 2, D Loss: 0.5050, G Loss: 1.1318, AE Loss: 0.5600\n",
            "Epoch 2, D Loss: 0.8833, G Loss: 1.3421, AE Loss: 0.6048\n",
            "Epoch 2, D Loss: 0.7860, G Loss: 1.0297, AE Loss: 0.4298\n",
            "Epoch 2, D Loss: 0.7163, G Loss: 1.1216, AE Loss: 0.4633\n",
            "Epoch 2, D Loss: 0.6782, G Loss: 1.0118, AE Loss: 0.7117\n",
            "Epoch 2, D Loss: 0.8134, G Loss: 1.1982, AE Loss: 0.4911\n",
            "Epoch 2, D Loss: 0.6107, G Loss: 1.0719, AE Loss: 0.4465\n",
            "Epoch 2, D Loss: 0.5129, G Loss: 1.2317, AE Loss: 0.7049\n",
            "Epoch 2, D Loss: 0.5538, G Loss: 1.2181, AE Loss: 0.6313\n",
            "Epoch 2, D Loss: 0.8371, G Loss: 0.9449, AE Loss: 0.6335\n",
            "Epoch 2, D Loss: 0.6318, G Loss: 1.2728, AE Loss: 0.6013\n",
            "Epoch 2, D Loss: 0.5863, G Loss: 1.1888, AE Loss: 0.5977\n",
            "Epoch 2, D Loss: 1.2718, G Loss: 1.3651, AE Loss: 0.5404\n",
            "Epoch 2, D Loss: 0.7460, G Loss: 1.5055, AE Loss: 0.6631\n",
            "Epoch 2, D Loss: 1.1303, G Loss: 1.2825, AE Loss: 0.5290\n",
            "Epoch 2, D Loss: 0.8311, G Loss: 1.4191, AE Loss: 0.5098\n",
            "Epoch 2, D Loss: 2.0313, G Loss: 1.3332, AE Loss: 0.5586\n",
            "Epoch 2, D Loss: 0.7332, G Loss: 1.6488, AE Loss: 0.6296\n",
            "Epoch 2, D Loss: 0.4670, G Loss: 1.4759, AE Loss: 0.5310\n",
            "Epoch 2, D Loss: 0.9655, G Loss: 1.4275, AE Loss: 0.4732\n",
            "Epoch 2, D Loss: 1.4503, G Loss: 1.5828, AE Loss: 0.6496\n",
            "Epoch 2, D Loss: 0.7424, G Loss: 1.5742, AE Loss: 0.5447\n",
            "Epoch 2, D Loss: 1.1201, G Loss: 1.6966, AE Loss: 0.5650\n",
            "Epoch 2, D Loss: 0.3383, G Loss: 1.5404, AE Loss: 0.4429\n",
            "Epoch 2, D Loss: 1.0840, G Loss: 1.3583, AE Loss: 0.4564\n",
            "Epoch 2, D Loss: 1.3599, G Loss: 1.4915, AE Loss: 0.5900\n",
            "Epoch 2, D Loss: 0.3845, G Loss: 1.5556, AE Loss: 0.2702\n",
            "Epoch 2, D Loss: 0.6211, G Loss: 1.5952, AE Loss: 0.4114\n",
            "Epoch 2, D Loss: 0.9371, G Loss: 2.4428, AE Loss: 0.6446\n",
            "Epoch 2, D Loss: 1.0649, G Loss: 1.5134, AE Loss: 0.4593\n",
            "Epoch 2, D Loss: 1.1448, G Loss: 1.4110, AE Loss: 0.5501\n",
            "Epoch 2, D Loss: 0.4617, G Loss: 1.2858, AE Loss: 0.5831\n",
            "Epoch 2, D Loss: 1.1799, G Loss: 1.1849, AE Loss: 0.4306\n",
            "Epoch 2, D Loss: 1.1043, G Loss: 1.1632, AE Loss: 0.5176\n",
            "Epoch 2, D Loss: 0.8176, G Loss: 1.2507, AE Loss: 0.5598\n",
            "Epoch 2, D Loss: 1.2139, G Loss: 1.2501, AE Loss: 0.5689\n",
            "Epoch 2, D Loss: 0.4963, G Loss: 1.2495, AE Loss: 0.5060\n",
            "Epoch 2, D Loss: 1.5944, G Loss: 1.2291, AE Loss: 0.6351\n",
            "Epoch 2, D Loss: 1.3560, G Loss: 1.0295, AE Loss: 0.5966\n",
            "Epoch 2, D Loss: 1.3657, G Loss: 1.1199, AE Loss: 0.5965\n",
            "Epoch 2, D Loss: 0.6827, G Loss: 1.1336, AE Loss: 0.7073\n",
            "Epoch 2, D Loss: 2.4898, G Loss: 1.0419, AE Loss: 0.6851\n",
            "Epoch 2, D Loss: 0.6537, G Loss: 1.0906, AE Loss: 0.7014\n",
            "Epoch 2, D Loss: 1.4562, G Loss: 1.0255, AE Loss: 0.5039\n",
            "Epoch 2, D Loss: 0.5928, G Loss: 1.1150, AE Loss: 0.4708\n",
            "Epoch 2, D Loss: 0.7743, G Loss: 1.0096, AE Loss: 0.5273\n",
            "Epoch 2, D Loss: 0.7113, G Loss: 1.0949, AE Loss: 0.6720\n",
            "Epoch 2, D Loss: 1.7656, G Loss: 1.1829, AE Loss: 0.5924\n",
            "Epoch 2, D Loss: 1.0429, G Loss: 1.1137, AE Loss: 0.5056\n",
            "Epoch 2, D Loss: 1.2078, G Loss: 0.9554, AE Loss: 0.6275\n",
            "Epoch 2, D Loss: 1.0127, G Loss: 1.1164, AE Loss: 0.6965\n",
            "Epoch 2, D Loss: 1.3433, G Loss: 1.1352, AE Loss: 0.6228\n",
            "Epoch 2, D Loss: 0.5019, G Loss: 1.0804, AE Loss: 0.6694\n",
            "Epoch 2, D Loss: 0.6570, G Loss: 1.0765, AE Loss: 0.5602\n",
            "Epoch 2, D Loss: 1.0589, G Loss: 1.1131, AE Loss: 0.6214\n",
            "Epoch 2, D Loss: 0.6929, G Loss: 1.1565, AE Loss: 0.6224\n",
            "Epoch 2, D Loss: 1.3115, G Loss: 1.1873, AE Loss: 0.4897\n",
            "Epoch 2, D Loss: 1.0192, G Loss: 1.1624, AE Loss: 0.5317\n",
            "Epoch 2, D Loss: 0.4786, G Loss: 1.1884, AE Loss: 0.6432\n",
            "Epoch 2, D Loss: 1.0458, G Loss: 2.2179, AE Loss: 0.3623\n",
            "Epoch 2, D Loss: 0.8661, G Loss: 1.4297, AE Loss: 0.5067\n",
            "Epoch 2, D Loss: 1.1444, G Loss: 1.3429, AE Loss: 0.5225\n",
            "Epoch 2, D Loss: 1.0690, G Loss: 1.4341, AE Loss: 0.6422\n",
            "Epoch 2, D Loss: 1.6618, G Loss: 1.1835, AE Loss: 0.5633\n",
            "Epoch 2, D Loss: 0.5588, G Loss: 1.2875, AE Loss: 0.4916\n",
            "Epoch 2, D Loss: 0.7124, G Loss: 1.0385, AE Loss: 0.5713\n",
            "Epoch 2, D Loss: 1.1949, G Loss: 1.2932, AE Loss: 0.5596\n",
            "Epoch 2, D Loss: 0.9305, G Loss: 1.2110, AE Loss: 0.4490\n",
            "Epoch 2, D Loss: 0.9116, G Loss: 1.2376, AE Loss: 0.6564\n",
            "Epoch 2, D Loss: 0.6898, G Loss: 1.4153, AE Loss: 0.4546\n",
            "Epoch 2, D Loss: 0.6369, G Loss: 1.1952, AE Loss: 0.6049\n",
            "Epoch 2, D Loss: 0.4234, G Loss: 1.3276, AE Loss: 0.6415\n",
            "Epoch 2, D Loss: 1.1245, G Loss: 1.9981, AE Loss: 0.5205\n",
            "Epoch 2, D Loss: 0.7608, G Loss: 1.2448, AE Loss: 0.5008\n",
            "Epoch 2, D Loss: 0.4613, G Loss: 1.2838, AE Loss: 0.6466\n",
            "Epoch 2, D Loss: 0.4069, G Loss: 1.2974, AE Loss: 0.5829\n",
            "Epoch 2, D Loss: 0.4805, G Loss: 1.3850, AE Loss: 0.5801\n",
            "Epoch 2, D Loss: 0.9882, G Loss: 1.2291, AE Loss: 0.4573\n",
            "Epoch 2, D Loss: 0.8237, G Loss: 1.4416, AE Loss: 0.7062\n",
            "Epoch 2, D Loss: 0.6525, G Loss: 1.4915, AE Loss: 0.6463\n",
            "Epoch 2, D Loss: 0.4264, G Loss: 1.2600, AE Loss: 0.4725\n",
            "Epoch 2, D Loss: 1.1666, G Loss: 1.4676, AE Loss: 0.6329\n",
            "Epoch 2, D Loss: 0.7126, G Loss: 1.6648, AE Loss: 0.6268\n",
            "Epoch 2, D Loss: 0.6521, G Loss: 1.6447, AE Loss: 0.5004\n",
            "Epoch 2, D Loss: 0.5530, G Loss: 1.4069, AE Loss: 0.5690\n",
            "Epoch 2, D Loss: 1.0399, G Loss: 1.5708, AE Loss: 0.4745\n",
            "Epoch 2, D Loss: 0.5098, G Loss: 1.4886, AE Loss: 0.5916\n",
            "Epoch 2, D Loss: 0.5614, G Loss: 1.4678, AE Loss: 0.4741\n",
            "Epoch 2, D Loss: 0.8200, G Loss: 1.5301, AE Loss: 0.5202\n",
            "Epoch 2, D Loss: 0.6067, G Loss: 1.7553, AE Loss: 0.2861\n",
            "Epoch 2, D Loss: 0.6535, G Loss: 1.5910, AE Loss: 0.5337\n",
            "Epoch 2, D Loss: 1.5274, G Loss: 1.4291, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 0.9354, G Loss: 1.6093, AE Loss: 0.5973\n",
            "Epoch 2, D Loss: 0.4406, G Loss: 1.7284, AE Loss: 0.5890\n",
            "Epoch 2, D Loss: 0.3315, G Loss: 1.5329, AE Loss: 0.5118\n",
            "Epoch 2, D Loss: 1.2348, G Loss: 1.6315, AE Loss: 0.5383\n",
            "Epoch 2, D Loss: 0.6766, G Loss: 1.5380, AE Loss: 0.5242\n",
            "Epoch 2, D Loss: 0.6099, G Loss: 1.5032, AE Loss: 0.5739\n",
            "Epoch 2, D Loss: 1.0619, G Loss: 1.4365, AE Loss: 0.5534\n",
            "Epoch 2, D Loss: 0.3599, G Loss: 1.4049, AE Loss: 0.5206\n",
            "Epoch 2, D Loss: 0.5739, G Loss: 1.4618, AE Loss: 0.5297\n",
            "Epoch 2, D Loss: 1.5241, G Loss: 1.5556, AE Loss: 0.5968\n",
            "Epoch 2, D Loss: 0.8110, G Loss: 1.5574, AE Loss: 0.5393\n",
            "Epoch 2, D Loss: 0.7292, G Loss: 1.6089, AE Loss: 0.5474\n",
            "Epoch 2, D Loss: 1.3922, G Loss: 1.4628, AE Loss: 0.5488\n",
            "Epoch 2, D Loss: 1.3804, G Loss: 1.3791, AE Loss: 0.4667\n",
            "Epoch 2, D Loss: 0.9346, G Loss: 1.5573, AE Loss: 0.5382\n",
            "Epoch 2, D Loss: 0.7156, G Loss: 1.4055, AE Loss: 0.6671\n",
            "Epoch 2, D Loss: 0.8618, G Loss: 1.2876, AE Loss: 0.5609\n",
            "Epoch 2, D Loss: 0.8865, G Loss: 1.3247, AE Loss: 0.5851\n",
            "Epoch 2, D Loss: 1.1104, G Loss: 1.3127, AE Loss: 0.5904\n",
            "Epoch 2, D Loss: 1.2911, G Loss: 1.5118, AE Loss: 0.6320\n",
            "Epoch 2, D Loss: 0.9431, G Loss: 1.2981, AE Loss: 0.5074\n",
            "Epoch 2, D Loss: 0.6643, G Loss: 1.5030, AE Loss: 0.5144\n",
            "Epoch 2, D Loss: 0.9199, G Loss: 1.4965, AE Loss: 0.5582\n",
            "Epoch 2, D Loss: 0.8328, G Loss: 1.4600, AE Loss: 0.4974\n",
            "Epoch 2, D Loss: 0.8713, G Loss: 1.5134, AE Loss: 0.5756\n",
            "Epoch 2, D Loss: 1.9867, G Loss: 1.3274, AE Loss: 0.5527\n",
            "Epoch 2, D Loss: 0.3371, G Loss: 1.5849, AE Loss: 0.6195\n",
            "Epoch 2, D Loss: 0.6872, G Loss: 1.6913, AE Loss: 0.4773\n",
            "Epoch 2, D Loss: 0.8311, G Loss: 1.5702, AE Loss: 0.6038\n",
            "Epoch 2, D Loss: 1.0178, G Loss: 1.6066, AE Loss: 0.5195\n",
            "Epoch 2, D Loss: 0.8119, G Loss: 1.8651, AE Loss: 0.5690\n",
            "Epoch 2, D Loss: 1.2683, G Loss: 1.6513, AE Loss: 0.7205\n",
            "Epoch 2, D Loss: 0.5862, G Loss: 1.6452, AE Loss: 0.5863\n",
            "Epoch 2, D Loss: 0.3968, G Loss: 1.7442, AE Loss: 0.5301\n",
            "Epoch 2, D Loss: 0.9232, G Loss: 1.6526, AE Loss: 0.6453\n",
            "Epoch 2, D Loss: 0.6745, G Loss: 1.6787, AE Loss: 0.5614\n",
            "Epoch 2, D Loss: 0.7245, G Loss: 1.6671, AE Loss: 0.5119\n",
            "Epoch 2, D Loss: 0.2603, G Loss: 1.7294, AE Loss: 0.5604\n",
            "Epoch 2, D Loss: 1.5617, G Loss: 1.7175, AE Loss: 0.4586\n",
            "Epoch 2, D Loss: 0.6336, G Loss: 2.3109, AE Loss: 0.4226\n",
            "Epoch 2, D Loss: 1.9690, G Loss: 1.7146, AE Loss: 0.4915\n",
            "Epoch 2, D Loss: 0.5473, G Loss: 1.7291, AE Loss: 0.6345\n",
            "Epoch 2, D Loss: 0.2997, G Loss: 1.6565, AE Loss: 0.6417\n",
            "Epoch 2, D Loss: 0.4191, G Loss: 1.6963, AE Loss: 0.5932\n",
            "Epoch 2, D Loss: 0.6574, G Loss: 2.0529, AE Loss: 0.3027\n",
            "Epoch 2, D Loss: 0.9291, G Loss: 2.0710, AE Loss: 0.5628\n",
            "Epoch 2, D Loss: 1.2363, G Loss: 1.8613, AE Loss: 0.5749\n",
            "Epoch 2, D Loss: 0.8600, G Loss: 1.8172, AE Loss: 0.5021\n",
            "Epoch 2, D Loss: 0.7444, G Loss: 1.8384, AE Loss: 0.5680\n",
            "Epoch 2, D Loss: 0.6472, G Loss: 1.8316, AE Loss: 0.5109\n",
            "Epoch 2, D Loss: 0.2216, G Loss: 1.9747, AE Loss: 0.6543\n",
            "Epoch 2, D Loss: 0.8788, G Loss: 1.8673, AE Loss: 0.5538\n",
            "Epoch 2, D Loss: 0.8497, G Loss: 1.9944, AE Loss: 0.4960\n",
            "Epoch 2, D Loss: 0.4104, G Loss: 1.8877, AE Loss: 0.4927\n",
            "Epoch 2, D Loss: 0.4361, G Loss: 1.8866, AE Loss: 0.5467\n",
            "Epoch 2, D Loss: 0.3789, G Loss: 2.1130, AE Loss: 0.5081\n",
            "Epoch 2, D Loss: 0.7258, G Loss: 2.2060, AE Loss: 0.5059\n",
            "Epoch 2, D Loss: 1.1119, G Loss: 2.0556, AE Loss: 0.6017\n",
            "Epoch 2, D Loss: 0.7113, G Loss: 2.1355, AE Loss: 0.5240\n",
            "Epoch 2, D Loss: 0.6948, G Loss: 2.1539, AE Loss: 0.5887\n",
            "Epoch 2, D Loss: 1.4530, G Loss: 1.9188, AE Loss: 0.6986\n",
            "Epoch 2, D Loss: 1.1952, G Loss: 2.2181, AE Loss: 0.4889\n",
            "Epoch 2, D Loss: 0.2553, G Loss: 2.2884, AE Loss: 0.5532\n",
            "Epoch 2, D Loss: 0.2438, G Loss: 2.2191, AE Loss: 0.5804\n",
            "Epoch 2, D Loss: 0.9067, G Loss: 2.0705, AE Loss: 0.5228\n",
            "Epoch 2, D Loss: 0.9540, G Loss: 2.0580, AE Loss: 0.6142\n",
            "Epoch 2, D Loss: 1.0660, G Loss: 2.0834, AE Loss: 0.5662\n",
            "Epoch 2, D Loss: 0.3143, G Loss: 1.9994, AE Loss: 0.5087\n",
            "Epoch 2, D Loss: 0.6401, G Loss: 2.0646, AE Loss: 0.5302\n",
            "Epoch 2, D Loss: 1.0590, G Loss: 2.0079, AE Loss: 0.5250\n",
            "Epoch 2, D Loss: 1.1885, G Loss: 2.1643, AE Loss: 0.5786\n",
            "Epoch 2, D Loss: 0.5089, G Loss: 2.1540, AE Loss: 0.5128\n",
            "Epoch 2, D Loss: 0.6355, G Loss: 2.3923, AE Loss: 0.5386\n",
            "Epoch 2, D Loss: 0.5097, G Loss: 2.0202, AE Loss: 0.4940\n",
            "Epoch 2, D Loss: 0.9604, G Loss: 2.1770, AE Loss: 0.5719\n",
            "Epoch 2, D Loss: 1.0702, G Loss: 2.0994, AE Loss: 0.5034\n",
            "Epoch 2, D Loss: 0.7037, G Loss: 2.1877, AE Loss: 0.4417\n",
            "Epoch 2, D Loss: 0.4165, G Loss: 2.3609, AE Loss: 0.5054\n",
            "Epoch 2, D Loss: 0.5053, G Loss: 2.3440, AE Loss: 0.4134\n",
            "Epoch 2, D Loss: 0.3892, G Loss: 2.3167, AE Loss: 0.4456\n",
            "Epoch 2, D Loss: 1.1215, G Loss: 2.4341, AE Loss: 0.5717\n",
            "Epoch 2, D Loss: 0.5945, G Loss: 2.3869, AE Loss: 0.6236\n",
            "Epoch 2, D Loss: 0.4417, G Loss: 2.1818, AE Loss: 0.4224\n",
            "Epoch 2, D Loss: 0.4284, G Loss: 2.2726, AE Loss: 0.5358\n",
            "Epoch 2, D Loss: 1.0940, G Loss: 2.5104, AE Loss: 0.5189\n",
            "Epoch 2, D Loss: 1.6559, G Loss: 2.5235, AE Loss: 0.5356\n",
            "Epoch 2, D Loss: 1.2411, G Loss: 2.5198, AE Loss: 0.5897\n",
            "Epoch 2, D Loss: 0.8737, G Loss: 2.5705, AE Loss: 0.6286\n",
            "Epoch 2, D Loss: 0.3247, G Loss: 2.5483, AE Loss: 0.5512\n",
            "Epoch 2, D Loss: 0.4366, G Loss: 2.5034, AE Loss: 0.6207\n",
            "Epoch 2, D Loss: 0.5277, G Loss: 2.4231, AE Loss: 0.5971\n",
            "Epoch 2, D Loss: 1.1749, G Loss: 2.5379, AE Loss: 0.7766\n",
            "Epoch 2, D Loss: 0.2793, G Loss: 2.4153, AE Loss: 0.5651\n",
            "Epoch 2, D Loss: 0.7940, G Loss: 2.4863, AE Loss: 0.5312\n",
            "Epoch 2, D Loss: 0.7286, G Loss: 2.6833, AE Loss: 0.5908\n",
            "Epoch 2, D Loss: 0.6418, G Loss: 2.4775, AE Loss: 0.5406\n",
            "Epoch 2, D Loss: 0.3982, G Loss: 2.5236, AE Loss: 0.6516\n",
            "Epoch 2, D Loss: 0.6003, G Loss: 2.5930, AE Loss: 0.5120\n",
            "Epoch 2, D Loss: 0.4301, G Loss: 2.6279, AE Loss: 0.4935\n",
            "Epoch 2, D Loss: 0.1535, G Loss: 2.6825, AE Loss: 0.6043\n",
            "Epoch 2, D Loss: 0.3234, G Loss: 2.7610, AE Loss: 0.5344\n",
            "Epoch 2, D Loss: 0.5970, G Loss: 2.8520, AE Loss: 0.4406\n",
            "Epoch 2, D Loss: 0.5253, G Loss: 2.6992, AE Loss: 0.5965\n",
            "Epoch 2, D Loss: 0.6098, G Loss: 2.9858, AE Loss: 0.5219\n",
            "Epoch 2, D Loss: 0.6522, G Loss: 2.7261, AE Loss: 0.5014\n",
            "Epoch 2, D Loss: 0.2648, G Loss: 2.6725, AE Loss: 0.4485\n",
            "Epoch 2, D Loss: 0.1648, G Loss: 2.7436, AE Loss: 0.5805\n",
            "Epoch 2, D Loss: 0.6776, G Loss: 2.5047, AE Loss: 0.5534\n",
            "Epoch 2, D Loss: 0.5787, G Loss: 2.4394, AE Loss: 0.4797\n",
            "Epoch 2, D Loss: 0.3804, G Loss: 2.4813, AE Loss: 0.4571\n",
            "Epoch 2, D Loss: 0.2702, G Loss: 2.5245, AE Loss: 0.6529\n",
            "Epoch 2, D Loss: 0.9122, G Loss: 2.5940, AE Loss: 0.5647\n",
            "Epoch 2, D Loss: 1.1860, G Loss: 2.6146, AE Loss: 0.5324\n",
            "Epoch 2, D Loss: 1.0022, G Loss: 2.6260, AE Loss: 0.4475\n",
            "Epoch 2, D Loss: 0.4351, G Loss: 2.6576, AE Loss: 0.5878\n",
            "Epoch 2, D Loss: 0.7110, G Loss: 2.5334, AE Loss: 0.6222\n",
            "Epoch 2, D Loss: 0.2918, G Loss: 2.5867, AE Loss: 0.5126\n",
            "Epoch 2, D Loss: 0.3483, G Loss: 2.5847, AE Loss: 0.4375\n",
            "Epoch 2, D Loss: 0.4530, G Loss: 2.5614, AE Loss: 0.5099\n",
            "Epoch 2, D Loss: 0.6759, G Loss: 2.6087, AE Loss: 0.4948\n",
            "Epoch 2, D Loss: 0.3957, G Loss: 2.7569, AE Loss: 0.5324\n",
            "Epoch 2, D Loss: 0.3310, G Loss: 2.4570, AE Loss: 0.5625\n",
            "Epoch 2, D Loss: 0.8943, G Loss: 2.7830, AE Loss: 0.5336\n",
            "Epoch 2, D Loss: 0.2106, G Loss: 2.8320, AE Loss: 0.4553\n",
            "Epoch 2, D Loss: 0.7781, G Loss: 2.7339, AE Loss: 0.5005\n",
            "Epoch 2, D Loss: 0.7757, G Loss: 2.8988, AE Loss: 0.6745\n",
            "Epoch 2, D Loss: 0.3168, G Loss: 2.9044, AE Loss: 0.5580\n",
            "Epoch 2, D Loss: 0.8626, G Loss: 2.9927, AE Loss: 0.5188\n",
            "Epoch 2, D Loss: 0.6694, G Loss: 2.7972, AE Loss: 0.4394\n",
            "Epoch 2, D Loss: 0.4322, G Loss: 2.7801, AE Loss: 0.6216\n",
            "Epoch 2, D Loss: 0.3727, G Loss: 2.7871, AE Loss: 0.5494\n",
            "Epoch 2, D Loss: 0.9632, G Loss: 2.8098, AE Loss: 0.6533\n",
            "Epoch 2, D Loss: 0.6189, G Loss: 2.8130, AE Loss: 0.4233\n",
            "Epoch 2, D Loss: 0.8777, G Loss: 2.8656, AE Loss: 0.4479\n",
            "Epoch 2, D Loss: 0.4848, G Loss: 2.8189, AE Loss: 0.6869\n",
            "Epoch 2, D Loss: 0.4069, G Loss: 2.8903, AE Loss: 0.6562\n",
            "Epoch 2, D Loss: 0.3097, G Loss: 2.8791, AE Loss: 0.4593\n",
            "Epoch 2, D Loss: 0.3269, G Loss: 2.7481, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 0.4667, G Loss: 2.7354, AE Loss: 0.6098\n",
            "Epoch 2, D Loss: 0.2916, G Loss: 2.9347, AE Loss: 0.6197\n",
            "Epoch 2, D Loss: 0.1084, G Loss: 2.8738, AE Loss: 0.4970\n",
            "Epoch 2, D Loss: 0.0835, G Loss: 2.9011, AE Loss: 0.5508\n",
            "Epoch 2, D Loss: 0.4409, G Loss: 2.9362, AE Loss: 0.5699\n",
            "Epoch 2, D Loss: 0.4174, G Loss: 2.8990, AE Loss: 0.6272\n",
            "Epoch 2, D Loss: 0.4421, G Loss: 2.9535, AE Loss: 0.5772\n",
            "Epoch 2, D Loss: 0.1549, G Loss: 2.9323, AE Loss: 0.4331\n",
            "Epoch 2, D Loss: 0.5923, G Loss: 2.8333, AE Loss: 0.4935\n",
            "Epoch 2, D Loss: 0.1366, G Loss: 2.9311, AE Loss: 0.5298\n",
            "Epoch 2, D Loss: 0.3388, G Loss: 2.9684, AE Loss: 0.4889\n",
            "Epoch 2, D Loss: 0.1070, G Loss: 2.9580, AE Loss: 0.5509\n",
            "Epoch 2, D Loss: 0.5490, G Loss: 2.7452, AE Loss: 0.6132\n",
            "Epoch 2, D Loss: 0.4234, G Loss: 2.9860, AE Loss: 0.6611\n",
            "Epoch 2, D Loss: 0.4172, G Loss: 2.7852, AE Loss: 0.5629\n",
            "Epoch 2, D Loss: 0.5034, G Loss: 2.8337, AE Loss: 0.4643\n",
            "Epoch 2, D Loss: 0.1184, G Loss: 2.8741, AE Loss: 0.5710\n",
            "Epoch 2, D Loss: 0.2622, G Loss: 2.8406, AE Loss: 0.5822\n",
            "Epoch 2, D Loss: 0.1091, G Loss: 2.7526, AE Loss: 0.5837\n",
            "Epoch 2, D Loss: 0.3395, G Loss: 3.1023, AE Loss: 0.5163\n",
            "Epoch 2, D Loss: 0.1252, G Loss: 2.8288, AE Loss: 0.5470\n",
            "Epoch 2, D Loss: 0.3973, G Loss: 2.9354, AE Loss: 0.4086\n",
            "Epoch 2, D Loss: 0.0848, G Loss: 2.9032, AE Loss: 0.7204\n",
            "Epoch 2, D Loss: 0.6046, G Loss: 3.1608, AE Loss: 0.5692\n",
            "Epoch 2, D Loss: 0.2623, G Loss: 2.6347, AE Loss: 0.7248\n",
            "Epoch 2, D Loss: 0.3453, G Loss: 2.8156, AE Loss: 0.4885\n",
            "Epoch 2, D Loss: 0.2019, G Loss: 2.7606, AE Loss: 0.5985\n",
            "Epoch 2, D Loss: 0.2889, G Loss: 2.9189, AE Loss: 0.6049\n",
            "Epoch 2, D Loss: 0.5618, G Loss: 2.9032, AE Loss: 0.6647\n",
            "Epoch 2, D Loss: 0.3561, G Loss: 2.6016, AE Loss: 0.6002\n",
            "Epoch 2, D Loss: 0.1212, G Loss: 2.9644, AE Loss: 0.4937\n",
            "Epoch 2, D Loss: 0.4350, G Loss: 2.9640, AE Loss: 0.5616\n",
            "Epoch 2, D Loss: 0.2280, G Loss: 2.9625, AE Loss: 0.5794\n",
            "Epoch 2, D Loss: 0.6220, G Loss: 2.8017, AE Loss: 0.4680\n",
            "Epoch 2, D Loss: 0.0987, G Loss: 2.6922, AE Loss: 0.3714\n",
            "Epoch 2, D Loss: 0.0984, G Loss: 2.7781, AE Loss: 0.6488\n",
            "Epoch 2, D Loss: 0.3001, G Loss: 2.6503, AE Loss: 0.6029\n",
            "Epoch 2, D Loss: 0.1948, G Loss: 2.6587, AE Loss: 0.4999\n",
            "Epoch 2, D Loss: 0.5768, G Loss: 2.6535, AE Loss: 0.4642\n",
            "Epoch 2, D Loss: 0.4675, G Loss: 2.9466, AE Loss: 0.5881\n",
            "Epoch 2, D Loss: 0.1602, G Loss: 2.5945, AE Loss: 0.4904\n",
            "Epoch 2, D Loss: 0.2554, G Loss: 2.9172, AE Loss: 0.5714\n",
            "Epoch 2, D Loss: 0.1397, G Loss: 2.9818, AE Loss: 0.5072\n",
            "Epoch 2, D Loss: 0.1541, G Loss: 2.7656, AE Loss: 0.4284\n",
            "Epoch 2, D Loss: 0.5231, G Loss: 2.6757, AE Loss: 0.5680\n",
            "Epoch 2, D Loss: 0.1782, G Loss: 2.5617, AE Loss: 0.5970\n",
            "Epoch 2, D Loss: 0.2263, G Loss: 2.5360, AE Loss: 0.7150\n",
            "Epoch 2, D Loss: 0.2420, G Loss: 2.6497, AE Loss: 0.5007\n",
            "Epoch 2, D Loss: 0.3630, G Loss: 2.4782, AE Loss: 0.6179\n",
            "Epoch 2, D Loss: 0.1121, G Loss: 2.5288, AE Loss: 0.5586\n",
            "Epoch 2, D Loss: 0.1642, G Loss: 2.5255, AE Loss: 0.5720\n",
            "Epoch 2, D Loss: 0.5764, G Loss: 2.4805, AE Loss: 0.6490\n",
            "Epoch 2, D Loss: 0.4716, G Loss: 2.3023, AE Loss: 0.4777\n",
            "Epoch 2, D Loss: 0.4535, G Loss: 2.3867, AE Loss: 0.6184\n",
            "Epoch 2, D Loss: 0.6777, G Loss: 2.3224, AE Loss: 0.6978\n",
            "Epoch 2, D Loss: 0.5548, G Loss: 2.4384, AE Loss: 0.5271\n",
            "Epoch 2, D Loss: 0.6925, G Loss: 2.4583, AE Loss: 0.6662\n",
            "Epoch 2, D Loss: 0.3386, G Loss: 2.3406, AE Loss: 0.8105\n",
            "Epoch 2, D Loss: 0.2327, G Loss: 2.5682, AE Loss: 0.5684\n",
            "Epoch 2, D Loss: 0.2180, G Loss: 2.5134, AE Loss: 0.5727\n",
            "Epoch 2, D Loss: 0.5461, G Loss: 2.4742, AE Loss: 0.6357\n",
            "Epoch 2, D Loss: 0.3338, G Loss: 2.5474, AE Loss: 0.6538\n",
            "Epoch 2, D Loss: 0.2056, G Loss: 2.4207, AE Loss: 0.7086\n",
            "Epoch 2, D Loss: 0.5491, G Loss: 2.5887, AE Loss: 0.6023\n",
            "Epoch 2, D Loss: 0.3997, G Loss: 2.4188, AE Loss: 0.5383\n",
            "Epoch 2, D Loss: 0.1612, G Loss: 2.5798, AE Loss: 0.6207\n",
            "Epoch 2, D Loss: 0.1430, G Loss: 2.3810, AE Loss: 0.6282\n",
            "Epoch 2, D Loss: 0.1825, G Loss: 2.6965, AE Loss: 0.5454\n",
            "Epoch 2, D Loss: 0.1844, G Loss: 2.5219, AE Loss: 0.4348\n",
            "Epoch 2, D Loss: 0.1966, G Loss: 2.3680, AE Loss: 0.4563\n",
            "Epoch 2, D Loss: 0.1627, G Loss: 2.1823, AE Loss: 0.6553\n",
            "Epoch 2, D Loss: 0.3123, G Loss: 2.1339, AE Loss: 0.3956\n",
            "Epoch 2, D Loss: 0.4780, G Loss: 2.1149, AE Loss: 0.5661\n",
            "Epoch 2, D Loss: 0.2287, G Loss: 2.1523, AE Loss: 0.4679\n",
            "Epoch 2, D Loss: 0.2588, G Loss: 2.0550, AE Loss: 0.5549\n",
            "Epoch 2, D Loss: 0.5223, G Loss: 1.8094, AE Loss: 0.4752\n",
            "Epoch 2, D Loss: 0.5630, G Loss: 2.2073, AE Loss: 0.3758\n",
            "Epoch 2, D Loss: 0.3341, G Loss: 1.6777, AE Loss: 0.5824\n",
            "Epoch 2, D Loss: 0.3013, G Loss: 1.7751, AE Loss: 0.5350\n",
            "Epoch 2, D Loss: 0.3359, G Loss: 1.9852, AE Loss: 0.4789\n",
            "Epoch 2, D Loss: 0.5989, G Loss: 1.6979, AE Loss: 0.7582\n",
            "Epoch 2, D Loss: 0.5797, G Loss: 2.0274, AE Loss: 0.5775\n",
            "Epoch 2, D Loss: 0.2306, G Loss: 1.8807, AE Loss: 0.5670\n",
            "Epoch 2, D Loss: 0.6089, G Loss: 1.8345, AE Loss: 0.5420\n",
            "Epoch 2, D Loss: 0.2951, G Loss: 1.9686, AE Loss: 0.4770\n",
            "Epoch 2, D Loss: 0.6783, G Loss: 1.9347, AE Loss: 0.5349\n",
            "Epoch 2, D Loss: 0.4432, G Loss: 1.7771, AE Loss: 0.5068\n",
            "Epoch 2, D Loss: 0.3408, G Loss: 1.5802, AE Loss: 0.7871\n",
            "Epoch 2, D Loss: 0.8874, G Loss: 1.8667, AE Loss: 0.5275\n",
            "Epoch 2, D Loss: 0.4182, G Loss: 1.9693, AE Loss: 0.6316\n",
            "Epoch 2, D Loss: 0.4410, G Loss: 1.7487, AE Loss: 0.6634\n",
            "Epoch 2, D Loss: 1.0771, G Loss: 1.6339, AE Loss: 0.6204\n",
            "Epoch 2, D Loss: 0.9143, G Loss: 1.7605, AE Loss: 0.6231\n",
            "Epoch 2, D Loss: 0.8094, G Loss: 1.7240, AE Loss: 0.8702\n",
            "Epoch 2, D Loss: 0.8839, G Loss: 1.7795, AE Loss: 0.4930\n",
            "Epoch 2, D Loss: 1.0621, G Loss: 1.5352, AE Loss: 0.7856\n",
            "Epoch 2, D Loss: 1.0868, G Loss: 1.6039, AE Loss: 0.5899\n",
            "Epoch 2, D Loss: 0.7499, G Loss: 1.7114, AE Loss: 0.5936\n",
            "Epoch 2, D Loss: 0.8502, G Loss: 1.7708, AE Loss: 0.5750\n",
            "Epoch 2, D Loss: 1.5514, G Loss: 1.6606, AE Loss: 0.4811\n",
            "Epoch 2, D Loss: 0.6645, G Loss: 1.4170, AE Loss: 0.5409\n",
            "Epoch 2, D Loss: 0.4940, G Loss: 1.6700, AE Loss: 0.6331\n",
            "Epoch 2, D Loss: 1.2629, G Loss: 1.1093, AE Loss: 0.5400\n",
            "Epoch 2, D Loss: 0.9658, G Loss: 1.2962, AE Loss: 0.6041\n",
            "Epoch 2, D Loss: 0.8358, G Loss: 1.1960, AE Loss: 0.6795\n",
            "Epoch 2, D Loss: 0.6700, G Loss: 1.2039, AE Loss: 0.7705\n",
            "Epoch 2, D Loss: 0.7690, G Loss: 1.2597, AE Loss: 0.4461\n",
            "Epoch 2, D Loss: 0.6436, G Loss: 1.0790, AE Loss: 0.5940\n",
            "Epoch 2, D Loss: 0.5698, G Loss: 1.2143, AE Loss: 0.4874\n",
            "Epoch 2, D Loss: 0.9057, G Loss: 1.1711, AE Loss: 0.7838\n",
            "Epoch 2, D Loss: 0.6131, G Loss: 1.2284, AE Loss: 0.4618\n",
            "Epoch 2, D Loss: 0.9185, G Loss: 1.2824, AE Loss: 0.5803\n",
            "Epoch 2, D Loss: 1.2365, G Loss: 0.9652, AE Loss: 0.4521\n",
            "Epoch 2, D Loss: 1.2245, G Loss: 1.1501, AE Loss: 0.6119\n",
            "Epoch 2, D Loss: 0.9269, G Loss: 1.2354, AE Loss: 0.6289\n",
            "Epoch 2, D Loss: 0.4689, G Loss: 1.4545, AE Loss: 0.5435\n",
            "Epoch 2, D Loss: 0.8075, G Loss: 1.0963, AE Loss: 0.6129\n",
            "Epoch 2, D Loss: 0.8283, G Loss: 1.1526, AE Loss: 0.4864\n",
            "Epoch 2, D Loss: 1.3150, G Loss: 0.9347, AE Loss: 0.5610\n",
            "Epoch 2, D Loss: 0.7385, G Loss: 1.0653, AE Loss: 0.5758\n",
            "Epoch 2, D Loss: 0.8551, G Loss: 1.2484, AE Loss: 0.4732\n",
            "Epoch 2, D Loss: 1.3421, G Loss: 0.9248, AE Loss: 0.9293\n",
            "Epoch 2, D Loss: 1.5256, G Loss: 0.8527, AE Loss: 0.7564\n",
            "Epoch 2, D Loss: 1.3055, G Loss: 0.7775, AE Loss: 0.4835\n",
            "Epoch 2, D Loss: 2.2654, G Loss: 0.6454, AE Loss: 0.7809\n",
            "Epoch 2, D Loss: 1.5197, G Loss: 0.9439, AE Loss: 0.4205\n",
            "Epoch 2, D Loss: 0.5469, G Loss: 1.1314, AE Loss: 0.6076\n",
            "Epoch 2, D Loss: 0.8918, G Loss: 0.8835, AE Loss: 0.5707\n",
            "Epoch 2, D Loss: 1.6207, G Loss: 1.0816, AE Loss: 0.6121\n",
            "Epoch 2, D Loss: 0.9522, G Loss: 1.2018, AE Loss: 0.3781\n",
            "Epoch 2, D Loss: 0.7908, G Loss: 1.2327, AE Loss: 0.6000\n",
            "Epoch 2, D Loss: 1.1261, G Loss: 1.0494, AE Loss: 0.5704\n",
            "Epoch 2, D Loss: 0.5902, G Loss: 1.1637, AE Loss: 0.5778\n",
            "Epoch 2, D Loss: 1.2297, G Loss: 1.0056, AE Loss: 0.4942\n",
            "Epoch 2, D Loss: 1.1690, G Loss: 1.2188, AE Loss: 0.3885\n",
            "Epoch 2, D Loss: 1.2330, G Loss: 1.3965, AE Loss: 0.6746\n",
            "Epoch 2, D Loss: 0.5878, G Loss: 1.2285, AE Loss: 0.5258\n",
            "Epoch 2, D Loss: 1.1623, G Loss: 1.1268, AE Loss: 0.5489\n",
            "Epoch 2, D Loss: 0.9276, G Loss: 1.2536, AE Loss: 0.5031\n",
            "Epoch 2, D Loss: 0.5689, G Loss: 1.3070, AE Loss: 0.5814\n",
            "Epoch 2, D Loss: 0.9891, G Loss: 1.2163, AE Loss: 0.6043\n",
            "Epoch 2, D Loss: 0.9227, G Loss: 1.1618, AE Loss: 0.6268\n",
            "Epoch 2, D Loss: 0.3218, G Loss: 1.6070, AE Loss: 0.6155\n",
            "Epoch 2, D Loss: 0.7825, G Loss: 1.5522, AE Loss: 0.4660\n",
            "Epoch 2, D Loss: 0.5977, G Loss: 1.5314, AE Loss: 0.6034\n",
            "Epoch 2, D Loss: 1.2416, G Loss: 1.6954, AE Loss: 0.6159\n",
            "Epoch 2, D Loss: 1.0305, G Loss: 1.3523, AE Loss: 0.5319\n",
            "Epoch 2, D Loss: 0.9815, G Loss: 1.6426, AE Loss: 0.5115\n",
            "Epoch 2, D Loss: 0.4962, G Loss: 1.5282, AE Loss: 0.5360\n",
            "Epoch 2, D Loss: 1.3620, G Loss: 1.3531, AE Loss: 0.4828\n",
            "Epoch 2, D Loss: 0.4809, G Loss: 1.5324, AE Loss: 0.5767\n",
            "Epoch 2, D Loss: 0.7247, G Loss: 1.5796, AE Loss: 0.5678\n",
            "Epoch 2, D Loss: 0.4993, G Loss: 1.5409, AE Loss: 0.4876\n",
            "Epoch 2, D Loss: 0.3540, G Loss: 1.7133, AE Loss: 0.6023\n",
            "Epoch 2, D Loss: 0.6625, G Loss: 1.6955, AE Loss: 0.6510\n",
            "Epoch 2, D Loss: 0.4036, G Loss: 1.8519, AE Loss: 0.5643\n",
            "Epoch 2, D Loss: 0.6817, G Loss: 1.7783, AE Loss: 0.6545\n",
            "Epoch 2, D Loss: 0.7312, G Loss: 1.7809, AE Loss: 0.4319\n",
            "Epoch 2, D Loss: 0.3039, G Loss: 1.9118, AE Loss: 0.6348\n",
            "Epoch 2, D Loss: 0.3088, G Loss: 1.7818, AE Loss: 0.6996\n",
            "Epoch 2, D Loss: 0.7437, G Loss: 1.8591, AE Loss: 0.5259\n",
            "Epoch 2, D Loss: 0.7473, G Loss: 1.9271, AE Loss: 0.7092\n",
            "Epoch 2, D Loss: 1.2332, G Loss: 2.0232, AE Loss: 0.5103\n",
            "Epoch 2, D Loss: 0.2882, G Loss: 1.9862, AE Loss: 0.5418\n",
            "Epoch 2, D Loss: 0.5479, G Loss: 2.0015, AE Loss: 0.5771\n",
            "Epoch 2, D Loss: 0.8052, G Loss: 1.9317, AE Loss: 0.4473\n",
            "Epoch 2, D Loss: 0.6340, G Loss: 1.8370, AE Loss: 0.5431\n",
            "Epoch 2, D Loss: 1.1815, G Loss: 1.9036, AE Loss: 0.5507\n",
            "Epoch 2, D Loss: 0.3203, G Loss: 1.8470, AE Loss: 0.4461\n",
            "Epoch 2, D Loss: 0.3103, G Loss: 1.7857, AE Loss: 0.6342\n",
            "Epoch 2, D Loss: 0.7196, G Loss: 1.9457, AE Loss: 0.4352\n",
            "Epoch 2, D Loss: 0.7338, G Loss: 1.9200, AE Loss: 0.5402\n",
            "Epoch 2, D Loss: 0.7486, G Loss: 1.7688, AE Loss: 0.5481\n",
            "Epoch 2, D Loss: 0.2909, G Loss: 1.9720, AE Loss: 0.4722\n",
            "Epoch 2, D Loss: 0.6015, G Loss: 1.8310, AE Loss: 0.5712\n",
            "Epoch 2, D Loss: 0.8116, G Loss: 1.6555, AE Loss: 0.5992\n",
            "Epoch 2, D Loss: 0.4934, G Loss: 1.7802, AE Loss: 0.5877\n",
            "Epoch 2, D Loss: 0.5551, G Loss: 1.8016, AE Loss: 0.5694\n",
            "Epoch 2, D Loss: 1.2775, G Loss: 1.5506, AE Loss: 0.5031\n",
            "Epoch 2, D Loss: 0.9373, G Loss: 1.7376, AE Loss: 0.5769\n",
            "Epoch 2, D Loss: 0.5447, G Loss: 1.7554, AE Loss: 0.5175\n",
            "Epoch 2, D Loss: 0.3124, G Loss: 1.7145, AE Loss: 0.6145\n",
            "Epoch 2, D Loss: 1.2355, G Loss: 1.5926, AE Loss: 0.5116\n",
            "Epoch 2, D Loss: 0.4876, G Loss: 1.7048, AE Loss: 0.5166\n",
            "Epoch 2, D Loss: 0.4602, G Loss: 1.4955, AE Loss: 0.5488\n",
            "Epoch 2, D Loss: 0.2820, G Loss: 1.6818, AE Loss: 0.5154\n",
            "Epoch 2, D Loss: 0.2926, G Loss: 1.6959, AE Loss: 0.5413\n",
            "Epoch 2, D Loss: 0.3638, G Loss: 1.5779, AE Loss: 0.5561\n",
            "Epoch 2, D Loss: 0.6901, G Loss: 1.6889, AE Loss: 0.4656\n",
            "Epoch 2, D Loss: 0.3903, G Loss: 1.6193, AE Loss: 0.5689\n",
            "Epoch 2, D Loss: 0.5128, G Loss: 1.7032, AE Loss: 0.6814\n",
            "Epoch 2, D Loss: 0.2659, G Loss: 2.3827, AE Loss: 0.7290\n",
            "Epoch 2, D Loss: 0.7269, G Loss: 1.4807, AE Loss: 0.5834\n",
            "Epoch 2, D Loss: 0.7421, G Loss: 1.6595, AE Loss: 0.7266\n",
            "Epoch 2, D Loss: 0.6126, G Loss: 1.7982, AE Loss: 0.5077\n",
            "Epoch 2, D Loss: 1.0236, G Loss: 1.8134, AE Loss: 0.5454\n",
            "Epoch 2, D Loss: 0.3183, G Loss: 1.9392, AE Loss: 0.5232\n",
            "Epoch 2, D Loss: 0.6857, G Loss: 1.7942, AE Loss: 0.4582\n",
            "Epoch 2, D Loss: 0.4481, G Loss: 1.8245, AE Loss: 0.4780\n",
            "Epoch 2, D Loss: 0.3733, G Loss: 1.9014, AE Loss: 0.4832\n",
            "Epoch 2, D Loss: 0.4370, G Loss: 1.6107, AE Loss: 0.6227\n",
            "Epoch 2, D Loss: 0.2345, G Loss: 1.8419, AE Loss: 0.5185\n",
            "Epoch 2, D Loss: 0.3641, G Loss: 1.8647, AE Loss: 0.6531\n",
            "Epoch 2, D Loss: 0.6917, G Loss: 1.7256, AE Loss: 0.5583\n",
            "Epoch 2, D Loss: 0.3710, G Loss: 2.0554, AE Loss: 0.5148\n",
            "Epoch 2, D Loss: 0.6164, G Loss: 1.8446, AE Loss: 0.6197\n",
            "Epoch 2, D Loss: 0.6308, G Loss: 1.7935, AE Loss: 0.5845\n",
            "Epoch 2, D Loss: 0.3386, G Loss: 1.8965, AE Loss: 0.4075\n",
            "Epoch 2, D Loss: 0.7624, G Loss: 1.8660, AE Loss: 0.4864\n",
            "Epoch 2, D Loss: 0.3746, G Loss: 1.6056, AE Loss: 0.5825\n",
            "Epoch 2, D Loss: 0.6672, G Loss: 1.6546, AE Loss: 0.6947\n",
            "Epoch 2, D Loss: 0.6676, G Loss: 1.7665, AE Loss: 0.4403\n",
            "Epoch 2, D Loss: 0.5778, G Loss: 1.6766, AE Loss: 0.5927\n",
            "Epoch 2, D Loss: 0.4140, G Loss: 1.5857, AE Loss: 0.4693\n",
            "Epoch 2, D Loss: 0.5320, G Loss: 1.7234, AE Loss: 0.5193\n",
            "Epoch 2, D Loss: 0.5956, G Loss: 1.5615, AE Loss: 0.5434\n",
            "Epoch 2, D Loss: 0.5106, G Loss: 1.7568, AE Loss: 0.6334\n",
            "Epoch 2, D Loss: 0.4228, G Loss: 1.6878, AE Loss: 0.4943\n",
            "Epoch 2, D Loss: 0.7245, G Loss: 1.6037, AE Loss: 0.4832\n",
            "Epoch 2, D Loss: 0.3492, G Loss: 1.7228, AE Loss: 0.5524\n",
            "Epoch 2, D Loss: 0.5552, G Loss: 1.7312, AE Loss: 0.5292\n",
            "Epoch 2, D Loss: 0.5218, G Loss: 1.7067, AE Loss: 0.5418\n",
            "Epoch 2, D Loss: 0.4681, G Loss: 1.6924, AE Loss: 0.4604\n",
            "Epoch 2, D Loss: 0.4800, G Loss: 1.8321, AE Loss: 0.6069\n",
            "Epoch 2, D Loss: 0.4391, G Loss: 1.6468, AE Loss: 0.4760\n",
            "Epoch 2, D Loss: 0.3017, G Loss: 1.6806, AE Loss: 0.5361\n",
            "Epoch 2, D Loss: 0.5409, G Loss: 1.8855, AE Loss: 0.5493\n",
            "Epoch 2, D Loss: 0.5090, G Loss: 1.8414, AE Loss: 0.6363\n",
            "Epoch 2, D Loss: 0.7299, G Loss: 1.7770, AE Loss: 0.5968\n",
            "Epoch 2, D Loss: 0.8203, G Loss: 1.6627, AE Loss: 0.6035\n",
            "Epoch 2, D Loss: 0.2663, G Loss: 1.8774, AE Loss: 0.5680\n",
            "Epoch 2, D Loss: 0.5766, G Loss: 1.8102, AE Loss: 0.5566\n",
            "Epoch 2, D Loss: 0.4100, G Loss: 1.8382, AE Loss: 0.6042\n",
            "Epoch 2, D Loss: 0.3845, G Loss: 1.8631, AE Loss: 0.7223\n",
            "Epoch 2, D Loss: 0.7514, G Loss: 1.8039, AE Loss: 0.6216\n",
            "Epoch 2, D Loss: 0.5235, G Loss: 1.8036, AE Loss: 0.6469\n",
            "Epoch 2, D Loss: 1.0936, G Loss: 1.8918, AE Loss: 0.5996\n",
            "Epoch 2, D Loss: 0.4711, G Loss: 1.9131, AE Loss: 0.4817\n",
            "Epoch 2, D Loss: 0.3999, G Loss: 1.7390, AE Loss: 0.5272\n",
            "Epoch 2, D Loss: 0.5657, G Loss: 1.7666, AE Loss: 0.4264\n",
            "Epoch 2, D Loss: 0.3682, G Loss: 1.8971, AE Loss: 0.7051\n",
            "Epoch 2, D Loss: 0.3476, G Loss: 1.9358, AE Loss: 0.5920\n",
            "Epoch 2, D Loss: 0.6027, G Loss: 1.9405, AE Loss: 0.5891\n",
            "Epoch 2, D Loss: 0.4414, G Loss: 1.7374, AE Loss: 0.5494\n",
            "Epoch 2, D Loss: 0.2835, G Loss: 1.8472, AE Loss: 0.5009\n",
            "Epoch 2, D Loss: 0.5471, G Loss: 1.7785, AE Loss: 0.5059\n",
            "Epoch 2, D Loss: 0.3940, G Loss: 1.8690, AE Loss: 0.4851\n",
            "Epoch 2, D Loss: 0.5154, G Loss: 1.8610, AE Loss: 0.4884\n",
            "Epoch 2, D Loss: 0.7032, G Loss: 1.8202, AE Loss: 0.5058\n",
            "Epoch 2, D Loss: 0.7959, G Loss: 1.7612, AE Loss: 0.5665\n",
            "Epoch 2, D Loss: 1.0496, G Loss: 1.6868, AE Loss: 0.4511\n",
            "Epoch 2, D Loss: 0.2759, G Loss: 1.6342, AE Loss: 0.5140\n",
            "Epoch 2, D Loss: 0.5512, G Loss: 1.5956, AE Loss: 0.4907\n",
            "Epoch 2, D Loss: 0.3324, G Loss: 1.6704, AE Loss: 0.4700\n",
            "Epoch 2, D Loss: 0.5675, G Loss: 1.6242, AE Loss: 0.5800\n",
            "Epoch 2, D Loss: 0.5560, G Loss: 1.4876, AE Loss: 0.6520\n",
            "Epoch 2, D Loss: 0.7440, G Loss: 1.6368, AE Loss: 0.4752\n",
            "Epoch 2, D Loss: 0.5762, G Loss: 1.6007, AE Loss: 0.5418\n",
            "Epoch 2, D Loss: 0.5262, G Loss: 1.4560, AE Loss: 0.5654\n",
            "Epoch 2, D Loss: 0.6327, G Loss: 1.5853, AE Loss: 0.5733\n",
            "Epoch 2, D Loss: 0.4844, G Loss: 1.5301, AE Loss: 0.5853\n",
            "Epoch 2, D Loss: 0.5217, G Loss: 1.4967, AE Loss: 0.5615\n",
            "Epoch 2, D Loss: 0.6353, G Loss: 1.4573, AE Loss: 0.4537\n",
            "Epoch 2, D Loss: 0.5547, G Loss: 1.5904, AE Loss: 0.5656\n",
            "Epoch 2, D Loss: 0.5931, G Loss: 1.4762, AE Loss: 0.5305\n",
            "Epoch 2, D Loss: 1.0975, G Loss: 1.5881, AE Loss: 0.5016\n",
            "Epoch 2, D Loss: 0.5350, G Loss: 1.4708, AE Loss: 0.6313\n",
            "Epoch 2, D Loss: 0.4432, G Loss: 1.6963, AE Loss: 0.6384\n",
            "Epoch 2, D Loss: 0.5962, G Loss: 1.4917, AE Loss: 0.7642\n",
            "Epoch 2, D Loss: 0.6848, G Loss: 1.5782, AE Loss: 0.5347\n",
            "Epoch 2, D Loss: 0.9555, G Loss: 1.5750, AE Loss: 0.5957\n",
            "Epoch 2, D Loss: 0.7150, G Loss: 1.6466, AE Loss: 0.5137\n",
            "Epoch 2, D Loss: 0.5370, G Loss: 1.5180, AE Loss: 0.5211\n",
            "Epoch 2, D Loss: 0.4471, G Loss: 1.5674, AE Loss: 0.5538\n",
            "Epoch 2, D Loss: 0.7354, G Loss: 1.5757, AE Loss: 0.4358\n",
            "Epoch 2, D Loss: 0.2886, G Loss: 1.6600, AE Loss: 0.5619\n",
            "Epoch 2, D Loss: 0.4311, G Loss: 1.5844, AE Loss: 0.5636\n",
            "Epoch 2, D Loss: 0.4721, G Loss: 1.6144, AE Loss: 0.5434\n",
            "Epoch 2, D Loss: 0.8054, G Loss: 1.6846, AE Loss: 0.5303\n",
            "Epoch 2, D Loss: 0.5171, G Loss: 1.6231, AE Loss: 0.5627\n",
            "Epoch 2, D Loss: 0.5303, G Loss: 1.6475, AE Loss: 0.5238\n",
            "Epoch 2, D Loss: 0.6096, G Loss: 1.6090, AE Loss: 0.5680\n",
            "Epoch 2, D Loss: 0.5875, G Loss: 1.6280, AE Loss: 0.4902\n",
            "Epoch 2, D Loss: 0.5889, G Loss: 1.5677, AE Loss: 0.4287\n",
            "Epoch 2, D Loss: 0.7629, G Loss: 1.5449, AE Loss: 0.5014\n",
            "Epoch 2, D Loss: 0.6004, G Loss: 1.7019, AE Loss: 0.5892\n",
            "Epoch 2, D Loss: 0.4469, G Loss: 1.6689, AE Loss: 0.5197\n",
            "Epoch 2, D Loss: 0.4315, G Loss: 1.6694, AE Loss: 0.4482\n",
            "Epoch 2, D Loss: 0.2407, G Loss: 1.6604, AE Loss: 0.5839\n",
            "Epoch 2, D Loss: 0.6330, G Loss: 1.5983, AE Loss: 0.5387\n",
            "Epoch 2, D Loss: 0.6484, G Loss: 1.6332, AE Loss: 0.4686\n",
            "Epoch 2, D Loss: 0.2595, G Loss: 1.6329, AE Loss: 0.5943\n",
            "Epoch 2, D Loss: 0.3297, G Loss: 1.6437, AE Loss: 0.5644\n",
            "Epoch 2, D Loss: 0.3454, G Loss: 1.6749, AE Loss: 0.6400\n",
            "Epoch 2, D Loss: 0.5351, G Loss: 1.7569, AE Loss: 0.5398\n",
            "Epoch 2, D Loss: 0.6745, G Loss: 1.7493, AE Loss: 0.5519\n",
            "Epoch 2, D Loss: 1.0295, G Loss: 1.6337, AE Loss: 0.5018\n",
            "Epoch 2, D Loss: 0.6307, G Loss: 1.7588, AE Loss: 0.4395\n",
            "Epoch 2, D Loss: 0.5500, G Loss: 1.8084, AE Loss: 0.4544\n",
            "Epoch 2, D Loss: 0.5005, G Loss: 1.7216, AE Loss: 0.6043\n",
            "Epoch 2, D Loss: 0.5343, G Loss: 1.7051, AE Loss: 0.5822\n",
            "Epoch 2, D Loss: 0.6401, G Loss: 1.7016, AE Loss: 0.4924\n",
            "Epoch 2, D Loss: 0.5105, G Loss: 1.7368, AE Loss: 0.5269\n",
            "Epoch 2, D Loss: 0.4326, G Loss: 1.7470, AE Loss: 0.5543\n",
            "Epoch 2, D Loss: 0.5106, G Loss: 1.7421, AE Loss: 0.4955\n",
            "Epoch 2, D Loss: 0.2323, G Loss: 1.7386, AE Loss: 0.5486\n",
            "Epoch 2, D Loss: 0.6312, G Loss: 1.8159, AE Loss: 0.6397\n",
            "Epoch 2, D Loss: 0.4184, G Loss: 1.7938, AE Loss: 0.5070\n",
            "Epoch 2, D Loss: 0.3267, G Loss: 1.8410, AE Loss: 0.5643\n",
            "Epoch 2, D Loss: 0.3959, G Loss: 1.8042, AE Loss: 0.6371\n",
            "Epoch 2, D Loss: 0.3852, G Loss: 1.7793, AE Loss: 0.6000\n",
            "Epoch 2, D Loss: 0.3176, G Loss: 1.7802, AE Loss: 0.5287\n",
            "Epoch 2, D Loss: 0.2269, G Loss: 1.8842, AE Loss: 0.5667\n",
            "Epoch 2, D Loss: 0.3034, G Loss: 1.8205, AE Loss: 0.3524\n",
            "Epoch 2, D Loss: 0.4400, G Loss: 1.7698, AE Loss: 0.5520\n",
            "Epoch 2, D Loss: 0.2150, G Loss: 1.7302, AE Loss: 0.6102\n",
            "Epoch 2, D Loss: 0.5579, G Loss: 1.8234, AE Loss: 0.5014\n",
            "Epoch 2, D Loss: 0.5112, G Loss: 1.7963, AE Loss: 0.6210\n",
            "Epoch 2, D Loss: 0.4430, G Loss: 1.9542, AE Loss: 0.5677\n",
            "Epoch 2, D Loss: 0.7324, G Loss: 1.8553, AE Loss: 0.7058\n",
            "Epoch 2, D Loss: 0.1964, G Loss: 1.8923, AE Loss: 0.5042\n",
            "Epoch 2, D Loss: 0.8071, G Loss: 1.9130, AE Loss: 0.4666\n",
            "Epoch 2, D Loss: 0.4839, G Loss: 1.9913, AE Loss: 0.5496\n",
            "Epoch 2, D Loss: 0.3910, G Loss: 1.9599, AE Loss: 0.5959\n",
            "Epoch 2, D Loss: 0.5783, G Loss: 1.9581, AE Loss: 0.4514\n",
            "Epoch 2, D Loss: 0.7466, G Loss: 2.0494, AE Loss: 0.4940\n",
            "Epoch 2, D Loss: 0.5833, G Loss: 1.9314, AE Loss: 0.5482\n",
            "Epoch 2, D Loss: 0.7556, G Loss: 2.0767, AE Loss: 0.6111\n",
            "Epoch 2, D Loss: 0.3217, G Loss: 2.0029, AE Loss: 0.5923\n",
            "Epoch 2, D Loss: 0.3590, G Loss: 1.9383, AE Loss: 0.4595\n",
            "Epoch 2, D Loss: 0.5153, G Loss: 1.9712, AE Loss: 0.4876\n",
            "Epoch 2, D Loss: 0.2034, G Loss: 2.0093, AE Loss: 0.4913\n",
            "Epoch 2, D Loss: 0.3723, G Loss: 2.0667, AE Loss: 0.4063\n",
            "Epoch 2, D Loss: 0.2672, G Loss: 2.0602, AE Loss: 0.5448\n",
            "Epoch 2, D Loss: 0.4527, G Loss: 2.0465, AE Loss: 0.5450\n",
            "Epoch 2, D Loss: 0.3606, G Loss: 1.9180, AE Loss: 0.4145\n",
            "Epoch 2, D Loss: 0.6267, G Loss: 1.9380, AE Loss: 0.6260\n",
            "Epoch 2, D Loss: 0.4068, G Loss: 2.0090, AE Loss: 0.5421\n",
            "Epoch 2, D Loss: 0.5451, G Loss: 1.9458, AE Loss: 0.4968\n",
            "Epoch 2, D Loss: 0.4722, G Loss: 1.8764, AE Loss: 0.6172\n",
            "Epoch 2, D Loss: 0.3679, G Loss: 1.9346, AE Loss: 0.5308\n",
            "Epoch 2, D Loss: 0.3429, G Loss: 2.0418, AE Loss: 0.4564\n",
            "Epoch 2, D Loss: 0.4669, G Loss: 2.0723, AE Loss: 0.5792\n",
            "Epoch 2, D Loss: 0.5515, G Loss: 2.0069, AE Loss: 0.6304\n",
            "Epoch 2, D Loss: 0.2367, G Loss: 1.8836, AE Loss: 0.4949\n",
            "Epoch 2, D Loss: 0.7404, G Loss: 1.9635, AE Loss: 0.4932\n",
            "Epoch 2, D Loss: 0.1855, G Loss: 2.0819, AE Loss: 0.5924\n",
            "Epoch 2, D Loss: 0.2564, G Loss: 1.8914, AE Loss: 0.4998\n",
            "Epoch 2, D Loss: 0.7214, G Loss: 1.9557, AE Loss: 0.5716\n",
            "Epoch 2, D Loss: 0.2622, G Loss: 1.9622, AE Loss: 0.4298\n",
            "Epoch 2, D Loss: 0.4247, G Loss: 1.9189, AE Loss: 0.4110\n",
            "Epoch 2, D Loss: 0.3617, G Loss: 1.8098, AE Loss: 0.5734\n",
            "Epoch 2, D Loss: 0.3681, G Loss: 2.2059, AE Loss: 0.4507\n",
            "Epoch 2, D Loss: 0.3029, G Loss: 1.8943, AE Loss: 0.6155\n",
            "Epoch 2, D Loss: 0.3008, G Loss: 2.0118, AE Loss: 0.6139\n",
            "Epoch 2, D Loss: 0.7600, G Loss: 1.9020, AE Loss: 0.4478\n",
            "Epoch 2, D Loss: 0.6350, G Loss: 1.9864, AE Loss: 0.5340\n",
            "Epoch 2, D Loss: 0.2810, G Loss: 2.0075, AE Loss: 0.5818\n",
            "Epoch 2, D Loss: 0.3063, G Loss: 1.9089, AE Loss: 0.5513\n",
            "Epoch 2, D Loss: 0.7932, G Loss: 1.8873, AE Loss: 0.3511\n",
            "Epoch 2, D Loss: 0.4556, G Loss: 1.9687, AE Loss: 0.4535\n",
            "Epoch 2, D Loss: 0.3583, G Loss: 1.9656, AE Loss: 0.4717\n",
            "Epoch 2, D Loss: 0.3343, G Loss: 1.9576, AE Loss: 0.6307\n",
            "Epoch 2, D Loss: 0.8889, G Loss: 1.9827, AE Loss: 0.5036\n",
            "Epoch 2, D Loss: 0.4383, G Loss: 1.8599, AE Loss: 0.5695\n",
            "Epoch 2, D Loss: 0.4693, G Loss: 1.9641, AE Loss: 0.4853\n",
            "Epoch 2, D Loss: 0.3270, G Loss: 2.1447, AE Loss: 0.5253\n",
            "Epoch 2, D Loss: 0.5742, G Loss: 1.8156, AE Loss: 0.5206\n",
            "Epoch 2, D Loss: 0.3884, G Loss: 1.9193, AE Loss: 0.5464\n",
            "Epoch 2, D Loss: 0.3213, G Loss: 2.0132, AE Loss: 0.5355\n",
            "Epoch 2, D Loss: 0.6278, G Loss: 1.9594, AE Loss: 0.5529\n",
            "Epoch 2, D Loss: 0.7134, G Loss: 1.9694, AE Loss: 0.5857\n",
            "Epoch 2, D Loss: 0.5932, G Loss: 1.9479, AE Loss: 0.4840\n",
            "Epoch 2, D Loss: 0.5297, G Loss: 1.8873, AE Loss: 0.5498\n",
            "Epoch 2, D Loss: 0.2196, G Loss: 1.8401, AE Loss: 0.6078\n",
            "Epoch 2, D Loss: 0.2097, G Loss: 1.9577, AE Loss: 0.5157\n",
            "Epoch 2, D Loss: 0.3184, G Loss: 2.0005, AE Loss: 0.6774\n",
            "Epoch 2, D Loss: 0.6453, G Loss: 2.0479, AE Loss: 0.5793\n",
            "Epoch 2, D Loss: 0.3303, G Loss: 2.0650, AE Loss: 0.6073\n",
            "Epoch 2, D Loss: 0.3522, G Loss: 1.9226, AE Loss: 0.5267\n",
            "Epoch 2, D Loss: 0.2040, G Loss: 2.0853, AE Loss: 0.6668\n",
            "Epoch 2, D Loss: 0.5036, G Loss: 2.0095, AE Loss: 0.5336\n",
            "Epoch 2, D Loss: 0.4869, G Loss: 2.0883, AE Loss: 0.5027\n",
            "Epoch 2, D Loss: 0.3533, G Loss: 1.9914, AE Loss: 0.5697\n",
            "Epoch 2, D Loss: 0.5992, G Loss: 2.0830, AE Loss: 0.3295\n",
            "Epoch 2, D Loss: 0.7232, G Loss: 2.1278, AE Loss: 0.5450\n",
            "Epoch 2, D Loss: 0.5376, G Loss: 2.0434, AE Loss: 0.6000\n",
            "Epoch 2, D Loss: 0.5997, G Loss: 2.0355, AE Loss: 0.7865\n",
            "Epoch 2, D Loss: 0.4347, G Loss: 2.0722, AE Loss: 0.5433\n",
            "Epoch 2, D Loss: 0.4125, G Loss: 2.0981, AE Loss: 0.5943\n",
            "Epoch 2, D Loss: 0.4098, G Loss: 2.0535, AE Loss: 0.6240\n",
            "Epoch 2, D Loss: 0.2645, G Loss: 2.1529, AE Loss: 0.5404\n",
            "Epoch 2, D Loss: 0.1771, G Loss: 2.0780, AE Loss: 0.5146\n",
            "Epoch 2, D Loss: 0.2942, G Loss: 2.0899, AE Loss: 0.7037\n",
            "Epoch 2, D Loss: 0.2795, G Loss: 2.0622, AE Loss: 0.5081\n",
            "Epoch 2, D Loss: 0.3759, G Loss: 1.9419, AE Loss: 0.4802\n",
            "Epoch 2, D Loss: 0.2168, G Loss: 1.8540, AE Loss: 0.5515\n",
            "Epoch 2, D Loss: 0.4770, G Loss: 2.0677, AE Loss: 0.5608\n",
            "Epoch 2, D Loss: 0.1928, G Loss: 2.0306, AE Loss: 0.4903\n",
            "Epoch 2, D Loss: 0.3771, G Loss: 2.0103, AE Loss: 0.7722\n",
            "Epoch 2, D Loss: 0.7306, G Loss: 1.9886, AE Loss: 0.6096\n",
            "Epoch 2, D Loss: 0.5069, G Loss: 1.9588, AE Loss: 0.4839\n",
            "Epoch 2, D Loss: 0.3884, G Loss: 1.9581, AE Loss: 0.4065\n",
            "Epoch 2, D Loss: 0.5413, G Loss: 2.0230, AE Loss: 0.5536\n",
            "Epoch 2, D Loss: 0.8499, G Loss: 1.7324, AE Loss: 0.4278\n",
            "Epoch 2, D Loss: 0.2247, G Loss: 1.8127, AE Loss: 0.6210\n",
            "Epoch 2, D Loss: 0.1958, G Loss: 1.8110, AE Loss: 0.5772\n",
            "Epoch 2, D Loss: 0.2272, G Loss: 1.8144, AE Loss: 0.5476\n",
            "Epoch 2, D Loss: 0.7125, G Loss: 1.7727, AE Loss: 0.5578\n",
            "Epoch 2, D Loss: 0.2191, G Loss: 1.8075, AE Loss: 0.6630\n",
            "Epoch 2, D Loss: 0.6214, G Loss: 1.8753, AE Loss: 0.5673\n",
            "Epoch 2, D Loss: 0.1889, G Loss: 1.8460, AE Loss: 0.6843\n",
            "Epoch 2, D Loss: 0.3253, G Loss: 1.8907, AE Loss: 0.5353\n",
            "Epoch 2, D Loss: 0.7136, G Loss: 1.9721, AE Loss: 0.5303\n",
            "Epoch 2, D Loss: 0.1911, G Loss: 1.9152, AE Loss: 0.4930\n",
            "Epoch 2, D Loss: 0.6032, G Loss: 1.9905, AE Loss: 0.5172\n",
            "Epoch 2, D Loss: 0.4053, G Loss: 1.9290, AE Loss: 0.4861\n",
            "Epoch 2, D Loss: 0.2291, G Loss: 1.9188, AE Loss: 0.6850\n",
            "Epoch 2, D Loss: 0.2939, G Loss: 1.9176, AE Loss: 0.4113\n",
            "Epoch 2, D Loss: 0.4467, G Loss: 1.9972, AE Loss: 0.5049\n",
            "Epoch 2, D Loss: 0.3635, G Loss: 2.1882, AE Loss: 0.5399\n",
            "Epoch 2, D Loss: 0.3070, G Loss: 2.0017, AE Loss: 0.6944\n",
            "Epoch 2, D Loss: 0.7674, G Loss: 2.0985, AE Loss: 0.4733\n",
            "Epoch 2, D Loss: 0.4761, G Loss: 2.1269, AE Loss: 0.5569\n",
            "Epoch 2, D Loss: 0.2302, G Loss: 2.0164, AE Loss: 0.4557\n",
            "Epoch 2, D Loss: 0.3014, G Loss: 2.0962, AE Loss: 0.5564\n",
            "Epoch 2, D Loss: 0.4985, G Loss: 2.1696, AE Loss: 0.5948\n",
            "Epoch 2, D Loss: 0.2130, G Loss: 2.2281, AE Loss: 0.5578\n",
            "Epoch 2, D Loss: 0.4370, G Loss: 2.1975, AE Loss: 0.6218\n",
            "Epoch 2, D Loss: 0.1906, G Loss: 2.1268, AE Loss: 0.5907\n",
            "Epoch 2, D Loss: 0.2975, G Loss: 2.2167, AE Loss: 0.5149\n",
            "Epoch 2, D Loss: 0.3599, G Loss: 2.2596, AE Loss: 0.6030\n",
            "Epoch 2, D Loss: 0.4607, G Loss: 2.2442, AE Loss: 0.5821\n",
            "Epoch 2, D Loss: 0.2750, G Loss: 2.1087, AE Loss: 0.7711\n",
            "Epoch 2, D Loss: 0.1906, G Loss: 2.2500, AE Loss: 0.6221\n",
            "Epoch 2, D Loss: 0.2567, G Loss: 2.4396, AE Loss: 0.4687\n",
            "Epoch 2, D Loss: 0.1481, G Loss: 2.2226, AE Loss: 0.5379\n",
            "Epoch 2, D Loss: 0.4538, G Loss: 2.4243, AE Loss: 0.5330\n",
            "Epoch 2, D Loss: 0.7653, G Loss: 2.3018, AE Loss: 0.5421\n",
            "Epoch 2, D Loss: 0.2066, G Loss: 2.3449, AE Loss: 0.5455\n",
            "Epoch 2, D Loss: 0.1773, G Loss: 2.4348, AE Loss: 0.5303\n",
            "Epoch 2, D Loss: 0.1367, G Loss: 2.3932, AE Loss: 0.5506\n",
            "Epoch 2, D Loss: 0.2432, G Loss: 2.3970, AE Loss: 0.6597\n",
            "Epoch 2, D Loss: 0.1904, G Loss: 2.3875, AE Loss: 0.5841\n",
            "Epoch 2, D Loss: 0.2846, G Loss: 2.3719, AE Loss: 0.4888\n",
            "Epoch 2, D Loss: 0.3056, G Loss: 2.4030, AE Loss: 0.7280\n",
            "Epoch 2, D Loss: 0.5673, G Loss: 2.3818, AE Loss: 0.6381\n",
            "Epoch 2, D Loss: 0.2040, G Loss: 2.4539, AE Loss: 0.4245\n",
            "Epoch 2, D Loss: 0.3156, G Loss: 2.4629, AE Loss: 0.5382\n",
            "Epoch 2, D Loss: 0.4190, G Loss: 2.4032, AE Loss: 0.6240\n",
            "Epoch 2, D Loss: 0.6110, G Loss: 2.3655, AE Loss: 0.5496\n",
            "Epoch 2, D Loss: 0.5984, G Loss: 2.4232, AE Loss: 0.6670\n",
            "Epoch 2, D Loss: 0.4782, G Loss: 2.4850, AE Loss: 0.5379\n",
            "Epoch 2, D Loss: 0.4621, G Loss: 2.3042, AE Loss: 0.4950\n",
            "Epoch 2, D Loss: 0.1785, G Loss: 2.6036, AE Loss: 0.5652\n",
            "Epoch 2, D Loss: 0.2332, G Loss: 2.3600, AE Loss: 0.5861\n",
            "Epoch 2, D Loss: 0.2503, G Loss: 2.3253, AE Loss: 0.6145\n",
            "Epoch 2, D Loss: 0.1458, G Loss: 2.3951, AE Loss: 0.6798\n",
            "Epoch 2, D Loss: 1.2583, G Loss: 2.3770, AE Loss: 0.4185\n",
            "Epoch 2, D Loss: 0.9338, G Loss: 2.2581, AE Loss: 0.5143\n",
            "Epoch 2, D Loss: 0.6616, G Loss: 2.3051, AE Loss: 0.5911\n",
            "Epoch 2, D Loss: 0.4196, G Loss: 2.2282, AE Loss: 0.5363\n",
            "Epoch 2, D Loss: 0.2897, G Loss: 2.2912, AE Loss: 0.4765\n",
            "Epoch 2, D Loss: 0.2606, G Loss: 2.1620, AE Loss: 0.5958\n",
            "Epoch 2, D Loss: 0.2641, G Loss: 2.2083, AE Loss: 0.5950\n",
            "Epoch 2, D Loss: 0.1352, G Loss: 2.1312, AE Loss: 0.4825\n",
            "Epoch 2, D Loss: 0.2130, G Loss: 2.1844, AE Loss: 0.7827\n",
            "Epoch 2, D Loss: 0.5731, G Loss: 2.0007, AE Loss: 0.5692\n",
            "Epoch 2, D Loss: 0.1448, G Loss: 2.1392, AE Loss: 0.5045\n",
            "Epoch 2, D Loss: 0.5372, G Loss: 2.0287, AE Loss: 0.8136\n",
            "Epoch 2, D Loss: 0.2421, G Loss: 2.1006, AE Loss: 0.4736\n",
            "Epoch 2, D Loss: 0.2987, G Loss: 2.0163, AE Loss: 0.6452\n",
            "Epoch 2, D Loss: 0.3059, G Loss: 2.1067, AE Loss: 0.6585\n",
            "Epoch 2, D Loss: 0.4518, G Loss: 2.0109, AE Loss: 0.4741\n",
            "Epoch 2, D Loss: 0.2303, G Loss: 1.9349, AE Loss: 0.6292\n",
            "Epoch 2, D Loss: 0.4030, G Loss: 2.0255, AE Loss: 0.5236\n",
            "Epoch 2, D Loss: 0.5720, G Loss: 1.9227, AE Loss: 0.4230\n",
            "Epoch 2, D Loss: 0.1879, G Loss: 1.8875, AE Loss: 0.4532\n",
            "Epoch 2, D Loss: 0.6747, G Loss: 1.7930, AE Loss: 0.5494\n",
            "Epoch 2, D Loss: 0.9133, G Loss: 1.6429, AE Loss: 0.4539\n",
            "Epoch 2, D Loss: 0.3608, G Loss: 1.6844, AE Loss: 0.4985\n",
            "Epoch 2, D Loss: 0.3171, G Loss: 1.6991, AE Loss: 0.5107\n",
            "Epoch 2, D Loss: 0.2821, G Loss: 1.6261, AE Loss: 0.5722\n",
            "Epoch 2, D Loss: 0.3351, G Loss: 1.5009, AE Loss: 0.3940\n",
            "Epoch 2, D Loss: 0.3256, G Loss: 1.4309, AE Loss: 0.5478\n",
            "Epoch 2, D Loss: 0.6728, G Loss: 1.6016, AE Loss: 0.6367\n",
            "Epoch 2, D Loss: 0.6236, G Loss: 1.3335, AE Loss: 0.5218\n",
            "Epoch 2, D Loss: 0.5526, G Loss: 1.4143, AE Loss: 0.5660\n",
            "Epoch 2, D Loss: 0.6021, G Loss: 1.3424, AE Loss: 0.6290\n",
            "Epoch 2, D Loss: 0.4716, G Loss: 1.1087, AE Loss: 0.6570\n",
            "Epoch 2, D Loss: 0.6054, G Loss: 1.2545, AE Loss: 0.5028\n",
            "Epoch 2, D Loss: 1.1030, G Loss: 1.2595, AE Loss: 0.5260\n",
            "Epoch 2, D Loss: 0.5291, G Loss: 1.4929, AE Loss: 0.5472\n",
            "Epoch 2, D Loss: 0.8976, G Loss: 1.4611, AE Loss: 0.5549\n",
            "Epoch 2, D Loss: 0.7489, G Loss: 1.1860, AE Loss: 0.4836\n",
            "Epoch 2, D Loss: 0.3722, G Loss: 1.3401, AE Loss: 0.5551\n",
            "Epoch 2, D Loss: 0.3127, G Loss: 1.5057, AE Loss: 0.7088\n",
            "Epoch 2, D Loss: 0.3931, G Loss: 1.3242, AE Loss: 0.5129\n",
            "Epoch 2, D Loss: 1.1978, G Loss: 1.2776, AE Loss: 0.6597\n",
            "Epoch 2, D Loss: 0.7277, G Loss: 1.2779, AE Loss: 0.4947\n",
            "Epoch 2, D Loss: 0.9538, G Loss: 1.3149, AE Loss: 0.5907\n",
            "Epoch 2, D Loss: 0.5981, G Loss: 1.3313, AE Loss: 0.5809\n",
            "Epoch 2, D Loss: 0.4592, G Loss: 1.3463, AE Loss: 0.5942\n",
            "Epoch 2, D Loss: 1.1350, G Loss: 1.3656, AE Loss: 0.4292\n",
            "Epoch 2, D Loss: 0.6233, G Loss: 1.2957, AE Loss: 0.6038\n",
            "Epoch 2, D Loss: 0.4611, G Loss: 1.3176, AE Loss: 0.6913\n",
            "Epoch 2, D Loss: 1.3740, G Loss: 1.2998, AE Loss: 0.4870\n",
            "Epoch 2, D Loss: 0.5174, G Loss: 1.2425, AE Loss: 0.5334\n",
            "Epoch 2, D Loss: 0.7886, G Loss: 1.0572, AE Loss: 0.2921\n",
            "Epoch 2, D Loss: 0.9430, G Loss: 1.2270, AE Loss: 0.6185\n",
            "Epoch 2, D Loss: 0.4402, G Loss: 1.2218, AE Loss: 0.5430\n",
            "Epoch 2, D Loss: 0.3783, G Loss: 1.3630, AE Loss: 0.5896\n",
            "Epoch 2, D Loss: 1.0368, G Loss: 1.3471, AE Loss: 0.6977\n",
            "Epoch 2, D Loss: 0.3647, G Loss: 1.4786, AE Loss: 0.6457\n",
            "Epoch 2, D Loss: 0.6829, G Loss: 1.3420, AE Loss: 0.7014\n",
            "Epoch 2, D Loss: 0.7449, G Loss: 1.6701, AE Loss: 0.6429\n",
            "Epoch 2, D Loss: 0.7401, G Loss: 1.4278, AE Loss: 0.7288\n",
            "Epoch 2, D Loss: 0.7248, G Loss: 1.7904, AE Loss: 0.5701\n",
            "Epoch 2, D Loss: 0.4255, G Loss: 1.7031, AE Loss: 0.5070\n",
            "Epoch 2, D Loss: 0.9987, G Loss: 1.7794, AE Loss: 0.4951\n",
            "Epoch 2, D Loss: 0.4745, G Loss: 1.6528, AE Loss: 0.4728\n",
            "Epoch 2, D Loss: 0.3355, G Loss: 1.9178, AE Loss: 0.6110\n",
            "Epoch 2, D Loss: 0.8206, G Loss: 1.7664, AE Loss: 0.5369\n",
            "Epoch 2, D Loss: 0.5760, G Loss: 1.8961, AE Loss: 0.4779\n",
            "Epoch 2, D Loss: 0.6792, G Loss: 1.7216, AE Loss: 0.5270\n",
            "Epoch 2, D Loss: 0.3126, G Loss: 1.7162, AE Loss: 0.6090\n",
            "Epoch 2, D Loss: 1.8227, G Loss: 1.6831, AE Loss: 0.5727\n",
            "Epoch 2, D Loss: 0.3374, G Loss: 1.7278, AE Loss: 0.5732\n",
            "Epoch 2, D Loss: 0.5845, G Loss: 1.6790, AE Loss: 0.5339\n",
            "Epoch 2, D Loss: 0.7230, G Loss: 1.6539, AE Loss: 0.5390\n",
            "Epoch 2, D Loss: 0.3310, G Loss: 1.7387, AE Loss: 0.5190\n",
            "Epoch 2, D Loss: 0.4175, G Loss: 1.7253, AE Loss: 0.5453\n",
            "Epoch 2, D Loss: 0.8546, G Loss: 1.5711, AE Loss: 0.6168\n",
            "Epoch 2, D Loss: 0.5925, G Loss: 1.4706, AE Loss: 0.6676\n",
            "Epoch 2, D Loss: 0.7283, G Loss: 1.6398, AE Loss: 0.4747\n",
            "Epoch 2, D Loss: 0.5452, G Loss: 1.6123, AE Loss: 0.4335\n",
            "Epoch 2, D Loss: 1.7795, G Loss: 1.5594, AE Loss: 0.4829\n",
            "Epoch 2, D Loss: 0.5291, G Loss: 1.6047, AE Loss: 0.5365\n",
            "Epoch 2, D Loss: 0.4498, G Loss: 1.5218, AE Loss: 0.5117\n",
            "Epoch 2, D Loss: 1.1818, G Loss: 1.5094, AE Loss: 0.5875\n",
            "Epoch 2, D Loss: 0.8926, G Loss: 1.5551, AE Loss: 0.3680\n",
            "Epoch 2, D Loss: 1.3189, G Loss: 1.5582, AE Loss: 0.5294\n",
            "Epoch 2, D Loss: 2.3206, G Loss: 1.4776, AE Loss: 0.6109\n",
            "Epoch 2, D Loss: 0.4938, G Loss: 1.6414, AE Loss: 0.4705\n",
            "Epoch 2, D Loss: 0.8664, G Loss: 1.5249, AE Loss: 0.4677\n",
            "Epoch 2, D Loss: 0.7249, G Loss: 1.4974, AE Loss: 0.6173\n",
            "Epoch 2, D Loss: 0.4186, G Loss: 1.5192, AE Loss: 0.7634\n",
            "Epoch 2, D Loss: 0.5644, G Loss: 1.5099, AE Loss: 0.5197\n",
            "Epoch 2, D Loss: 1.0861, G Loss: 1.5279, AE Loss: 0.4532\n",
            "Epoch 2, D Loss: 0.6372, G Loss: 1.5190, AE Loss: 0.5880\n",
            "Epoch 2, D Loss: 0.8550, G Loss: 1.5828, AE Loss: 0.4278\n",
            "Epoch 2, D Loss: 1.9924, G Loss: 1.6216, AE Loss: 0.5115\n",
            "Epoch 2, D Loss: 0.5978, G Loss: 1.5362, AE Loss: 0.5802\n",
            "Epoch 2, D Loss: 0.3423, G Loss: 1.5464, AE Loss: 0.7142\n",
            "Epoch 2, D Loss: 0.9086, G Loss: 1.6585, AE Loss: 0.5571\n",
            "Epoch 2, D Loss: 0.6396, G Loss: 1.7098, AE Loss: 0.4091\n",
            "Epoch 2, D Loss: 1.0108, G Loss: 1.5361, AE Loss: 0.6023\n",
            "Epoch 2, D Loss: 0.2824, G Loss: 1.6026, AE Loss: 0.6047\n",
            "Epoch 2, D Loss: 1.3535, G Loss: 1.6005, AE Loss: 0.4750\n",
            "Epoch 2, D Loss: 0.8724, G Loss: 1.6859, AE Loss: 0.5117\n",
            "Epoch 2, D Loss: 0.8643, G Loss: 1.6188, AE Loss: 0.5626\n",
            "Epoch 2, D Loss: 1.2980, G Loss: 1.6313, AE Loss: 0.6002\n",
            "Epoch 2, D Loss: 1.4254, G Loss: 1.5126, AE Loss: 0.4944\n",
            "Epoch 2, D Loss: 0.5898, G Loss: 1.6768, AE Loss: 0.5147\n",
            "Epoch 2, D Loss: 0.9390, G Loss: 1.6883, AE Loss: 0.6592\n",
            "Epoch 2, D Loss: 1.0913, G Loss: 1.5626, AE Loss: 0.5610\n",
            "Epoch 2, D Loss: 0.5592, G Loss: 1.5168, AE Loss: 0.5507\n",
            "Epoch 2, D Loss: 1.2178, G Loss: 1.4754, AE Loss: 0.6306\n",
            "Epoch 2, D Loss: 0.4923, G Loss: 1.6195, AE Loss: 0.5342\n",
            "Epoch 2, D Loss: 0.7558, G Loss: 1.6281, AE Loss: 0.4368\n",
            "Epoch 2, D Loss: 0.6256, G Loss: 1.5502, AE Loss: 0.6183\n",
            "Epoch 2, D Loss: 0.3776, G Loss: 1.5737, AE Loss: 0.4192\n",
            "Epoch 2, D Loss: 0.3834, G Loss: 1.4412, AE Loss: 0.6323\n",
            "Epoch 2, D Loss: 1.3233, G Loss: 1.6692, AE Loss: 0.5545\n",
            "Epoch 2, D Loss: 1.1260, G Loss: 1.6345, AE Loss: 0.5500\n",
            "Epoch 2, D Loss: 0.9661, G Loss: 1.6265, AE Loss: 0.6278\n",
            "Epoch 2, D Loss: 1.0256, G Loss: 1.5006, AE Loss: 0.6399\n",
            "Epoch 2, D Loss: 0.3174, G Loss: 1.4321, AE Loss: 0.4472\n",
            "Epoch 2, D Loss: 0.7130, G Loss: 1.4781, AE Loss: 0.5559\n",
            "Epoch 2, D Loss: 0.6507, G Loss: 1.6111, AE Loss: 0.6114\n",
            "Epoch 2, D Loss: 1.5319, G Loss: 1.7293, AE Loss: 0.5360\n",
            "Epoch 2, D Loss: 0.3517, G Loss: 1.7544, AE Loss: 0.4725\n",
            "Epoch 2, D Loss: 1.1546, G Loss: 1.5823, AE Loss: 0.5920\n",
            "Epoch 2, D Loss: 0.5001, G Loss: 1.7404, AE Loss: 0.6779\n",
            "Epoch 2, D Loss: 0.2981, G Loss: 1.4927, AE Loss: 0.6022\n",
            "Epoch 2, D Loss: 0.8142, G Loss: 1.5032, AE Loss: 0.5456\n",
            "Epoch 2, D Loss: 0.4446, G Loss: 1.7336, AE Loss: 0.5176\n",
            "Epoch 2, D Loss: 1.1152, G Loss: 1.6275, AE Loss: 0.5728\n",
            "Epoch 2, D Loss: 0.6385, G Loss: 1.7440, AE Loss: 0.6098\n",
            "Epoch 2, D Loss: 0.3968, G Loss: 1.6855, AE Loss: 0.5075\n",
            "Epoch 2, D Loss: 0.2600, G Loss: 1.6468, AE Loss: 0.4179\n",
            "Epoch 2, D Loss: 1.0942, G Loss: 1.6511, AE Loss: 0.4376\n",
            "Epoch 2, D Loss: 0.3609, G Loss: 1.7763, AE Loss: 0.7350\n",
            "Epoch 2, D Loss: 0.2765, G Loss: 1.7258, AE Loss: 0.5987\n",
            "Epoch 2, D Loss: 0.7859, G Loss: 1.7354, AE Loss: 0.5581\n",
            "Epoch 2, D Loss: 0.9303, G Loss: 1.7495, AE Loss: 0.4577\n",
            "Epoch 2, D Loss: 0.6181, G Loss: 1.7041, AE Loss: 0.5469\n",
            "Epoch 2, D Loss: 1.4427, G Loss: 1.8149, AE Loss: 0.4375\n",
            "Epoch 2, D Loss: 0.4695, G Loss: 1.7937, AE Loss: 0.4735\n",
            "Epoch 2, D Loss: 0.6761, G Loss: 1.7996, AE Loss: 0.5426\n",
            "Epoch 2, D Loss: 0.8443, G Loss: 1.9401, AE Loss: 0.5861\n",
            "Epoch 2, D Loss: 0.4910, G Loss: 1.9556, AE Loss: 0.6403\n",
            "Epoch 2, D Loss: 0.8014, G Loss: 1.9911, AE Loss: 0.5753\n",
            "Epoch 2, D Loss: 1.0291, G Loss: 1.9844, AE Loss: 0.4501\n",
            "Epoch 2, D Loss: 0.2862, G Loss: 1.9871, AE Loss: 0.4086\n",
            "Epoch 2, D Loss: 0.9450, G Loss: 1.9729, AE Loss: 0.4379\n",
            "Epoch 2, D Loss: 0.4615, G Loss: 2.0987, AE Loss: 0.5518\n",
            "Epoch 2, D Loss: 1.1686, G Loss: 2.2393, AE Loss: 0.5609\n",
            "Epoch 2, D Loss: 0.9144, G Loss: 2.1400, AE Loss: 0.5622\n",
            "Epoch 2, D Loss: 1.3231, G Loss: 2.1487, AE Loss: 0.5490\n",
            "Epoch 2, D Loss: 0.7450, G Loss: 2.1442, AE Loss: 0.4675\n",
            "Epoch 2, D Loss: 0.7567, G Loss: 2.0049, AE Loss: 0.4909\n",
            "Epoch 2, D Loss: 0.2336, G Loss: 2.1012, AE Loss: 0.5865\n",
            "Epoch 2, D Loss: 0.5570, G Loss: 2.0481, AE Loss: 0.5014\n",
            "Epoch 2, D Loss: 0.9357, G Loss: 2.1208, AE Loss: 0.5516\n",
            "Epoch 2, D Loss: 0.7316, G Loss: 2.0410, AE Loss: 0.5334\n",
            "Epoch 2, D Loss: 0.9352, G Loss: 2.0872, AE Loss: 0.5184\n",
            "Epoch 2, D Loss: 0.1460, G Loss: 2.2025, AE Loss: 0.5693\n",
            "Epoch 2, D Loss: 0.4940, G Loss: 2.0439, AE Loss: 0.6409\n",
            "Epoch 2, D Loss: 0.4078, G Loss: 2.1124, AE Loss: 0.5604\n",
            "Epoch 2, D Loss: 0.9967, G Loss: 2.1206, AE Loss: 0.4996\n",
            "Epoch 2, D Loss: 0.2647, G Loss: 1.9637, AE Loss: 0.6009\n",
            "Epoch 2, D Loss: 0.7374, G Loss: 2.0069, AE Loss: 0.4890\n",
            "Epoch 2, D Loss: 1.0470, G Loss: 2.0301, AE Loss: 0.5574\n",
            "Epoch 2, D Loss: 0.8863, G Loss: 1.8876, AE Loss: 0.4373\n",
            "Epoch 2, D Loss: 1.6269, G Loss: 2.1726, AE Loss: 0.6319\n",
            "Epoch 2, D Loss: 0.4999, G Loss: 1.9638, AE Loss: 0.4583\n",
            "Epoch 2, D Loss: 0.2047, G Loss: 1.8816, AE Loss: 0.6578\n",
            "Epoch 2, D Loss: 0.3699, G Loss: 1.9863, AE Loss: 0.4869\n",
            "Epoch 2, D Loss: 0.3129, G Loss: 1.8417, AE Loss: 0.5399\n",
            "Epoch 2, D Loss: 0.8708, G Loss: 1.8301, AE Loss: 0.5318\n",
            "Epoch 2, D Loss: 0.5358, G Loss: 1.8423, AE Loss: 0.5228\n",
            "Epoch 2, D Loss: 0.9417, G Loss: 1.8905, AE Loss: 0.5193\n",
            "Epoch 2, D Loss: 0.3143, G Loss: 1.8333, AE Loss: 0.5161\n",
            "Epoch 2, D Loss: 0.7830, G Loss: 1.7182, AE Loss: 0.6231\n",
            "Epoch 2, D Loss: 0.4768, G Loss: 1.7301, AE Loss: 0.5240\n",
            "Epoch 2, D Loss: 0.8218, G Loss: 1.8225, AE Loss: 0.5084\n",
            "Epoch 2, D Loss: 0.4421, G Loss: 1.9176, AE Loss: 0.5190\n",
            "Epoch 2, D Loss: 0.2805, G Loss: 1.6815, AE Loss: 0.5128\n",
            "Epoch 2, D Loss: 0.5763, G Loss: 1.7087, AE Loss: 0.5336\n",
            "Epoch 2, D Loss: 0.2898, G Loss: 1.8877, AE Loss: 0.5297\n",
            "Epoch 2, D Loss: 0.3021, G Loss: 1.9237, AE Loss: 0.5666\n",
            "Epoch 2, D Loss: 1.0773, G Loss: 1.8604, AE Loss: 0.5794\n",
            "Epoch 2, D Loss: 0.5268, G Loss: 1.9204, AE Loss: 0.5869\n",
            "Epoch 2, D Loss: 0.3131, G Loss: 1.6877, AE Loss: 0.5819\n",
            "Epoch 2, D Loss: 0.2767, G Loss: 2.0017, AE Loss: 0.5466\n",
            "Epoch 2, D Loss: 0.6082, G Loss: 1.6749, AE Loss: 0.4811\n",
            "Epoch 2, D Loss: 0.7908, G Loss: 1.6828, AE Loss: 0.5350\n",
            "Epoch 2, D Loss: 0.4447, G Loss: 1.9178, AE Loss: 0.5719\n",
            "Epoch 2, D Loss: 1.0761, G Loss: 1.8796, AE Loss: 0.6320\n",
            "Epoch 2, D Loss: 0.6631, G Loss: 1.9227, AE Loss: 0.6202\n",
            "Epoch 2, D Loss: 0.3155, G Loss: 1.7640, AE Loss: 0.6270\n",
            "Epoch 2, D Loss: 0.5162, G Loss: 1.7095, AE Loss: 0.7094\n",
            "Epoch 2, D Loss: 0.6153, G Loss: 1.5815, AE Loss: 0.6186\n",
            "Epoch 2, D Loss: 0.7967, G Loss: 1.7225, AE Loss: 0.4935\n",
            "Epoch 2, D Loss: 0.5111, G Loss: 1.8321, AE Loss: 0.3891\n",
            "Epoch 2, D Loss: 0.3946, G Loss: 1.7854, AE Loss: 0.5108\n",
            "Epoch 2, D Loss: 0.8911, G Loss: 1.9936, AE Loss: 0.4678\n",
            "Epoch 2, D Loss: 0.3167, G Loss: 1.9671, AE Loss: 0.5545\n",
            "Epoch 2, D Loss: 0.6981, G Loss: 1.5289, AE Loss: 0.5488\n",
            "Epoch 2, D Loss: 0.2826, G Loss: 1.7627, AE Loss: 0.7374\n",
            "Epoch 2, D Loss: 0.7015, G Loss: 1.8950, AE Loss: 0.5878\n",
            "Epoch 2, D Loss: 0.5694, G Loss: 1.6190, AE Loss: 0.6484\n",
            "Epoch 2, D Loss: 0.9526, G Loss: 1.8159, AE Loss: 0.5108\n",
            "Epoch 2, D Loss: 0.2932, G Loss: 1.6804, AE Loss: 0.5856\n",
            "Epoch 2, D Loss: 0.8784, G Loss: 1.7676, AE Loss: 0.4937\n",
            "Epoch 2, D Loss: 1.1589, G Loss: 1.7652, AE Loss: 0.6354\n",
            "Epoch 2, D Loss: 0.3410, G Loss: 1.7223, AE Loss: 0.5174\n",
            "Epoch 2, D Loss: 1.1427, G Loss: 1.6491, AE Loss: 0.6166\n",
            "Epoch 2, D Loss: 0.3432, G Loss: 1.7079, AE Loss: 0.6947\n",
            "Epoch 2, D Loss: 0.8826, G Loss: 1.5981, AE Loss: 0.3805\n",
            "Epoch 2, D Loss: 1.5152, G Loss: 1.6822, AE Loss: 0.5337\n",
            "Epoch 2, D Loss: 1.0216, G Loss: 1.4752, AE Loss: 0.5670\n",
            "Epoch 2, D Loss: 0.3902, G Loss: 1.6123, AE Loss: 0.5009\n",
            "Epoch 2, D Loss: 0.9109, G Loss: 1.6282, AE Loss: 0.4702\n",
            "Epoch 2, D Loss: 0.7250, G Loss: 1.4195, AE Loss: 0.4966\n",
            "Epoch 2, D Loss: 0.6747, G Loss: 1.3723, AE Loss: 0.4907\n",
            "Epoch 2, D Loss: 1.1811, G Loss: 1.5409, AE Loss: 0.5664\n",
            "Epoch 2, D Loss: 0.8057, G Loss: 1.4756, AE Loss: 0.6254\n",
            "Epoch 2, D Loss: 0.5938, G Loss: 1.5135, AE Loss: 0.5893\n",
            "Epoch 2, D Loss: 0.9869, G Loss: 1.7437, AE Loss: 0.5251\n",
            "Epoch 2, D Loss: 1.1608, G Loss: 1.6124, AE Loss: 0.4558\n",
            "Epoch 2, D Loss: 0.7484, G Loss: 1.6574, AE Loss: 0.6307\n",
            "Epoch 2, D Loss: 1.3192, G Loss: 1.4855, AE Loss: 0.6046\n",
            "Epoch 2, D Loss: 1.1223, G Loss: 1.7856, AE Loss: 0.6554\n",
            "Epoch 2, D Loss: 0.9321, G Loss: 1.2387, AE Loss: 0.4345\n",
            "Epoch 2, D Loss: 1.4980, G Loss: 1.5638, AE Loss: 0.6869\n",
            "Epoch 2, D Loss: 1.5592, G Loss: 1.7175, AE Loss: 0.5603\n",
            "Epoch 2, D Loss: 0.7371, G Loss: 1.6350, AE Loss: 0.5599\n",
            "Epoch 2, D Loss: 0.8587, G Loss: 1.8395, AE Loss: 0.6046\n",
            "Epoch 2, D Loss: 0.5140, G Loss: 1.4649, AE Loss: 0.5848\n",
            "Epoch 2, D Loss: 0.6749, G Loss: 1.7588, AE Loss: 0.5643\n",
            "Epoch 2, D Loss: 1.4328, G Loss: 1.4776, AE Loss: 0.4733\n",
            "Epoch 2, D Loss: 0.6005, G Loss: 1.5100, AE Loss: 0.5807\n",
            "Epoch 2, D Loss: 0.5492, G Loss: 1.5638, AE Loss: 0.5121\n",
            "Epoch 2, D Loss: 1.1530, G Loss: 1.6323, AE Loss: 0.6748\n",
            "Epoch 2, D Loss: 0.6239, G Loss: 1.7706, AE Loss: 0.5028\n",
            "Epoch 2, D Loss: 1.7335, G Loss: 1.4545, AE Loss: 0.5918\n",
            "Epoch 2, D Loss: 1.0937, G Loss: 1.3032, AE Loss: 0.4789\n",
            "Epoch 2, D Loss: 0.3218, G Loss: 1.7640, AE Loss: 0.5541\n",
            "Epoch 2, D Loss: 0.9691, G Loss: 1.4059, AE Loss: 0.5239\n",
            "Epoch 2, D Loss: 2.0559, G Loss: 1.4225, AE Loss: 0.7539\n",
            "Epoch 2, D Loss: 0.7138, G Loss: 1.5824, AE Loss: 0.5495\n",
            "Epoch 2, D Loss: 0.9674, G Loss: 1.5830, AE Loss: 0.5629\n",
            "Epoch 2, D Loss: 0.9647, G Loss: 1.2924, AE Loss: 0.4523\n",
            "Epoch 2, D Loss: 1.0826, G Loss: 1.3305, AE Loss: 0.4665\n",
            "Epoch 2, D Loss: 1.2460, G Loss: 1.6373, AE Loss: 0.4307\n",
            "Epoch 2, D Loss: 1.4308, G Loss: 1.5501, AE Loss: 0.6224\n",
            "Epoch 2, D Loss: 1.1472, G Loss: 1.3641, AE Loss: 0.6093\n",
            "Epoch 2, D Loss: 1.1690, G Loss: 1.1808, AE Loss: 0.5517\n",
            "Epoch 2, D Loss: 0.5842, G Loss: 1.4579, AE Loss: 0.4824\n",
            "Epoch 2, D Loss: 1.8025, G Loss: 1.3848, AE Loss: 0.5129\n",
            "Epoch 2, D Loss: 0.3449, G Loss: 1.8338, AE Loss: 0.4328\n",
            "Epoch 2, D Loss: 1.1063, G Loss: 1.9887, AE Loss: 0.5455\n",
            "Epoch 2, D Loss: 1.1291, G Loss: 1.5237, AE Loss: 0.5545\n",
            "Epoch 2, D Loss: 1.8930, G Loss: 1.5105, AE Loss: 0.4695\n",
            "Epoch 2, D Loss: 0.4959, G Loss: 1.4877, AE Loss: 0.4750\n",
            "Epoch 2, D Loss: 1.2933, G Loss: 1.5907, AE Loss: 0.5945\n",
            "Epoch 2, D Loss: 0.6883, G Loss: 1.9473, AE Loss: 0.5075\n",
            "Epoch 2, D Loss: 1.2388, G Loss: 1.6951, AE Loss: 0.5401\n",
            "Epoch 2, D Loss: 1.1653, G Loss: 1.8064, AE Loss: 0.5217\n",
            "Epoch 2, D Loss: 0.6676, G Loss: 1.7963, AE Loss: 0.4767\n",
            "Epoch 2, D Loss: 1.2628, G Loss: 1.5357, AE Loss: 0.4721\n",
            "Epoch 2, D Loss: 1.2199, G Loss: 1.4500, AE Loss: 0.5628\n",
            "Epoch 2, D Loss: 0.3111, G Loss: 1.7849, AE Loss: 0.5266\n",
            "Epoch 2, D Loss: 0.9532, G Loss: 1.3708, AE Loss: 0.6970\n",
            "Epoch 2, D Loss: 0.4644, G Loss: 1.7223, AE Loss: 0.4370\n",
            "Epoch 2, D Loss: 0.6211, G Loss: 1.9650, AE Loss: 0.6022\n",
            "Epoch 2, D Loss: 0.6542, G Loss: 1.6437, AE Loss: 0.6917\n",
            "Epoch 2, D Loss: 0.5432, G Loss: 2.0342, AE Loss: 0.6291\n",
            "Epoch 2, D Loss: 0.8895, G Loss: 1.5603, AE Loss: 0.5486\n",
            "Epoch 2, D Loss: 2.8184, G Loss: 1.9248, AE Loss: 0.5531\n",
            "Epoch 2, D Loss: 0.9758, G Loss: 1.5535, AE Loss: 0.6388\n",
            "Epoch 2, D Loss: 2.0297, G Loss: 1.9147, AE Loss: 0.5353\n",
            "Epoch 2, D Loss: 0.9862, G Loss: 1.8735, AE Loss: 0.5215\n",
            "Epoch 2, D Loss: 0.7311, G Loss: 1.7369, AE Loss: 0.7336\n",
            "Epoch 2, D Loss: 1.2494, G Loss: 1.6238, AE Loss: 0.4479\n",
            "Epoch 2, D Loss: 1.2088, G Loss: 1.4461, AE Loss: 0.6444\n",
            "Epoch 2, D Loss: 0.8763, G Loss: 1.5838, AE Loss: 0.5567\n",
            "Epoch 2, D Loss: 0.5331, G Loss: 1.5664, AE Loss: 0.5247\n",
            "Epoch 2, D Loss: 1.1423, G Loss: 1.4784, AE Loss: 0.5988\n",
            "Epoch 2, D Loss: 0.9474, G Loss: 1.5742, AE Loss: 0.5145\n",
            "Epoch 2, D Loss: 0.8687, G Loss: 1.2570, AE Loss: 0.5958\n",
            "Epoch 2, D Loss: 0.7837, G Loss: 1.3198, AE Loss: 0.4220\n",
            "Epoch 2, D Loss: 0.9165, G Loss: 1.5237, AE Loss: 0.9231\n",
            "Epoch 2, D Loss: 0.3834, G Loss: 1.4761, AE Loss: 0.6445\n",
            "Epoch 2, D Loss: 0.6354, G Loss: 1.4130, AE Loss: 0.5135\n",
            "Epoch 2, D Loss: 0.6220, G Loss: 1.5092, AE Loss: 0.4572\n",
            "Epoch 2, D Loss: 1.6487, G Loss: 1.4344, AE Loss: 0.5834\n",
            "Epoch 2, D Loss: 1.5048, G Loss: 1.6729, AE Loss: 0.4906\n",
            "Epoch 2, D Loss: 0.8655, G Loss: 1.3465, AE Loss: 0.5954\n",
            "Epoch 2, D Loss: 0.5490, G Loss: 1.4593, AE Loss: 0.4582\n",
            "Epoch 2, D Loss: 1.3297, G Loss: 1.5993, AE Loss: 0.5079\n",
            "Epoch 2, D Loss: 0.9408, G Loss: 1.1911, AE Loss: 0.5598\n",
            "Epoch 2, D Loss: 0.9613, G Loss: 1.3809, AE Loss: 0.4672\n",
            "Epoch 2, D Loss: 1.5639, G Loss: 1.4744, AE Loss: 0.4640\n",
            "Epoch 2, D Loss: 0.8558, G Loss: 1.4084, AE Loss: 0.5682\n",
            "Epoch 2, D Loss: 0.7403, G Loss: 1.3534, AE Loss: 0.5520\n",
            "Epoch 2, D Loss: 0.6702, G Loss: 1.4294, AE Loss: 0.5808\n",
            "Epoch 2, D Loss: 1.0843, G Loss: 1.4138, AE Loss: 0.4177\n",
            "Epoch 2, D Loss: 1.4444, G Loss: 1.3600, AE Loss: 0.6483\n",
            "Epoch 2, D Loss: 0.7717, G Loss: 1.5857, AE Loss: 0.6099\n",
            "Epoch 2, D Loss: 0.6533, G Loss: 1.6540, AE Loss: 0.4973\n",
            "Epoch 2, D Loss: 1.6500, G Loss: 1.6739, AE Loss: 0.4552\n",
            "Epoch 2, D Loss: 0.6442, G Loss: 1.8543, AE Loss: 0.4843\n",
            "Epoch 2, D Loss: 0.4768, G Loss: 1.7461, AE Loss: 0.3939\n",
            "Epoch 2, D Loss: 0.3830, G Loss: 2.1458, AE Loss: 0.5805\n",
            "Epoch 2, D Loss: 0.8332, G Loss: 1.8491, AE Loss: 0.4451\n",
            "Epoch 2, D Loss: 0.6571, G Loss: 2.1552, AE Loss: 0.6534\n",
            "Epoch 2, D Loss: 0.4876, G Loss: 1.8669, AE Loss: 0.6433\n",
            "Epoch 2, D Loss: 1.6933, G Loss: 2.1114, AE Loss: 0.5856\n",
            "Epoch 2, D Loss: 0.7331, G Loss: 2.0169, AE Loss: 0.4933\n",
            "Epoch 2, D Loss: 0.4484, G Loss: 1.6986, AE Loss: 0.5385\n",
            "Epoch 2, D Loss: 1.0302, G Loss: 1.7099, AE Loss: 0.4942\n",
            "Epoch 2, D Loss: 1.0273, G Loss: 1.6815, AE Loss: 0.5167\n",
            "Epoch 2, D Loss: 0.8920, G Loss: 1.3983, AE Loss: 0.6049\n",
            "Epoch 2, D Loss: 0.9415, G Loss: 1.8024, AE Loss: 0.6212\n",
            "Epoch 2, D Loss: 0.6255, G Loss: 1.8887, AE Loss: 0.6655\n",
            "Epoch 2, D Loss: 0.4120, G Loss: 1.6677, AE Loss: 0.5962\n",
            "Epoch 2, D Loss: 0.5502, G Loss: 1.9280, AE Loss: 0.5406\n",
            "Epoch 2, D Loss: 0.7071, G Loss: 1.8383, AE Loss: 0.6136\n",
            "Epoch 2, D Loss: 0.8121, G Loss: 1.7040, AE Loss: 0.6247\n",
            "Epoch 2, D Loss: 1.1998, G Loss: 1.6771, AE Loss: 0.5661\n",
            "Epoch 2, D Loss: 0.9752, G Loss: 1.5920, AE Loss: 0.6698\n",
            "Epoch 2, D Loss: 0.6735, G Loss: 1.8093, AE Loss: 0.5123\n",
            "Epoch 2, D Loss: 0.5083, G Loss: 1.6858, AE Loss: 0.4587\n",
            "Epoch 2, D Loss: 1.1630, G Loss: 1.7509, AE Loss: 0.4465\n",
            "Epoch 2, D Loss: 0.3973, G Loss: 1.6944, AE Loss: 0.6435\n",
            "Epoch 2, D Loss: 1.4034, G Loss: 1.5472, AE Loss: 0.5285\n",
            "Epoch 2, D Loss: 1.2869, G Loss: 1.5584, AE Loss: 0.5380\n",
            "Epoch 2, D Loss: 1.0105, G Loss: 1.6148, AE Loss: 0.5850\n",
            "Epoch 2, D Loss: 1.2302, G Loss: 1.7350, AE Loss: 0.5307\n",
            "Epoch 2, D Loss: 1.8210, G Loss: 1.6348, AE Loss: 0.4942\n",
            "Epoch 2, D Loss: 1.2922, G Loss: 1.8454, AE Loss: 0.6259\n",
            "Epoch 2, D Loss: 1.3015, G Loss: 1.8387, AE Loss: 0.5172\n",
            "Epoch 2, D Loss: 0.7828, G Loss: 1.6367, AE Loss: 0.5474\n",
            "Epoch 2, D Loss: 1.4025, G Loss: 1.7504, AE Loss: 0.5537\n",
            "Epoch 2, D Loss: 0.8686, G Loss: 1.6258, AE Loss: 0.4690\n",
            "Epoch 2, D Loss: 0.8393, G Loss: 1.8474, AE Loss: 0.6099\n",
            "Epoch 2, D Loss: 0.6422, G Loss: 1.3043, AE Loss: 0.5091\n",
            "Epoch 2, D Loss: 0.5954, G Loss: 1.5224, AE Loss: 0.5666\n",
            "Epoch 2, D Loss: 1.2137, G Loss: 1.3431, AE Loss: 0.5475\n",
            "Epoch 2, D Loss: 0.3571, G Loss: 1.7351, AE Loss: 0.6330\n",
            "Epoch 2, D Loss: 1.0500, G Loss: 1.5145, AE Loss: 0.5558\n",
            "Epoch 2, D Loss: 0.7062, G Loss: 1.6745, AE Loss: 0.5046\n",
            "Epoch 2, D Loss: 0.9735, G Loss: 1.8320, AE Loss: 0.7520\n",
            "Epoch 2, D Loss: 0.7636, G Loss: 1.5845, AE Loss: 0.6596\n",
            "Epoch 2, D Loss: 1.2014, G Loss: 1.5876, AE Loss: 0.4914\n",
            "Epoch 2, D Loss: 0.3086, G Loss: 1.6378, AE Loss: 0.4083\n",
            "Epoch 2, D Loss: 1.0458, G Loss: 1.5985, AE Loss: 0.5506\n",
            "Epoch 2, D Loss: 0.7492, G Loss: 1.7526, AE Loss: 0.5234\n",
            "Epoch 2, D Loss: 1.1900, G Loss: 1.7094, AE Loss: 0.5060\n",
            "Epoch 2, D Loss: 1.9294, G Loss: 1.5644, AE Loss: 0.6763\n",
            "Epoch 2, D Loss: 1.5852, G Loss: 1.7436, AE Loss: 0.4136\n",
            "Epoch 2, D Loss: 1.2048, G Loss: 1.7135, AE Loss: 0.6107\n",
            "Epoch 2, D Loss: 0.4143, G Loss: 1.5498, AE Loss: 0.5401\n",
            "Epoch 2, D Loss: 0.4913, G Loss: 1.7306, AE Loss: 0.5402\n",
            "Epoch 2, D Loss: 0.8307, G Loss: 1.9118, AE Loss: 0.5199\n",
            "Epoch 2, D Loss: 1.3460, G Loss: 1.6335, AE Loss: 0.5746\n",
            "Epoch 2, D Loss: 0.7598, G Loss: 1.8982, AE Loss: 0.6462\n",
            "Epoch 2, D Loss: 0.8999, G Loss: 1.7363, AE Loss: 0.5750\n",
            "Epoch 2, D Loss: 0.7636, G Loss: 1.5319, AE Loss: 0.6136\n",
            "Epoch 2, D Loss: 1.2192, G Loss: 1.6164, AE Loss: 0.5447\n",
            "Epoch 2, D Loss: 0.2284, G Loss: 1.9639, AE Loss: 0.6061\n",
            "Epoch 2, D Loss: 0.3468, G Loss: 1.7887, AE Loss: 0.6194\n",
            "Epoch 2, D Loss: 1.4154, G Loss: 1.7167, AE Loss: 0.5255\n",
            "Epoch 2, D Loss: 1.0304, G Loss: 1.7071, AE Loss: 0.6569\n",
            "Epoch 2, D Loss: 0.9704, G Loss: 1.9457, AE Loss: 0.6530\n",
            "Epoch 2, D Loss: 0.3641, G Loss: 2.0077, AE Loss: 0.5999\n",
            "Epoch 2, D Loss: 1.6284, G Loss: 1.8571, AE Loss: 0.5289\n",
            "Epoch 2, D Loss: 0.7694, G Loss: 1.9427, AE Loss: 0.3999\n",
            "Epoch 2, D Loss: 1.5142, G Loss: 1.7686, AE Loss: 0.6104\n",
            "Epoch 2, D Loss: 1.0077, G Loss: 1.8248, AE Loss: 0.5285\n",
            "Epoch 2, D Loss: 0.8394, G Loss: 1.8361, AE Loss: 0.4873\n",
            "Epoch 2, D Loss: 0.2899, G Loss: 2.2434, AE Loss: 0.5786\n",
            "Epoch 2, D Loss: 0.8014, G Loss: 1.7626, AE Loss: 0.5394\n",
            "Epoch 2, D Loss: 1.0720, G Loss: 1.6830, AE Loss: 0.5300\n",
            "Epoch 2, D Loss: 0.6727, G Loss: 1.8902, AE Loss: 0.5584\n",
            "Epoch 2, D Loss: 0.4432, G Loss: 2.0827, AE Loss: 0.5791\n",
            "Epoch 2, D Loss: 0.3309, G Loss: 2.1769, AE Loss: 0.4799\n",
            "Epoch 2, D Loss: 1.4827, G Loss: 1.9033, AE Loss: 0.5697\n",
            "Epoch 2, D Loss: 1.3713, G Loss: 1.8554, AE Loss: 0.5204\n",
            "Epoch 2, D Loss: 0.3898, G Loss: 1.8042, AE Loss: 0.4765\n",
            "Epoch 2, D Loss: 0.6294, G Loss: 1.8432, AE Loss: 0.6052\n",
            "Epoch 2, D Loss: 0.6274, G Loss: 1.8572, AE Loss: 0.6784\n",
            "Epoch 2, D Loss: 2.0528, G Loss: 1.8083, AE Loss: 0.4838\n",
            "Epoch 2, D Loss: 0.9345, G Loss: 1.7880, AE Loss: 0.5010\n",
            "Epoch 2, D Loss: 0.3275, G Loss: 1.5938, AE Loss: 0.5208\n",
            "Epoch 2, D Loss: 0.6624, G Loss: 1.6912, AE Loss: 0.5888\n",
            "Epoch 2, D Loss: 1.4864, G Loss: 1.5887, AE Loss: 0.5482\n",
            "Epoch 2, D Loss: 0.7043, G Loss: 1.6526, AE Loss: 0.6787\n",
            "Epoch 2, D Loss: 0.9076, G Loss: 1.9768, AE Loss: 0.6222\n",
            "Epoch 2, D Loss: 1.9925, G Loss: 1.6420, AE Loss: 0.5262\n",
            "Epoch 2, D Loss: 1.9997, G Loss: 1.6418, AE Loss: 0.5438\n",
            "Epoch 2, D Loss: 0.6578, G Loss: 1.7233, AE Loss: 0.5465\n",
            "Epoch 2, D Loss: 0.8505, G Loss: 1.5840, AE Loss: 0.4761\n",
            "Epoch 2, D Loss: 1.0777, G Loss: 1.4981, AE Loss: 0.6770\n",
            "Epoch 2, D Loss: 2.0528, G Loss: 1.7015, AE Loss: 0.5360\n",
            "Epoch 2, D Loss: 1.6406, G Loss: 1.8243, AE Loss: 0.4732\n",
            "Epoch 2, D Loss: 0.6155, G Loss: 1.6107, AE Loss: 0.5798\n",
            "Epoch 2, D Loss: 0.4638, G Loss: 1.6828, AE Loss: 0.5029\n",
            "Epoch 2, D Loss: 0.9321, G Loss: 1.4915, AE Loss: 0.6256\n",
            "Epoch 2, D Loss: 0.7900, G Loss: 1.7335, AE Loss: 0.4714\n",
            "Epoch 2, D Loss: 1.8154, G Loss: 1.5408, AE Loss: 0.4688\n",
            "Epoch 2, D Loss: 0.6888, G Loss: 1.5564, AE Loss: 0.5671\n",
            "Epoch 2, D Loss: 0.8035, G Loss: 1.8255, AE Loss: 0.6474\n",
            "Epoch 2, D Loss: 1.2299, G Loss: 1.8632, AE Loss: 0.5801\n",
            "Epoch 2, D Loss: 0.2887, G Loss: 1.8577, AE Loss: 0.4953\n",
            "Epoch 2, D Loss: 1.1001, G Loss: 1.6095, AE Loss: 0.5627\n",
            "Epoch 2, D Loss: 0.6183, G Loss: 1.5571, AE Loss: 0.5151\n",
            "Epoch 2, D Loss: 0.6986, G Loss: 1.8259, AE Loss: 0.4784\n",
            "Epoch 2, D Loss: 0.7077, G Loss: 1.6321, AE Loss: 0.5998\n",
            "Epoch 2, D Loss: 1.2132, G Loss: 1.7008, AE Loss: 0.4011\n",
            "Epoch 2, D Loss: 0.4474, G Loss: 1.8636, AE Loss: 0.5509\n",
            "Epoch 2, D Loss: 1.7430, G Loss: 1.7928, AE Loss: 0.5937\n",
            "Epoch 2, D Loss: 1.4755, G Loss: 1.6391, AE Loss: 0.5623\n",
            "Epoch 2, D Loss: 1.4763, G Loss: 1.9095, AE Loss: 0.3915\n",
            "Epoch 2, D Loss: 1.0424, G Loss: 1.9659, AE Loss: 0.4632\n",
            "Epoch 2, D Loss: 0.2961, G Loss: 1.9233, AE Loss: 0.4977\n",
            "Epoch 2, D Loss: 1.2545, G Loss: 1.7708, AE Loss: 0.4795\n",
            "Epoch 2, D Loss: 0.8577, G Loss: 1.9717, AE Loss: 0.4767\n",
            "Epoch 2, D Loss: 1.4994, G Loss: 2.1057, AE Loss: 0.4908\n",
            "Epoch 2, D Loss: 0.7578, G Loss: 2.0218, AE Loss: 0.6545\n",
            "Epoch 2, D Loss: 0.5837, G Loss: 1.8824, AE Loss: 0.6217\n",
            "Epoch 2, D Loss: 1.4525, G Loss: 1.7478, AE Loss: 0.6341\n",
            "Epoch 2, D Loss: 0.3720, G Loss: 1.5843, AE Loss: 0.5774\n",
            "Epoch 2, D Loss: 0.6669, G Loss: 1.6270, AE Loss: 0.6451\n",
            "Epoch 2, D Loss: 0.4484, G Loss: 1.9922, AE Loss: 0.6777\n",
            "Epoch 2, D Loss: 1.2123, G Loss: 1.7075, AE Loss: 0.3674\n",
            "Epoch 2, D Loss: 0.3437, G Loss: 1.4973, AE Loss: 0.5556\n",
            "Epoch 2, D Loss: 0.3651, G Loss: 1.8209, AE Loss: 0.4354\n",
            "Epoch 2, D Loss: 0.3394, G Loss: 1.6589, AE Loss: 0.3941\n",
            "Epoch 2, D Loss: 1.9751, G Loss: 1.6116, AE Loss: 0.6072\n",
            "Epoch 2, D Loss: 0.9034, G Loss: 1.5489, AE Loss: 0.5307\n",
            "Epoch 2, D Loss: 1.4545, G Loss: 1.7062, AE Loss: 0.5773\n",
            "Epoch 2, D Loss: 1.1883, G Loss: 1.7791, AE Loss: 0.6738\n",
            "Epoch 2, D Loss: 0.8930, G Loss: 1.5306, AE Loss: 0.3340\n",
            "Epoch 2, D Loss: 0.8305, G Loss: 1.5898, AE Loss: 0.6035\n",
            "Epoch 2, D Loss: 0.5341, G Loss: 1.4870, AE Loss: 0.5787\n",
            "Epoch 2, D Loss: 0.8720, G Loss: 1.6146, AE Loss: 0.4750\n",
            "Epoch 2, D Loss: 1.2204, G Loss: 1.3901, AE Loss: 0.4540\n",
            "Epoch 2, D Loss: 0.9901, G Loss: 1.4361, AE Loss: 0.4352\n",
            "Epoch 2, D Loss: 0.5214, G Loss: 1.5998, AE Loss: 0.7057\n",
            "Epoch 2, D Loss: 0.5790, G Loss: 1.8923, AE Loss: 0.4759\n",
            "Epoch 2, D Loss: 0.8845, G Loss: 1.4587, AE Loss: 0.4514\n",
            "Epoch 2, D Loss: 1.5043, G Loss: 1.6399, AE Loss: 0.6419\n",
            "Epoch 2, D Loss: 1.3375, G Loss: 1.6831, AE Loss: 0.6175\n",
            "Epoch 2, D Loss: 2.0243, G Loss: 1.7622, AE Loss: 0.4332\n",
            "Epoch 2, D Loss: 1.5006, G Loss: 1.4088, AE Loss: 0.5155\n",
            "Epoch 2, D Loss: 0.3983, G Loss: 1.9165, AE Loss: 0.5975\n",
            "Epoch 2, D Loss: 1.8720, G Loss: 1.6752, AE Loss: 0.5072\n",
            "Epoch 2, D Loss: 1.2480, G Loss: 1.6633, AE Loss: 0.5319\n",
            "Epoch 2, D Loss: 0.8294, G Loss: 1.5067, AE Loss: 0.5023\n",
            "Epoch 2, D Loss: 1.8143, G Loss: 1.3372, AE Loss: 0.5355\n",
            "Epoch 2, D Loss: 0.6725, G Loss: 1.3734, AE Loss: 0.6539\n",
            "Epoch 2, D Loss: 1.1961, G Loss: 1.2931, AE Loss: 0.4778\n",
            "Epoch 2, D Loss: 1.0379, G Loss: 1.7766, AE Loss: 0.7118\n",
            "Epoch 2, D Loss: 0.8137, G Loss: 1.4521, AE Loss: 0.6102\n",
            "Epoch 2, D Loss: 1.0135, G Loss: 1.5027, AE Loss: 0.4851\n",
            "Epoch 2, D Loss: 1.1740, G Loss: 1.3623, AE Loss: 0.4958\n",
            "Epoch 2, D Loss: 2.3235, G Loss: 1.4730, AE Loss: 0.4096\n",
            "Epoch 2, D Loss: 0.7886, G Loss: 1.4881, AE Loss: 0.5418\n",
            "Epoch 2, D Loss: 1.1859, G Loss: 1.5778, AE Loss: 0.5761\n",
            "Epoch 2, D Loss: 0.4835, G Loss: 1.2928, AE Loss: 0.6952\n",
            "Epoch 2, D Loss: 1.0991, G Loss: 1.3207, AE Loss: 0.5397\n",
            "Epoch 2, D Loss: 1.0210, G Loss: 1.4491, AE Loss: 0.5624\n",
            "Epoch 2, D Loss: 1.2358, G Loss: 1.4712, AE Loss: 0.5569\n",
            "Epoch 2, D Loss: 1.8814, G Loss: 1.4180, AE Loss: 0.5900\n",
            "Epoch 2, D Loss: 0.6807, G Loss: 1.5844, AE Loss: 0.5390\n",
            "Epoch 2, D Loss: 1.0214, G Loss: 1.4470, AE Loss: 0.5870\n",
            "Epoch 2, D Loss: 1.7038, G Loss: 1.5375, AE Loss: 0.5888\n",
            "Epoch 2, D Loss: 1.2183, G Loss: 1.5431, AE Loss: 0.7204\n",
            "Epoch 2, D Loss: 0.6368, G Loss: 1.4937, AE Loss: 0.5827\n",
            "Epoch 2, D Loss: 2.2288, G Loss: 1.2989, AE Loss: 0.6239\n",
            "Epoch 2, D Loss: 1.7992, G Loss: 1.3932, AE Loss: 0.5843\n",
            "Epoch 2, D Loss: 1.0897, G Loss: 1.3695, AE Loss: 0.6857\n",
            "Epoch 2, D Loss: 1.6847, G Loss: 1.4992, AE Loss: 0.6296\n",
            "Epoch 2, D Loss: 0.7579, G Loss: 1.6071, AE Loss: 0.5493\n",
            "Epoch 2, D Loss: 0.7512, G Loss: 1.5462, AE Loss: 0.5534\n",
            "Epoch 2, D Loss: 0.5711, G Loss: 1.4522, AE Loss: 0.4739\n",
            "Epoch 2, D Loss: 1.6039, G Loss: 1.4926, AE Loss: 0.5938\n",
            "Epoch 2, D Loss: 0.7158, G Loss: 1.3240, AE Loss: 0.6085\n",
            "Epoch 2, D Loss: 0.8734, G Loss: 1.3638, AE Loss: 0.6946\n",
            "Epoch 2, D Loss: 1.8575, G Loss: 1.3381, AE Loss: 0.6081\n",
            "Epoch 2, D Loss: 0.7043, G Loss: 1.5228, AE Loss: 0.7060\n",
            "Epoch 2, D Loss: 1.7766, G Loss: 1.4855, AE Loss: 0.4857\n",
            "Epoch 2, D Loss: 1.1686, G Loss: 1.3526, AE Loss: 0.5803\n",
            "Epoch 2, D Loss: 1.2329, G Loss: 1.5869, AE Loss: 0.7353\n",
            "Epoch 2, D Loss: 1.7062, G Loss: 1.5477, AE Loss: 0.5326\n",
            "Epoch 2, D Loss: 1.8631, G Loss: 1.4870, AE Loss: 0.5380\n",
            "Epoch 2, D Loss: 0.6897, G Loss: 1.6109, AE Loss: 0.4829\n",
            "Epoch 2, D Loss: 0.6933, G Loss: 1.6509, AE Loss: 0.4995\n",
            "Epoch 2, D Loss: 0.9304, G Loss: 1.4714, AE Loss: 0.4748\n",
            "Epoch 2, D Loss: 0.7627, G Loss: 1.5799, AE Loss: 0.6692\n",
            "Epoch 2, D Loss: 1.1493, G Loss: 1.5376, AE Loss: 0.6685\n",
            "Epoch 2, D Loss: 0.8444, G Loss: 1.5464, AE Loss: 0.5956\n",
            "Epoch 2, D Loss: 1.8881, G Loss: 1.5969, AE Loss: 0.4760\n",
            "Epoch 2, D Loss: 0.8842, G Loss: 1.5967, AE Loss: 0.4561\n",
            "Epoch 2, D Loss: 1.2419, G Loss: 1.6218, AE Loss: 0.5790\n",
            "Epoch 2, D Loss: 1.1002, G Loss: 1.5633, AE Loss: 0.6179\n",
            "Epoch 2, D Loss: 2.1083, G Loss: 1.5330, AE Loss: 0.5975\n",
            "Epoch 2, D Loss: 0.3086, G Loss: 1.5824, AE Loss: 0.5193\n",
            "Epoch 2, D Loss: 0.6912, G Loss: 1.6027, AE Loss: 0.5942\n",
            "Epoch 2, D Loss: 1.0611, G Loss: 1.6989, AE Loss: 0.5046\n",
            "Epoch 2, D Loss: 1.7114, G Loss: 1.5709, AE Loss: 0.6586\n",
            "Epoch 2, D Loss: 1.6192, G Loss: 1.6732, AE Loss: 0.6966\n",
            "Epoch 2, D Loss: 0.5883, G Loss: 1.6976, AE Loss: 0.6070\n",
            "Epoch 2, D Loss: 0.7569, G Loss: 1.5924, AE Loss: 0.6279\n",
            "Epoch 2, D Loss: 1.4698, G Loss: 1.5963, AE Loss: 0.6186\n",
            "Epoch 2, D Loss: 0.3503, G Loss: 1.7631, AE Loss: 0.6088\n",
            "Epoch 2, D Loss: 0.6346, G Loss: 1.7551, AE Loss: 0.5046\n",
            "Epoch 2, D Loss: 0.8930, G Loss: 1.6930, AE Loss: 0.4405\n",
            "Epoch 2, D Loss: 0.9745, G Loss: 1.6449, AE Loss: 0.5313\n",
            "Epoch 2, D Loss: 0.5353, G Loss: 1.7854, AE Loss: 0.5511\n",
            "Epoch 2, D Loss: 0.8863, G Loss: 1.7197, AE Loss: 0.4969\n",
            "Epoch 2, D Loss: 1.1096, G Loss: 1.5773, AE Loss: 0.6263\n",
            "Epoch 2, D Loss: 0.7718, G Loss: 1.6466, AE Loss: 0.4647\n",
            "Epoch 2, D Loss: 1.7756, G Loss: 1.5840, AE Loss: 0.4722\n",
            "Epoch 2, D Loss: 0.4201, G Loss: 1.5432, AE Loss: 0.5576\n",
            "Epoch 2, D Loss: 0.4636, G Loss: 1.4482, AE Loss: 0.4549\n",
            "Epoch 2, D Loss: 0.7592, G Loss: 1.4555, AE Loss: 0.5110\n",
            "Epoch 2, D Loss: 0.8915, G Loss: 1.7267, AE Loss: 0.6744\n",
            "Epoch 2, D Loss: 1.4603, G Loss: 1.3501, AE Loss: 0.5383\n",
            "Epoch 2, D Loss: 0.7140, G Loss: 1.3963, AE Loss: 0.6008\n",
            "Epoch 2, D Loss: 0.4830, G Loss: 1.3350, AE Loss: 0.7107\n",
            "Epoch 2, D Loss: 0.5347, G Loss: 1.2626, AE Loss: 0.5805\n",
            "Epoch 2, D Loss: 1.3350, G Loss: 1.4532, AE Loss: 0.5898\n",
            "Epoch 2, D Loss: 1.4716, G Loss: 1.3793, AE Loss: 0.6162\n",
            "Epoch 2, D Loss: 1.0706, G Loss: 1.3384, AE Loss: 0.5916\n",
            "Epoch 2, D Loss: 1.0400, G Loss: 1.4304, AE Loss: 0.4970\n",
            "Epoch 2, D Loss: 1.2652, G Loss: 1.2229, AE Loss: 0.5439\n",
            "Epoch 2, D Loss: 1.0286, G Loss: 1.2789, AE Loss: 0.4700\n",
            "Epoch 2, D Loss: 0.7282, G Loss: 1.2703, AE Loss: 0.4727\n",
            "Epoch 2, D Loss: 0.4701, G Loss: 1.3508, AE Loss: 0.4685\n",
            "Epoch 2, D Loss: 0.5925, G Loss: 1.3161, AE Loss: 0.5836\n",
            "Epoch 2, D Loss: 1.0781, G Loss: 1.3616, AE Loss: 0.6483\n",
            "Epoch 2, D Loss: 0.8817, G Loss: 1.3483, AE Loss: 0.6460\n",
            "Epoch 2, D Loss: 0.8251, G Loss: 1.3414, AE Loss: 0.5994\n",
            "Epoch 2, D Loss: 1.2313, G Loss: 1.3198, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 0.8045, G Loss: 1.2667, AE Loss: 0.6158\n",
            "Epoch 2, D Loss: 1.2811, G Loss: 1.4514, AE Loss: 0.6630\n",
            "Epoch 2, D Loss: 0.7332, G Loss: 1.4656, AE Loss: 0.5985\n",
            "Epoch 2, D Loss: 0.5806, G Loss: 1.5022, AE Loss: 0.5308\n",
            "Epoch 2, D Loss: 1.4450, G Loss: 1.4495, AE Loss: 0.5389\n",
            "Epoch 2, D Loss: 0.8067, G Loss: 1.5707, AE Loss: 0.6590\n",
            "Epoch 2, D Loss: 1.4286, G Loss: 1.6073, AE Loss: 0.4889\n",
            "Epoch 2, D Loss: 0.9648, G Loss: 1.6416, AE Loss: 0.5427\n",
            "Epoch 2, D Loss: 0.6704, G Loss: 1.4640, AE Loss: 0.6103\n",
            "Epoch 2, D Loss: 0.7183, G Loss: 1.5273, AE Loss: 0.5668\n",
            "Epoch 2, D Loss: 0.5142, G Loss: 1.5997, AE Loss: 0.4820\n",
            "Epoch 2, D Loss: 0.5148, G Loss: 1.5479, AE Loss: 0.4836\n",
            "Epoch 2, D Loss: 1.4417, G Loss: 1.4125, AE Loss: 0.5368\n",
            "Epoch 2, D Loss: 0.4480, G Loss: 1.6450, AE Loss: 0.5529\n",
            "Epoch 2, D Loss: 1.7074, G Loss: 1.6460, AE Loss: 0.6178\n",
            "Epoch 2, D Loss: 1.4107, G Loss: 1.6071, AE Loss: 0.4827\n",
            "Epoch 2, D Loss: 0.7315, G Loss: 1.6010, AE Loss: 0.6370\n",
            "Epoch 2, D Loss: 0.8727, G Loss: 1.4548, AE Loss: 0.5997\n",
            "Epoch 2, D Loss: 0.5141, G Loss: 1.4212, AE Loss: 0.5480\n",
            "Epoch 2, D Loss: 0.5233, G Loss: 1.5747, AE Loss: 0.5498\n",
            "Epoch 2, D Loss: 0.5422, G Loss: 1.5183, AE Loss: 0.6073\n",
            "Epoch 2, D Loss: 0.8007, G Loss: 1.4801, AE Loss: 0.4949\n",
            "Epoch 2, D Loss: 0.8443, G Loss: 1.4599, AE Loss: 0.5621\n",
            "Epoch 2, D Loss: 0.5983, G Loss: 1.4600, AE Loss: 0.5758\n",
            "Epoch 2, D Loss: 0.7834, G Loss: 1.6404, AE Loss: 0.4916\n",
            "Epoch 2, D Loss: 1.0777, G Loss: 1.5936, AE Loss: 0.5663\n",
            "Epoch 2, D Loss: 0.6820, G Loss: 1.6158, AE Loss: 0.4649\n",
            "Epoch 2, D Loss: 1.0923, G Loss: 1.4146, AE Loss: 0.4388\n",
            "Epoch 2, D Loss: 0.6642, G Loss: 1.6739, AE Loss: 0.5212\n",
            "Epoch 2, D Loss: 1.0912, G Loss: 1.4714, AE Loss: 0.5263\n",
            "Epoch 2, D Loss: 0.7805, G Loss: 1.3875, AE Loss: 0.6561\n",
            "Epoch 2, D Loss: 1.1815, G Loss: 1.4820, AE Loss: 0.5416\n",
            "Epoch 2, D Loss: 1.4271, G Loss: 1.5780, AE Loss: 0.7744\n",
            "Epoch 2, D Loss: 0.3930, G Loss: 1.5301, AE Loss: 0.4678\n",
            "Epoch 2, D Loss: 0.6672, G Loss: 1.4693, AE Loss: 0.6690\n",
            "Epoch 2, D Loss: 0.5618, G Loss: 1.4241, AE Loss: 0.6197\n",
            "Epoch 2, D Loss: 0.6921, G Loss: 1.5208, AE Loss: 0.5406\n",
            "Epoch 2, D Loss: 0.9004, G Loss: 1.4395, AE Loss: 0.6451\n",
            "Epoch 2, D Loss: 0.8380, G Loss: 1.4757, AE Loss: 0.5180\n",
            "Epoch 2, D Loss: 1.0040, G Loss: 1.4815, AE Loss: 0.5495\n",
            "Epoch 2, D Loss: 1.1737, G Loss: 1.6249, AE Loss: 0.6851\n",
            "Epoch 2, D Loss: 0.6846, G Loss: 1.2313, AE Loss: 0.5395\n",
            "Epoch 2, D Loss: 0.5137, G Loss: 1.3743, AE Loss: 0.5636\n",
            "Epoch 2, D Loss: 0.5946, G Loss: 1.5341, AE Loss: 0.5512\n",
            "Epoch 2, D Loss: 1.2061, G Loss: 1.5509, AE Loss: 0.4815\n",
            "Epoch 2, D Loss: 0.9028, G Loss: 1.3940, AE Loss: 0.5661\n",
            "Epoch 2, D Loss: 0.8031, G Loss: 1.6761, AE Loss: 0.5177\n",
            "Epoch 2, D Loss: 0.8348, G Loss: 1.6282, AE Loss: 0.5753\n",
            "Epoch 2, D Loss: 0.6300, G Loss: 1.5656, AE Loss: 0.6140\n",
            "Epoch 2, D Loss: 1.5474, G Loss: 1.7176, AE Loss: 0.6334\n",
            "Epoch 2, D Loss: 1.7735, G Loss: 1.7441, AE Loss: 0.5009\n",
            "Epoch 2, D Loss: 1.1686, G Loss: 1.5396, AE Loss: 0.6931\n",
            "Epoch 2, D Loss: 1.7713, G Loss: 1.5590, AE Loss: 0.4816\n",
            "Epoch 2, D Loss: 0.6852, G Loss: 1.7043, AE Loss: 0.4709\n",
            "Epoch 2, D Loss: 0.4313, G Loss: 1.6172, AE Loss: 0.5838\n",
            "Epoch 2, D Loss: 0.8699, G Loss: 1.3411, AE Loss: 0.4992\n",
            "Epoch 2, D Loss: 0.6069, G Loss: 1.5934, AE Loss: 0.5643\n",
            "Epoch 2, D Loss: 1.1964, G Loss: 2.2010, AE Loss: 0.5313\n",
            "Epoch 2, D Loss: 0.7052, G Loss: 1.7579, AE Loss: 0.5237\n",
            "Epoch 2, D Loss: 0.8939, G Loss: 1.8011, AE Loss: 0.5301\n",
            "Epoch 2, D Loss: 0.9408, G Loss: 1.6460, AE Loss: 0.5269\n",
            "Epoch 2, D Loss: 0.8337, G Loss: 1.8025, AE Loss: 0.5510\n",
            "Epoch 2, D Loss: 0.3041, G Loss: 1.7144, AE Loss: 0.5463\n",
            "Epoch 2, D Loss: 1.0458, G Loss: 1.7616, AE Loss: 0.4956\n",
            "Epoch 2, D Loss: 0.7646, G Loss: 1.7901, AE Loss: 0.5083\n",
            "Epoch 2, D Loss: 1.1335, G Loss: 1.9551, AE Loss: 0.5854\n",
            "Epoch 2, D Loss: 0.9822, G Loss: 1.8416, AE Loss: 0.4754\n",
            "Epoch 2, D Loss: 0.2544, G Loss: 1.8477, AE Loss: 0.5360\n",
            "Epoch 2, D Loss: 0.9013, G Loss: 1.6853, AE Loss: 0.5380\n",
            "Epoch 2, D Loss: 0.7996, G Loss: 2.1183, AE Loss: 0.6213\n",
            "Epoch 2, D Loss: 0.7565, G Loss: 2.1084, AE Loss: 0.7292\n",
            "Epoch 2, D Loss: 0.8660, G Loss: 1.8656, AE Loss: 0.4433\n",
            "Epoch 2, D Loss: 1.2504, G Loss: 1.9919, AE Loss: 0.4861\n",
            "Epoch 2, D Loss: 0.4179, G Loss: 1.9012, AE Loss: 0.4599\n",
            "Epoch 2, D Loss: 0.6234, G Loss: 1.9696, AE Loss: 0.5924\n",
            "Epoch 2, D Loss: 1.0275, G Loss: 1.9412, AE Loss: 0.6000\n",
            "Epoch 2, D Loss: 0.8887, G Loss: 2.0025, AE Loss: 0.6024\n",
            "Epoch 2, D Loss: 0.3351, G Loss: 1.9327, AE Loss: 0.5448\n",
            "Epoch 2, D Loss: 0.9471, G Loss: 1.8191, AE Loss: 0.6006\n",
            "Epoch 2, D Loss: 0.5883, G Loss: 1.8973, AE Loss: 0.4228\n",
            "Epoch 2, D Loss: 0.4667, G Loss: 1.8586, AE Loss: 0.5948\n",
            "Epoch 2, D Loss: 1.0323, G Loss: 1.9532, AE Loss: 0.5256\n",
            "Epoch 2, D Loss: 0.8396, G Loss: 1.7871, AE Loss: 0.5201\n",
            "Epoch 2, D Loss: 0.4580, G Loss: 1.8636, AE Loss: 0.5982\n",
            "Epoch 2, D Loss: 0.8998, G Loss: 2.0926, AE Loss: 0.7462\n",
            "Epoch 2, D Loss: 0.6467, G Loss: 1.6342, AE Loss: 0.5788\n",
            "Epoch 2, D Loss: 1.0508, G Loss: 1.9105, AE Loss: 0.4938\n",
            "Epoch 2, D Loss: 1.1592, G Loss: 1.8639, AE Loss: 0.5910\n",
            "Epoch 2, D Loss: 1.2810, G Loss: 1.8432, AE Loss: 0.5068\n",
            "Epoch 2, D Loss: 0.5217, G Loss: 2.0639, AE Loss: 0.6317\n",
            "Epoch 2, D Loss: 0.6963, G Loss: 1.9743, AE Loss: 0.6183\n",
            "Epoch 2, D Loss: 0.5826, G Loss: 2.0085, AE Loss: 0.4232\n",
            "Epoch 2, D Loss: 0.6723, G Loss: 1.9028, AE Loss: 0.5148\n",
            "Epoch 2, D Loss: 0.9889, G Loss: 1.8638, AE Loss: 0.4513\n",
            "Epoch 2, D Loss: 0.7521, G Loss: 2.1085, AE Loss: 0.3868\n",
            "Epoch 2, D Loss: 0.8857, G Loss: 1.8418, AE Loss: 0.6372\n",
            "Epoch 2, D Loss: 0.3772, G Loss: 2.0436, AE Loss: 0.5847\n",
            "Epoch 2, D Loss: 1.0500, G Loss: 1.9693, AE Loss: 0.5770\n",
            "Epoch 2, D Loss: 0.8007, G Loss: 2.2255, AE Loss: 0.4946\n",
            "Epoch 2, D Loss: 0.9378, G Loss: 1.8065, AE Loss: 0.5507\n",
            "Epoch 2, D Loss: 1.2465, G Loss: 1.8981, AE Loss: 0.5818\n",
            "Epoch 2, D Loss: 1.0021, G Loss: 2.1131, AE Loss: 0.4684\n",
            "Epoch 2, D Loss: 0.5049, G Loss: 1.8018, AE Loss: 0.6137\n",
            "Epoch 2, D Loss: 0.3443, G Loss: 1.9904, AE Loss: 0.6135\n",
            "Epoch 2, D Loss: 0.2988, G Loss: 1.8172, AE Loss: 0.5847\n",
            "Epoch 2, D Loss: 0.8669, G Loss: 1.7909, AE Loss: 0.3840\n",
            "Epoch 2, D Loss: 0.4169, G Loss: 2.1120, AE Loss: 0.6417\n",
            "Epoch 2, D Loss: 0.6853, G Loss: 1.7692, AE Loss: 0.5114\n",
            "Epoch 2, D Loss: 0.8524, G Loss: 1.8001, AE Loss: 0.5855\n",
            "Epoch 2, D Loss: 0.7092, G Loss: 1.8251, AE Loss: 0.6119\n",
            "Epoch 2, D Loss: 0.4106, G Loss: 1.8427, AE Loss: 0.7485\n",
            "Epoch 2, D Loss: 0.3436, G Loss: 1.6526, AE Loss: 0.4825\n",
            "Epoch 2, D Loss: 0.7002, G Loss: 1.6543, AE Loss: 0.3983\n",
            "Epoch 2, D Loss: 0.3288, G Loss: 1.7544, AE Loss: 0.4841\n",
            "Epoch 2, D Loss: 0.8398, G Loss: 1.5282, AE Loss: 0.5980\n",
            "Epoch 2, D Loss: 0.3749, G Loss: 1.6771, AE Loss: 0.4505\n",
            "Epoch 2, D Loss: 0.8837, G Loss: 1.5323, AE Loss: 0.4354\n",
            "Epoch 2, D Loss: 0.4027, G Loss: 1.7128, AE Loss: 0.5321\n",
            "Epoch 2, D Loss: 0.4797, G Loss: 1.5096, AE Loss: 0.5963\n",
            "Epoch 2, D Loss: 0.5836, G Loss: 1.9960, AE Loss: 0.6125\n",
            "Epoch 2, D Loss: 0.6638, G Loss: 1.7396, AE Loss: 0.5061\n",
            "Epoch 2, D Loss: 0.7042, G Loss: 1.9037, AE Loss: 0.4493\n",
            "Epoch 2, D Loss: 0.8606, G Loss: 1.9011, AE Loss: 0.5447\n",
            "Epoch 2, D Loss: 0.4621, G Loss: 2.2906, AE Loss: 0.5468\n",
            "Epoch 2, D Loss: 0.8772, G Loss: 2.0344, AE Loss: 0.5112\n",
            "Epoch 2, D Loss: 0.7547, G Loss: 2.0811, AE Loss: 0.5293\n",
            "Epoch 2, D Loss: 0.9501, G Loss: 1.9455, AE Loss: 0.5680\n",
            "Epoch 2, D Loss: 0.3281, G Loss: 2.1531, AE Loss: 0.6573\n",
            "Epoch 2, D Loss: 0.5835, G Loss: 2.0290, AE Loss: 0.5528\n",
            "Epoch 2, D Loss: 0.4197, G Loss: 1.9962, AE Loss: 0.5323\n",
            "Epoch 2, D Loss: 0.4347, G Loss: 1.9049, AE Loss: 0.5166\n",
            "Epoch 2, D Loss: 0.6957, G Loss: 2.1126, AE Loss: 0.5089\n",
            "Epoch 2, D Loss: 1.0720, G Loss: 2.1205, AE Loss: 0.6081\n",
            "Epoch 2, D Loss: 1.1884, G Loss: 2.2164, AE Loss: 0.7069\n",
            "Epoch 2, D Loss: 0.8573, G Loss: 2.1517, AE Loss: 0.4980\n",
            "Epoch 2, D Loss: 0.4268, G Loss: 1.9602, AE Loss: 0.5549\n",
            "Epoch 2, D Loss: 0.8201, G Loss: 1.9625, AE Loss: 0.6048\n",
            "Epoch 2, D Loss: 0.6610, G Loss: 1.8972, AE Loss: 0.5201\n",
            "Epoch 2, D Loss: 0.7066, G Loss: 2.0388, AE Loss: 0.6223\n",
            "Epoch 2, D Loss: 1.0592, G Loss: 2.1514, AE Loss: 0.4508\n",
            "Epoch 2, D Loss: 0.3139, G Loss: 1.9356, AE Loss: 0.5715\n",
            "Epoch 2, D Loss: 1.2158, G Loss: 2.2589, AE Loss: 0.5600\n",
            "Epoch 2, D Loss: 1.2098, G Loss: 2.1151, AE Loss: 0.6440\n",
            "Epoch 2, D Loss: 0.6249, G Loss: 2.3486, AE Loss: 0.5780\n",
            "Epoch 2, D Loss: 0.3570, G Loss: 2.1251, AE Loss: 0.5685\n",
            "Epoch 2, D Loss: 0.4596, G Loss: 1.9145, AE Loss: 0.6183\n",
            "Epoch 2, D Loss: 0.3357, G Loss: 2.1218, AE Loss: 0.6034\n",
            "Epoch 2, D Loss: 0.4953, G Loss: 1.8620, AE Loss: 0.6074\n",
            "Epoch 2, D Loss: 0.5364, G Loss: 1.9418, AE Loss: 0.7208\n",
            "Epoch 2, D Loss: 0.8583, G Loss: 1.8734, AE Loss: 0.5122\n",
            "Epoch 2, D Loss: 0.3976, G Loss: 2.1482, AE Loss: 0.5463\n",
            "Epoch 2, D Loss: 0.5248, G Loss: 1.9368, AE Loss: 0.5468\n",
            "Epoch 2, D Loss: 0.4477, G Loss: 2.1681, AE Loss: 0.5711\n",
            "Epoch 2, D Loss: 0.4392, G Loss: 1.9266, AE Loss: 0.4940\n",
            "Epoch 2, D Loss: 0.4060, G Loss: 1.9757, AE Loss: 0.5142\n",
            "Epoch 2, D Loss: 0.4876, G Loss: 1.8133, AE Loss: 0.6494\n",
            "Epoch 2, D Loss: 0.5913, G Loss: 1.9572, AE Loss: 0.6160\n",
            "Epoch 2, D Loss: 0.9352, G Loss: 1.9164, AE Loss: 0.5253\n",
            "Epoch 2, D Loss: 0.9454, G Loss: 1.8259, AE Loss: 0.5417\n",
            "Epoch 2, D Loss: 0.2686, G Loss: 1.8721, AE Loss: 0.4908\n",
            "Epoch 2, D Loss: 0.5773, G Loss: 1.6722, AE Loss: 0.5526\n",
            "Epoch 2, D Loss: 0.9797, G Loss: 1.6278, AE Loss: 0.6268\n",
            "Epoch 2, D Loss: 0.3869, G Loss: 1.8802, AE Loss: 0.4105\n",
            "Epoch 2, D Loss: 1.2246, G Loss: 1.5445, AE Loss: 0.5235\n",
            "Epoch 2, D Loss: 0.7610, G Loss: 1.9427, AE Loss: 0.5477\n",
            "Epoch 2, D Loss: 0.4180, G Loss: 1.7312, AE Loss: 0.6090\n",
            "Epoch 2, D Loss: 0.3822, G Loss: 1.9969, AE Loss: 0.6732\n",
            "Epoch 2, D Loss: 1.1502, G Loss: 1.5767, AE Loss: 0.5384\n",
            "Epoch 2, D Loss: 0.4832, G Loss: 1.5957, AE Loss: 0.6634\n",
            "Epoch 2, D Loss: 0.5664, G Loss: 1.4979, AE Loss: 0.5837\n",
            "Epoch 2, D Loss: 0.6364, G Loss: 1.5782, AE Loss: 0.4617\n",
            "Epoch 2, D Loss: 0.5598, G Loss: 1.7602, AE Loss: 0.5283\n",
            "Epoch 2, D Loss: 0.7696, G Loss: 1.6707, AE Loss: 0.5411\n",
            "Epoch 2, D Loss: 0.5254, G Loss: 1.6761, AE Loss: 0.4966\n",
            "Epoch 2, D Loss: 0.4446, G Loss: 1.7728, AE Loss: 0.5228\n",
            "Epoch 2, D Loss: 0.4010, G Loss: 1.9406, AE Loss: 0.5601\n",
            "Epoch 2, D Loss: 0.3801, G Loss: 1.9708, AE Loss: 0.6265\n",
            "Epoch 2, D Loss: 0.4776, G Loss: 1.7522, AE Loss: 0.5313\n",
            "Epoch 2, D Loss: 0.6017, G Loss: 1.8053, AE Loss: 0.4889\n",
            "Epoch 2, D Loss: 0.6744, G Loss: 1.8604, AE Loss: 0.5601\n",
            "Epoch 2, D Loss: 0.3886, G Loss: 1.9373, AE Loss: 0.5763\n",
            "Epoch 2, D Loss: 0.5365, G Loss: 1.7091, AE Loss: 0.5108\n",
            "Epoch 2, D Loss: 1.1057, G Loss: 1.7364, AE Loss: 0.5430\n",
            "Epoch 2, D Loss: 0.7484, G Loss: 1.6131, AE Loss: 0.5969\n",
            "Epoch 2, D Loss: 0.7988, G Loss: 1.8976, AE Loss: 0.6335\n",
            "Epoch 2, D Loss: 0.8169, G Loss: 1.6106, AE Loss: 0.5907\n",
            "Epoch 2, D Loss: 0.3154, G Loss: 1.7971, AE Loss: 0.5724\n",
            "Epoch 2, D Loss: 1.0105, G Loss: 1.8242, AE Loss: 0.6303\n",
            "Epoch 2, D Loss: 0.5154, G Loss: 1.6632, AE Loss: 0.5327\n",
            "Epoch 2, D Loss: 0.5446, G Loss: 1.6582, AE Loss: 0.5640\n",
            "Epoch 2, D Loss: 1.0365, G Loss: 1.7299, AE Loss: 0.5975\n",
            "Epoch 2, D Loss: 0.6451, G Loss: 1.7026, AE Loss: 0.5886\n",
            "Epoch 2, D Loss: 0.6609, G Loss: 1.7881, AE Loss: 0.5770\n",
            "Epoch 2, D Loss: 0.2022, G Loss: 1.8692, AE Loss: 0.5234\n",
            "Epoch 2, D Loss: 0.9625, G Loss: 1.8395, AE Loss: 0.4678\n",
            "Epoch 2, D Loss: 0.3814, G Loss: 1.8657, AE Loss: 0.5746\n",
            "Epoch 2, D Loss: 0.3669, G Loss: 1.8954, AE Loss: 0.8558\n",
            "Epoch 2, D Loss: 0.4151, G Loss: 1.9500, AE Loss: 0.4917\n",
            "Epoch 2, D Loss: 1.1163, G Loss: 1.9001, AE Loss: 0.7096\n",
            "Epoch 2, D Loss: 0.8497, G Loss: 1.9674, AE Loss: 0.4817\n",
            "Epoch 2, D Loss: 0.6985, G Loss: 1.9682, AE Loss: 0.4384\n",
            "Epoch 2, D Loss: 0.9125, G Loss: 2.2236, AE Loss: 0.5128\n",
            "Epoch 2, D Loss: 0.6011, G Loss: 2.0082, AE Loss: 0.5950\n",
            "Epoch 2, D Loss: 0.1901, G Loss: 2.3548, AE Loss: 0.5044\n",
            "Epoch 2, D Loss: 0.4655, G Loss: 2.1170, AE Loss: 0.4327\n",
            "Epoch 2, D Loss: 0.2709, G Loss: 2.1009, AE Loss: 0.4914\n",
            "Epoch 2, D Loss: 0.6241, G Loss: 1.9549, AE Loss: 0.4534\n",
            "Epoch 2, D Loss: 0.2244, G Loss: 1.7833, AE Loss: 0.4422\n",
            "Epoch 2, D Loss: 0.3569, G Loss: 1.8933, AE Loss: 0.4973\n",
            "Epoch 2, D Loss: 0.7200, G Loss: 1.6981, AE Loss: 0.4987\n",
            "Epoch 2, D Loss: 0.4589, G Loss: 1.7197, AE Loss: 0.4322\n",
            "Epoch 2, D Loss: 0.5153, G Loss: 1.7162, AE Loss: 0.6212\n",
            "Epoch 2, D Loss: 0.6332, G Loss: 1.5783, AE Loss: 0.5635\n",
            "Epoch 2, D Loss: 0.9056, G Loss: 1.4974, AE Loss: 0.6675\n",
            "Epoch 2, D Loss: 0.5751, G Loss: 1.3798, AE Loss: 0.4384\n",
            "Epoch 2, D Loss: 0.5126, G Loss: 1.4232, AE Loss: 0.4863\n",
            "Epoch 2, D Loss: 0.8561, G Loss: 1.5283, AE Loss: 0.5500\n",
            "Epoch 2, D Loss: 0.6319, G Loss: 1.5195, AE Loss: 0.4734\n",
            "Epoch 2, D Loss: 0.6269, G Loss: 1.4100, AE Loss: 0.5302\n",
            "Epoch 2, D Loss: 0.4558, G Loss: 1.3489, AE Loss: 0.5424\n",
            "Epoch 2, D Loss: 0.4166, G Loss: 1.4214, AE Loss: 0.5270\n",
            "Epoch 2, D Loss: 0.5777, G Loss: 1.3354, AE Loss: 0.6163\n",
            "Epoch 2, D Loss: 0.8418, G Loss: 1.4582, AE Loss: 0.5593\n",
            "Epoch 2, D Loss: 1.1199, G Loss: 1.5066, AE Loss: 0.6723\n",
            "Epoch 2, D Loss: 0.5538, G Loss: 1.4509, AE Loss: 0.5939\n",
            "Epoch 2, D Loss: 0.5850, G Loss: 1.4340, AE Loss: 0.5576\n",
            "Epoch 2, D Loss: 0.6014, G Loss: 1.4755, AE Loss: 0.5914\n",
            "Epoch 2, D Loss: 0.5866, G Loss: 1.3172, AE Loss: 0.5349\n",
            "Epoch 2, D Loss: 1.1864, G Loss: 1.4111, AE Loss: 0.6408\n",
            "Epoch 2, D Loss: 0.5557, G Loss: 1.5499, AE Loss: 0.5184\n",
            "Epoch 2, D Loss: 0.6373, G Loss: 1.4705, AE Loss: 0.5000\n",
            "Epoch 2, D Loss: 0.7801, G Loss: 1.3236, AE Loss: 0.5880\n",
            "Epoch 2, D Loss: 0.5530, G Loss: 1.3476, AE Loss: 0.5264\n",
            "Epoch 2, D Loss: 0.6035, G Loss: 1.3471, AE Loss: 0.5139\n",
            "Epoch 2, D Loss: 0.5137, G Loss: 1.5690, AE Loss: 0.4406\n",
            "Epoch 2, D Loss: 1.2615, G Loss: 1.3011, AE Loss: 0.4896\n",
            "Epoch 2, D Loss: 1.1116, G Loss: 1.3378, AE Loss: 0.5579\n",
            "Epoch 2, D Loss: 0.9154, G Loss: 1.3280, AE Loss: 0.5404\n",
            "Epoch 2, D Loss: 0.3745, G Loss: 1.5076, AE Loss: 0.5291\n",
            "Epoch 2, D Loss: 0.7830, G Loss: 1.4775, AE Loss: 0.4864\n",
            "Epoch 2, D Loss: 0.5973, G Loss: 1.3300, AE Loss: 0.5709\n",
            "Epoch 2, D Loss: 0.9226, G Loss: 1.2675, AE Loss: 0.5350\n",
            "Epoch 2, D Loss: 0.9688, G Loss: 1.1876, AE Loss: 0.4865\n",
            "Epoch 2, D Loss: 0.6970, G Loss: 1.1908, AE Loss: 0.5871\n",
            "Epoch 2, D Loss: 0.6142, G Loss: 1.3467, AE Loss: 0.5737\n",
            "Epoch 2, D Loss: 0.6634, G Loss: 1.2640, AE Loss: 0.5492\n",
            "Epoch 2, D Loss: 1.4347, G Loss: 1.1728, AE Loss: 0.6687\n",
            "Epoch 2, D Loss: 0.7363, G Loss: 1.5490, AE Loss: 0.6355\n",
            "Epoch 2, D Loss: 0.6581, G Loss: 1.2816, AE Loss: 0.6584\n",
            "Epoch 2, D Loss: 1.2247, G Loss: 1.3288, AE Loss: 0.5203\n",
            "Epoch 2, D Loss: 0.8201, G Loss: 1.3237, AE Loss: 0.8295\n",
            "Epoch 2, D Loss: 1.4174, G Loss: 1.5378, AE Loss: 0.5715\n",
            "Epoch 2, D Loss: 1.1219, G Loss: 1.5529, AE Loss: 0.7312\n",
            "Epoch 2, D Loss: 0.7217, G Loss: 1.4860, AE Loss: 0.6033\n",
            "Epoch 2, D Loss: 1.0916, G Loss: 1.4211, AE Loss: 0.4690\n",
            "Epoch 2, D Loss: 0.6114, G Loss: 1.6158, AE Loss: 0.5274\n",
            "Epoch 2, D Loss: 0.4292, G Loss: 1.6236, AE Loss: 0.6521\n",
            "Epoch 2, D Loss: 0.7827, G Loss: 1.7977, AE Loss: 0.4974\n",
            "Epoch 2, D Loss: 0.7354, G Loss: 1.7389, AE Loss: 0.6214\n",
            "Epoch 2, D Loss: 0.2750, G Loss: 1.7109, AE Loss: 0.5342\n",
            "Epoch 2, D Loss: 0.5174, G Loss: 1.7796, AE Loss: 0.5505\n",
            "Epoch 2, D Loss: 0.5589, G Loss: 1.7008, AE Loss: 0.4833\n",
            "Epoch 2, D Loss: 0.7395, G Loss: 1.7931, AE Loss: 0.4798\n",
            "Epoch 2, D Loss: 0.5774, G Loss: 1.6109, AE Loss: 0.5992\n",
            "Epoch 2, D Loss: 0.7132, G Loss: 1.6832, AE Loss: 0.5549\n",
            "Epoch 2, D Loss: 0.3695, G Loss: 1.6653, AE Loss: 0.4745\n",
            "Epoch 2, D Loss: 0.5171, G Loss: 1.5883, AE Loss: 0.5722\n",
            "Epoch 2, D Loss: 0.2432, G Loss: 1.6724, AE Loss: 0.6286\n",
            "Epoch 2, D Loss: 1.0442, G Loss: 1.5634, AE Loss: 0.5996\n",
            "Epoch 2, D Loss: 0.5212, G Loss: 1.5570, AE Loss: 0.5538\n",
            "Epoch 2, D Loss: 0.6670, G Loss: 1.4466, AE Loss: 0.6720\n",
            "Epoch 2, D Loss: 0.8434, G Loss: 1.4288, AE Loss: 0.5219\n",
            "Epoch 2, D Loss: 1.1863, G Loss: 1.4448, AE Loss: 0.5804\n",
            "Epoch 2, D Loss: 0.7828, G Loss: 1.3512, AE Loss: 0.4947\n",
            "Epoch 2, D Loss: 0.6981, G Loss: 1.2668, AE Loss: 0.6040\n",
            "Epoch 2, D Loss: 0.6551, G Loss: 1.5190, AE Loss: 0.5042\n",
            "Epoch 2, D Loss: 0.6756, G Loss: 1.7198, AE Loss: 0.6373\n",
            "Epoch 2, D Loss: 1.0180, G Loss: 1.4209, AE Loss: 0.5923\n",
            "Epoch 2, D Loss: 1.0463, G Loss: 1.3454, AE Loss: 0.5020\n",
            "Epoch 2, D Loss: 0.5255, G Loss: 1.4036, AE Loss: 0.5469\n",
            "Epoch 2, D Loss: 1.4704, G Loss: 1.3411, AE Loss: 0.5303\n",
            "Epoch 2, D Loss: 0.7795, G Loss: 1.3586, AE Loss: 0.4919\n",
            "Epoch 2, D Loss: 0.9768, G Loss: 1.3973, AE Loss: 0.6259\n",
            "Epoch 2, D Loss: 0.6037, G Loss: 1.3259, AE Loss: 0.6670\n",
            "Epoch 2, D Loss: 0.9989, G Loss: 1.3728, AE Loss: 0.4619\n",
            "Epoch 2, D Loss: 2.0969, G Loss: 1.4093, AE Loss: 0.4039\n",
            "Epoch 2, D Loss: 0.7386, G Loss: 1.6480, AE Loss: 0.6386\n",
            "Epoch 2, D Loss: 0.9977, G Loss: 1.3078, AE Loss: 0.4887\n",
            "Epoch 2, D Loss: 1.1487, G Loss: 1.3098, AE Loss: 0.4300\n",
            "Epoch 2, D Loss: 0.8793, G Loss: 1.4001, AE Loss: 0.5716\n",
            "Epoch 2, D Loss: 1.0514, G Loss: 1.4052, AE Loss: 0.5332\n",
            "Epoch 2, D Loss: 0.7799, G Loss: 1.3244, AE Loss: 0.4672\n",
            "Epoch 2, D Loss: 1.5760, G Loss: 1.3287, AE Loss: 0.5190\n",
            "Epoch 2, D Loss: 0.5512, G Loss: 1.3269, AE Loss: 0.5775\n",
            "Epoch 2, D Loss: 0.8527, G Loss: 1.3083, AE Loss: 0.5397\n",
            "Epoch 2, D Loss: 0.5029, G Loss: 1.4618, AE Loss: 0.5033\n",
            "Epoch 2, D Loss: 1.5823, G Loss: 1.4659, AE Loss: 0.6583\n",
            "Epoch 2, D Loss: 1.5042, G Loss: 1.4634, AE Loss: 0.6069\n",
            "Epoch 2, D Loss: 0.8767, G Loss: 1.5561, AE Loss: 0.5315\n",
            "Epoch 2, D Loss: 0.8818, G Loss: 1.5886, AE Loss: 0.5572\n",
            "Epoch 2, D Loss: 0.2845, G Loss: 1.5908, AE Loss: 0.4617\n",
            "Epoch 2, D Loss: 0.8933, G Loss: 1.4786, AE Loss: 0.5541\n",
            "Epoch 2, D Loss: 0.6221, G Loss: 1.5896, AE Loss: 0.4526\n",
            "Epoch 2, D Loss: 0.7706, G Loss: 1.6030, AE Loss: 0.7380\n",
            "Epoch 2, D Loss: 0.4234, G Loss: 1.5639, AE Loss: 0.5011\n",
            "Epoch 2, D Loss: 0.8203, G Loss: 1.6115, AE Loss: 0.6258\n",
            "Epoch 2, D Loss: 0.6906, G Loss: 1.4924, AE Loss: 0.6777\n",
            "Epoch 2, D Loss: 0.9594, G Loss: 1.5476, AE Loss: 0.5625\n",
            "Epoch 2, D Loss: 0.3744, G Loss: 1.5267, AE Loss: 0.5027\n",
            "Epoch 2, D Loss: 0.7285, G Loss: 1.6907, AE Loss: 0.6388\n",
            "Epoch 2, D Loss: 0.4623, G Loss: 1.6671, AE Loss: 0.5012\n",
            "Epoch 2, D Loss: 0.4833, G Loss: 1.6290, AE Loss: 0.5113\n",
            "Epoch 2, D Loss: 1.1509, G Loss: 1.5701, AE Loss: 0.4588\n",
            "Epoch 2, D Loss: 0.3929, G Loss: 1.5290, AE Loss: 0.5172\n",
            "Epoch 2, D Loss: 0.4805, G Loss: 1.8056, AE Loss: 0.5899\n",
            "Epoch 2, D Loss: 0.5905, G Loss: 1.6497, AE Loss: 0.6179\n",
            "Epoch 2, D Loss: 1.3907, G Loss: 1.5543, AE Loss: 0.5230\n",
            "Epoch 2, D Loss: 0.5360, G Loss: 1.6791, AE Loss: 0.5297\n",
            "Epoch 2, D Loss: 0.7534, G Loss: 1.4986, AE Loss: 0.4778\n",
            "Epoch 2, D Loss: 0.5813, G Loss: 1.5517, AE Loss: 0.5661\n",
            "Epoch 2, D Loss: 0.5935, G Loss: 1.5547, AE Loss: 0.4833\n",
            "Epoch 2, D Loss: 0.9153, G Loss: 1.6170, AE Loss: 0.6483\n",
            "Epoch 2, D Loss: 0.7575, G Loss: 1.4780, AE Loss: 0.4846\n",
            "Epoch 2, D Loss: 0.7676, G Loss: 1.4275, AE Loss: 0.4928\n",
            "Epoch 2, D Loss: 0.7448, G Loss: 1.4633, AE Loss: 0.4917\n",
            "Epoch 2, D Loss: 0.5352, G Loss: 1.6615, AE Loss: 0.4943\n",
            "Epoch 2, D Loss: 1.5180, G Loss: 1.4053, AE Loss: 0.8007\n",
            "Epoch 2, D Loss: 1.0562, G Loss: 1.4673, AE Loss: 0.5781\n",
            "Epoch 2, D Loss: 0.5820, G Loss: 1.3657, AE Loss: 0.5154\n",
            "Epoch 2, D Loss: 1.0366, G Loss: 1.4856, AE Loss: 0.4949\n",
            "Epoch 2, D Loss: 0.8252, G Loss: 1.4247, AE Loss: 0.5838\n",
            "Epoch 2, D Loss: 0.6812, G Loss: 1.3222, AE Loss: 0.5748\n",
            "Epoch 2, D Loss: 0.9047, G Loss: 1.4543, AE Loss: 0.5453\n",
            "Epoch 2, D Loss: 1.3378, G Loss: 1.3846, AE Loss: 0.6342\n",
            "Epoch 2, D Loss: 0.3606, G Loss: 1.3773, AE Loss: 0.5975\n",
            "Epoch 2, D Loss: 0.6561, G Loss: 1.3106, AE Loss: 0.4372\n",
            "Epoch 2, D Loss: 0.7246, G Loss: 1.2834, AE Loss: 0.6172\n",
            "Epoch 2, D Loss: 1.6312, G Loss: 1.2771, AE Loss: 0.6262\n",
            "Epoch 2, D Loss: 0.8167, G Loss: 1.3689, AE Loss: 0.5371\n",
            "Epoch 2, D Loss: 1.2643, G Loss: 1.3528, AE Loss: 0.6438\n",
            "Epoch 2, D Loss: 0.4742, G Loss: 1.3473, AE Loss: 0.5500\n",
            "Epoch 2, D Loss: 0.7774, G Loss: 1.3328, AE Loss: 0.5480\n",
            "Epoch 2, D Loss: 0.3409, G Loss: 1.3987, AE Loss: 0.4139\n",
            "Epoch 2, D Loss: 0.9897, G Loss: 1.3909, AE Loss: 0.6378\n",
            "Epoch 2, D Loss: 0.5844, G Loss: 1.4681, AE Loss: 0.4940\n",
            "Epoch 2, D Loss: 0.6408, G Loss: 1.4852, AE Loss: 0.4445\n",
            "Epoch 2, D Loss: 0.2805, G Loss: 1.6211, AE Loss: 0.5557\n",
            "Epoch 2, D Loss: 0.5820, G Loss: 1.3598, AE Loss: 0.4627\n",
            "Epoch 2, D Loss: 0.5453, G Loss: 1.4669, AE Loss: 0.6276\n",
            "Epoch 2, D Loss: 0.5596, G Loss: 1.6274, AE Loss: 0.5806\n",
            "Epoch 2, D Loss: 0.7513, G Loss: 1.6132, AE Loss: 0.5462\n",
            "Epoch 2, D Loss: 1.4169, G Loss: 1.6012, AE Loss: 0.6264\n",
            "Epoch 2, D Loss: 0.4191, G Loss: 1.5783, AE Loss: 0.4323\n",
            "Epoch 2, D Loss: 0.3061, G Loss: 1.6402, AE Loss: 0.5419\n",
            "Epoch 2, D Loss: 0.3399, G Loss: 1.6573, AE Loss: 0.4453\n",
            "Epoch 2, D Loss: 1.5315, G Loss: 1.6183, AE Loss: 0.4456\n",
            "Epoch 2, D Loss: 0.7887, G Loss: 1.5999, AE Loss: 0.6045\n",
            "Epoch 2, D Loss: 0.7133, G Loss: 1.6650, AE Loss: 0.6760\n",
            "Epoch 2, D Loss: 0.7744, G Loss: 1.8026, AE Loss: 0.4034\n",
            "Epoch 2, D Loss: 0.6517, G Loss: 1.6739, AE Loss: 0.4722\n",
            "Epoch 2, D Loss: 0.6389, G Loss: 1.8345, AE Loss: 0.6199\n",
            "Epoch 2, D Loss: 0.8196, G Loss: 1.7127, AE Loss: 0.5067\n",
            "Epoch 2, D Loss: 1.1350, G Loss: 1.6039, AE Loss: 0.5866\n",
            "Epoch 2, D Loss: 0.7671, G Loss: 1.7129, AE Loss: 0.5185\n",
            "Epoch 2, D Loss: 0.9710, G Loss: 1.6657, AE Loss: 0.6570\n",
            "Epoch 2, D Loss: 0.7848, G Loss: 1.6471, AE Loss: 0.5974\n",
            "Epoch 2, D Loss: 0.4584, G Loss: 1.7036, AE Loss: 0.6024\n",
            "Epoch 2, D Loss: 0.6546, G Loss: 1.6510, AE Loss: 0.5730\n",
            "Epoch 2, D Loss: 0.8123, G Loss: 1.5463, AE Loss: 0.6023\n",
            "Epoch 2, D Loss: 0.5165, G Loss: 1.6338, AE Loss: 0.4901\n",
            "Epoch 2, D Loss: 0.3575, G Loss: 1.5828, AE Loss: 0.5751\n",
            "Epoch 2, D Loss: 1.0574, G Loss: 1.5849, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 0.4514, G Loss: 1.6554, AE Loss: 0.5093\n",
            "Epoch 2, D Loss: 0.6891, G Loss: 1.5948, AE Loss: 0.6288\n",
            "Epoch 2, D Loss: 0.5022, G Loss: 1.6982, AE Loss: 0.6968\n",
            "Epoch 2, D Loss: 1.0725, G Loss: 1.6650, AE Loss: 0.5703\n",
            "Epoch 2, D Loss: 0.4427, G Loss: 1.6118, AE Loss: 0.5536\n",
            "Epoch 2, D Loss: 1.5350, G Loss: 1.6375, AE Loss: 0.7254\n",
            "Epoch 2, D Loss: 0.3785, G Loss: 1.7063, AE Loss: 0.6105\n",
            "Epoch 2, D Loss: 0.8481, G Loss: 1.7304, AE Loss: 0.4991\n",
            "Epoch 2, D Loss: 1.3340, G Loss: 1.6086, AE Loss: 0.4916\n",
            "Epoch 2, D Loss: 0.5175, G Loss: 1.7568, AE Loss: 0.5863\n",
            "Epoch 2, D Loss: 1.2736, G Loss: 1.6320, AE Loss: 0.5681\n",
            "Epoch 2, D Loss: 0.4726, G Loss: 1.6999, AE Loss: 0.5533\n",
            "Epoch 2, D Loss: 0.7033, G Loss: 1.7201, AE Loss: 0.5254\n",
            "Epoch 2, D Loss: 0.2774, G Loss: 1.8060, AE Loss: 0.5785\n",
            "Epoch 2, D Loss: 0.6268, G Loss: 1.9486, AE Loss: 0.5016\n",
            "Epoch 2, D Loss: 1.3125, G Loss: 1.6791, AE Loss: 0.5980\n",
            "Epoch 2, D Loss: 0.7069, G Loss: 1.7946, AE Loss: 0.4424\n",
            "Epoch 2, D Loss: 0.8812, G Loss: 1.6876, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 0.4671, G Loss: 1.7117, AE Loss: 0.5494\n",
            "Epoch 2, D Loss: 1.1115, G Loss: 1.8132, AE Loss: 0.4982\n",
            "Epoch 2, D Loss: 0.2024, G Loss: 1.8679, AE Loss: 0.4965\n",
            "Epoch 2, D Loss: 0.2560, G Loss: 1.8983, AE Loss: 0.4403\n",
            "Epoch 2, D Loss: 0.5917, G Loss: 1.8006, AE Loss: 0.5766\n",
            "Epoch 2, D Loss: 0.5603, G Loss: 1.9032, AE Loss: 0.5722\n",
            "Epoch 2, D Loss: 0.7618, G Loss: 1.9932, AE Loss: 0.5129\n",
            "Epoch 2, D Loss: 0.7464, G Loss: 1.8128, AE Loss: 0.5504\n",
            "Epoch 2, D Loss: 0.2248, G Loss: 1.9362, AE Loss: 0.4859\n",
            "Epoch 2, D Loss: 0.5977, G Loss: 1.8351, AE Loss: 0.5467\n",
            "Epoch 2, D Loss: 0.7868, G Loss: 1.9773, AE Loss: 0.5975\n",
            "Epoch 2, D Loss: 0.6755, G Loss: 1.9428, AE Loss: 0.5255\n",
            "Epoch 2, D Loss: 0.7591, G Loss: 1.8865, AE Loss: 0.6518\n",
            "Epoch 2, D Loss: 0.4053, G Loss: 1.8944, AE Loss: 0.5190\n",
            "Epoch 2, D Loss: 0.8049, G Loss: 1.9268, AE Loss: 0.7668\n",
            "Epoch 2, D Loss: 0.4303, G Loss: 1.8581, AE Loss: 0.6641\n",
            "Epoch 2, D Loss: 0.2071, G Loss: 1.9427, AE Loss: 0.5498\n",
            "Epoch 2, D Loss: 0.7802, G Loss: 2.0791, AE Loss: 0.4843\n",
            "Epoch 2, D Loss: 0.3432, G Loss: 1.9857, AE Loss: 0.5251\n",
            "Epoch 2, D Loss: 0.8345, G Loss: 1.8934, AE Loss: 0.6044\n",
            "Epoch 2, D Loss: 0.8824, G Loss: 1.9895, AE Loss: 0.5266\n",
            "Epoch 2, D Loss: 0.9756, G Loss: 2.0469, AE Loss: 0.5213\n",
            "Epoch 2, D Loss: 0.8590, G Loss: 2.1669, AE Loss: 0.6514\n",
            "Epoch 2, D Loss: 0.6062, G Loss: 1.9598, AE Loss: 0.4524\n",
            "Epoch 2, D Loss: 0.5450, G Loss: 1.9666, AE Loss: 0.5785\n",
            "Epoch 2, D Loss: 0.3442, G Loss: 2.0265, AE Loss: 0.5286\n",
            "Epoch 2, D Loss: 1.1288, G Loss: 2.0504, AE Loss: 0.5717\n",
            "Epoch 2, D Loss: 0.6554, G Loss: 2.1276, AE Loss: 0.6240\n",
            "Epoch 2, D Loss: 0.4605, G Loss: 2.0414, AE Loss: 0.4897\n",
            "Epoch 2, D Loss: 0.8321, G Loss: 2.0563, AE Loss: 0.4769\n",
            "Epoch 2, D Loss: 0.3867, G Loss: 2.2615, AE Loss: 0.4650\n",
            "Epoch 2, D Loss: 0.9152, G Loss: 2.2736, AE Loss: 0.3970\n",
            "Epoch 2, D Loss: 0.5608, G Loss: 2.0923, AE Loss: 0.5035\n",
            "Epoch 2, D Loss: 0.7006, G Loss: 2.1150, AE Loss: 0.5094\n",
            "Epoch 2, D Loss: 1.1000, G Loss: 2.1948, AE Loss: 0.4847\n",
            "Epoch 2, D Loss: 0.5057, G Loss: 2.3293, AE Loss: 0.5078\n",
            "Epoch 2, D Loss: 0.1453, G Loss: 2.2299, AE Loss: 0.5252\n",
            "Epoch 2, D Loss: 0.1779, G Loss: 2.0543, AE Loss: 0.5696\n",
            "Epoch 2, D Loss: 0.4645, G Loss: 2.0137, AE Loss: 0.5243\n",
            "Epoch 2, D Loss: 0.7922, G Loss: 2.0637, AE Loss: 0.6075\n",
            "Epoch 2, D Loss: 0.3377, G Loss: 2.1690, AE Loss: 0.4904\n",
            "Epoch 2, D Loss: 0.4499, G Loss: 2.1054, AE Loss: 0.5186\n",
            "Epoch 2, D Loss: 0.5413, G Loss: 2.2729, AE Loss: 0.5778\n",
            "Epoch 2, D Loss: 0.5645, G Loss: 2.3663, AE Loss: 0.7270\n",
            "Epoch 2, D Loss: 0.4170, G Loss: 2.2931, AE Loss: 0.5592\n",
            "Epoch 2, D Loss: 1.2529, G Loss: 2.2263, AE Loss: 0.5247\n",
            "Epoch 2, D Loss: 0.4128, G Loss: 2.1373, AE Loss: 0.5640\n",
            "Epoch 2, D Loss: 1.0417, G Loss: 2.4056, AE Loss: 0.4881\n",
            "Epoch 2, D Loss: 1.0968, G Loss: 2.2186, AE Loss: 0.5089\n",
            "Epoch 2, D Loss: 0.6041, G Loss: 2.2750, AE Loss: 0.5742\n",
            "Epoch 2, D Loss: 1.3514, G Loss: 1.7775, AE Loss: 0.5514\n",
            "Epoch 2, D Loss: 0.5130, G Loss: 2.2527, AE Loss: 0.6273\n",
            "Epoch 2, D Loss: 0.6614, G Loss: 2.1778, AE Loss: 0.4514\n",
            "Epoch 2, D Loss: 0.6292, G Loss: 1.8731, AE Loss: 0.4942\n",
            "Epoch 2, D Loss: 0.2754, G Loss: 2.1649, AE Loss: 0.4435\n",
            "Epoch 2, D Loss: 0.7129, G Loss: 2.3349, AE Loss: 0.4797\n",
            "Epoch 2, D Loss: 0.7760, G Loss: 1.8249, AE Loss: 0.6292\n",
            "Epoch 2, D Loss: 0.4542, G Loss: 2.2698, AE Loss: 0.5417\n",
            "Epoch 2, D Loss: 1.0939, G Loss: 1.8090, AE Loss: 0.5133\n",
            "Epoch 2, D Loss: 1.0597, G Loss: 1.7785, AE Loss: 0.5548\n",
            "Epoch 2, D Loss: 1.2226, G Loss: 1.7357, AE Loss: 0.4764\n",
            "Epoch 2, D Loss: 0.1668, G Loss: 2.2400, AE Loss: 0.5690\n",
            "Epoch 2, D Loss: 0.5750, G Loss: 2.0528, AE Loss: 0.6099\n",
            "Epoch 2, D Loss: 0.7071, G Loss: 2.0766, AE Loss: 0.4615\n",
            "Epoch 2, D Loss: 0.8616, G Loss: 1.8695, AE Loss: 0.6566\n",
            "Epoch 2, D Loss: 1.0945, G Loss: 1.9393, AE Loss: 0.4880\n",
            "Epoch 2, D Loss: 0.4376, G Loss: 1.7346, AE Loss: 0.5673\n",
            "Epoch 2, D Loss: 0.6486, G Loss: 1.7635, AE Loss: 0.5295\n",
            "Epoch 2, D Loss: 0.3747, G Loss: 2.1048, AE Loss: 0.5770\n",
            "Epoch 2, D Loss: 0.4377, G Loss: 2.0547, AE Loss: 0.3613\n",
            "Epoch 2, D Loss: 0.4949, G Loss: 2.1725, AE Loss: 0.5225\n",
            "Epoch 2, D Loss: 0.3797, G Loss: 2.1355, AE Loss: 0.6049\n",
            "Epoch 2, D Loss: 1.0594, G Loss: 2.0747, AE Loss: 0.7232\n",
            "Epoch 2, D Loss: 0.6375, G Loss: 1.7332, AE Loss: 0.6086\n",
            "Epoch 2, D Loss: 0.7099, G Loss: 1.8953, AE Loss: 0.6296\n",
            "Epoch 2, D Loss: 0.6160, G Loss: 2.2283, AE Loss: 0.5894\n",
            "Epoch 2, D Loss: 1.1343, G Loss: 2.2530, AE Loss: 0.6003\n",
            "Epoch 2, D Loss: 0.9636, G Loss: 2.2120, AE Loss: 0.6914\n",
            "Epoch 2, D Loss: 1.0964, G Loss: 2.1240, AE Loss: 0.5070\n",
            "Epoch 2, D Loss: 0.5571, G Loss: 2.3924, AE Loss: 0.5071\n",
            "Epoch 2, D Loss: 0.6910, G Loss: 2.0904, AE Loss: 0.5018\n",
            "Epoch 2, D Loss: 0.6926, G Loss: 2.3488, AE Loss: 0.5496\n",
            "Epoch 2, D Loss: 0.7116, G Loss: 2.5791, AE Loss: 0.6420\n",
            "Epoch 2, D Loss: 0.4792, G Loss: 2.1928, AE Loss: 0.5590\n",
            "Epoch 2, D Loss: 0.7927, G Loss: 2.2600, AE Loss: 0.4471\n",
            "Epoch 2, D Loss: 0.7333, G Loss: 2.5128, AE Loss: 0.6286\n",
            "Epoch 2, D Loss: 0.6872, G Loss: 2.1932, AE Loss: 0.5101\n",
            "Epoch 2, D Loss: 0.6914, G Loss: 2.5818, AE Loss: 0.5962\n",
            "Epoch 2, D Loss: 0.3914, G Loss: 2.4057, AE Loss: 0.6580\n",
            "Epoch 2, D Loss: 0.4047, G Loss: 2.3870, AE Loss: 0.6069\n",
            "Epoch 2, D Loss: 0.8328, G Loss: 2.3998, AE Loss: 0.7058\n",
            "Epoch 2, D Loss: 0.3484, G Loss: 2.1557, AE Loss: 0.4534\n",
            "Epoch 2, D Loss: 0.7611, G Loss: 2.1339, AE Loss: 0.5507\n",
            "Epoch 2, D Loss: 0.4952, G Loss: 2.4348, AE Loss: 0.5674\n",
            "Epoch 2, D Loss: 0.7217, G Loss: 2.4797, AE Loss: 0.5568\n",
            "Epoch 2, D Loss: 0.5189, G Loss: 2.2091, AE Loss: 0.4836\n",
            "Epoch 2, D Loss: 0.8296, G Loss: 2.4634, AE Loss: 0.6229\n",
            "Epoch 2, D Loss: 0.9807, G Loss: 2.5214, AE Loss: 0.5600\n",
            "Epoch 2, D Loss: 0.3242, G Loss: 2.3182, AE Loss: 0.4950\n",
            "Epoch 2, D Loss: 0.6774, G Loss: 2.1195, AE Loss: 0.5361\n",
            "Epoch 2, D Loss: 0.8073, G Loss: 2.3399, AE Loss: 0.6006\n",
            "Epoch 2, D Loss: 0.4024, G Loss: 2.4451, AE Loss: 0.5438\n",
            "Epoch 2, D Loss: 0.4136, G Loss: 2.6232, AE Loss: 0.5970\n",
            "Epoch 2, D Loss: 0.8713, G Loss: 2.4031, AE Loss: 0.5461\n",
            "Epoch 2, D Loss: 0.2494, G Loss: 2.3142, AE Loss: 0.5702\n",
            "Epoch 2, D Loss: 0.4532, G Loss: 2.4617, AE Loss: 0.4976\n",
            "Epoch 2, D Loss: 0.6860, G Loss: 2.4272, AE Loss: 0.5373\n",
            "Epoch 2, D Loss: 0.2447, G Loss: 2.5186, AE Loss: 0.5730\n",
            "Epoch 2, D Loss: 0.1620, G Loss: 2.6793, AE Loss: 0.4752\n",
            "Epoch 2, D Loss: 0.4581, G Loss: 2.4590, AE Loss: 0.6195\n",
            "Epoch 2, D Loss: 0.1004, G Loss: 2.8133, AE Loss: 0.6175\n",
            "Epoch 2, D Loss: 0.6369, G Loss: 2.4497, AE Loss: 0.5064\n",
            "Epoch 2, D Loss: 0.1767, G Loss: 2.5073, AE Loss: 0.5922\n",
            "Epoch 2, D Loss: 0.6849, G Loss: 2.6058, AE Loss: 0.4553\n",
            "Epoch 2, D Loss: 0.5511, G Loss: 2.3742, AE Loss: 0.6084\n",
            "Epoch 2, D Loss: 0.2837, G Loss: 2.5697, AE Loss: 0.4973\n",
            "Epoch 2, D Loss: 0.2038, G Loss: 2.5080, AE Loss: 0.5109\n",
            "Epoch 2, D Loss: 0.8041, G Loss: 2.5331, AE Loss: 0.5180\n",
            "Epoch 2, D Loss: 0.3223, G Loss: 2.7584, AE Loss: 0.5591\n",
            "Epoch 2, D Loss: 0.4452, G Loss: 2.7027, AE Loss: 0.4340\n",
            "Epoch 2, D Loss: 0.1486, G Loss: 2.6907, AE Loss: 0.5784\n",
            "Epoch 2, D Loss: 0.1253, G Loss: 2.8994, AE Loss: 0.4763\n",
            "Epoch 2, D Loss: 0.6684, G Loss: 2.9696, AE Loss: 0.6464\n",
            "Epoch 2, D Loss: 0.7494, G Loss: 2.6325, AE Loss: 0.5154\n",
            "Epoch 2, D Loss: 0.9640, G Loss: 3.0143, AE Loss: 0.5446\n",
            "Epoch 2, D Loss: 0.4432, G Loss: 2.6043, AE Loss: 0.5611\n",
            "Epoch 2, D Loss: 0.5332, G Loss: 2.7195, AE Loss: 0.5884\n",
            "Epoch 2, D Loss: 0.2700, G Loss: 2.6767, AE Loss: 0.5019\n",
            "Epoch 2, D Loss: 0.3329, G Loss: 2.9155, AE Loss: 0.6146\n",
            "Epoch 2, D Loss: 0.3154, G Loss: 2.6873, AE Loss: 0.5744\n",
            "Epoch 2, D Loss: 0.4177, G Loss: 2.5899, AE Loss: 0.4723\n",
            "Epoch 2, D Loss: 0.5874, G Loss: 2.7176, AE Loss: 0.6834\n",
            "Epoch 2, D Loss: 0.9934, G Loss: 2.6843, AE Loss: 0.5992\n",
            "Epoch 2, D Loss: 0.3988, G Loss: 2.6375, AE Loss: 0.4990\n",
            "Epoch 2, D Loss: 1.1295, G Loss: 2.5853, AE Loss: 0.6026\n",
            "Epoch 2, D Loss: 0.2868, G Loss: 2.7502, AE Loss: 0.5609\n",
            "Epoch 2, D Loss: 1.2375, G Loss: 2.9776, AE Loss: 0.5623\n",
            "Epoch 2, D Loss: 0.1859, G Loss: 2.8051, AE Loss: 0.5164\n",
            "Epoch 2, D Loss: 0.3400, G Loss: 2.7018, AE Loss: 0.5422\n",
            "Epoch 2, D Loss: 0.1783, G Loss: 2.6776, AE Loss: 0.6417\n",
            "Epoch 2, D Loss: 0.9655, G Loss: 2.7362, AE Loss: 0.5261\n",
            "Epoch 2, D Loss: 0.7969, G Loss: 2.4964, AE Loss: 0.4417\n",
            "Epoch 2, D Loss: 1.8638, G Loss: 2.7015, AE Loss: 0.6624\n",
            "Epoch 2, D Loss: 0.4906, G Loss: 2.4752, AE Loss: 0.4891\n",
            "Epoch 2, D Loss: 0.8077, G Loss: 2.3375, AE Loss: 0.4803\n",
            "Epoch 2, D Loss: 0.4484, G Loss: 2.3504, AE Loss: 0.4610\n",
            "Epoch 2, D Loss: 0.3120, G Loss: 2.1972, AE Loss: 0.4359\n",
            "Epoch 2, D Loss: 1.1516, G Loss: 2.2269, AE Loss: 0.7777\n",
            "Epoch 2, D Loss: 0.5271, G Loss: 2.1974, AE Loss: 0.6511\n",
            "Epoch 2, D Loss: 0.4641, G Loss: 2.5782, AE Loss: 0.5306\n",
            "Epoch 2, D Loss: 0.5955, G Loss: 2.3333, AE Loss: 0.5557\n",
            "Epoch 2, D Loss: 0.8456, G Loss: 2.7137, AE Loss: 0.4658\n",
            "Epoch 2, D Loss: 0.6434, G Loss: 2.2084, AE Loss: 0.6186\n",
            "Epoch 2, D Loss: 0.2900, G Loss: 2.5426, AE Loss: 0.5344\n",
            "Epoch 2, D Loss: 0.4848, G Loss: 2.5362, AE Loss: 0.5722\n",
            "Epoch 2, D Loss: 0.9595, G Loss: 2.7351, AE Loss: 0.5295\n",
            "Epoch 2, D Loss: 0.3829, G Loss: 2.5982, AE Loss: 0.5434\n",
            "Epoch 2, D Loss: 0.7033, G Loss: 2.4942, AE Loss: 0.5394\n",
            "Epoch 2, D Loss: 0.4272, G Loss: 2.9517, AE Loss: 0.5328\n",
            "Epoch 2, D Loss: 0.7363, G Loss: 2.7742, AE Loss: 0.4785\n",
            "Epoch 2, D Loss: 0.1931, G Loss: 2.5326, AE Loss: 0.5022\n",
            "Epoch 2, D Loss: 0.6321, G Loss: 2.8555, AE Loss: 0.5548\n",
            "Epoch 2, D Loss: 0.2700, G Loss: 2.3319, AE Loss: 0.4580\n",
            "Epoch 2, D Loss: 0.2788, G Loss: 2.9162, AE Loss: 0.5125\n",
            "Epoch 2, D Loss: 0.5216, G Loss: 2.8921, AE Loss: 0.6072\n",
            "Epoch 2, D Loss: 0.6643, G Loss: 2.4564, AE Loss: 0.4360\n",
            "Epoch 2, D Loss: 0.7464, G Loss: 2.4523, AE Loss: 0.5738\n",
            "Epoch 2, D Loss: 0.6206, G Loss: 2.8302, AE Loss: 0.5970\n",
            "Epoch 2, D Loss: 0.4808, G Loss: 2.6350, AE Loss: 0.6842\n",
            "Epoch 2, D Loss: 0.5795, G Loss: 2.2357, AE Loss: 0.4852\n",
            "Epoch 2, D Loss: 0.6513, G Loss: 2.6140, AE Loss: 0.4720\n",
            "Epoch 2, D Loss: 0.3106, G Loss: 2.4651, AE Loss: 0.5710\n",
            "Epoch 2, D Loss: 0.4573, G Loss: 2.6237, AE Loss: 0.6075\n",
            "Epoch 2, D Loss: 0.8683, G Loss: 3.2291, AE Loss: 0.5268\n",
            "Epoch 2, D Loss: 0.6875, G Loss: 2.6012, AE Loss: 0.6050\n",
            "Epoch 2, D Loss: 0.5419, G Loss: 2.3453, AE Loss: 0.5917\n",
            "Epoch 2, D Loss: 0.5262, G Loss: 2.4155, AE Loss: 0.4088\n",
            "Epoch 2, D Loss: 0.9657, G Loss: 2.4465, AE Loss: 0.4919\n",
            "Epoch 2, D Loss: 0.8393, G Loss: 2.2348, AE Loss: 0.5405\n",
            "Epoch 2, D Loss: 0.5440, G Loss: 2.5121, AE Loss: 0.5492\n",
            "Epoch 2, D Loss: 0.6888, G Loss: 2.5707, AE Loss: 0.5789\n",
            "Epoch 2, D Loss: 0.3250, G Loss: 2.6386, AE Loss: 0.4388\n",
            "Epoch 2, D Loss: 0.5502, G Loss: 3.1178, AE Loss: 0.5600\n",
            "Epoch 2, D Loss: 1.3014, G Loss: 2.2930, AE Loss: 0.6757\n",
            "Epoch 2, D Loss: 0.4805, G Loss: 2.2193, AE Loss: 0.4847\n",
            "Epoch 2, D Loss: 0.3183, G Loss: 2.4833, AE Loss: 0.6648\n",
            "Epoch 2, D Loss: 0.1658, G Loss: 3.3656, AE Loss: 0.6694\n",
            "Epoch 2, D Loss: 0.5967, G Loss: 2.4812, AE Loss: 0.4876\n",
            "Epoch 2, D Loss: 0.7075, G Loss: 2.8451, AE Loss: 0.6406\n",
            "Epoch 2, D Loss: 0.5154, G Loss: 2.4771, AE Loss: 0.6753\n",
            "Epoch 2, D Loss: 0.7140, G Loss: 2.7634, AE Loss: 0.4873\n",
            "Epoch 2, D Loss: 0.2779, G Loss: 2.3967, AE Loss: 0.5762\n",
            "Epoch 2, D Loss: 0.4189, G Loss: 2.5338, AE Loss: 0.4682\n",
            "Epoch 2, D Loss: 0.4383, G Loss: 2.6659, AE Loss: 0.5277\n",
            "Epoch 2, D Loss: 0.6717, G Loss: 2.9577, AE Loss: 0.5800\n",
            "Epoch 2, D Loss: 0.4769, G Loss: 2.8061, AE Loss: 0.5317\n",
            "Epoch 2, D Loss: 0.3164, G Loss: 2.2849, AE Loss: 0.6749\n",
            "Epoch 2, D Loss: 0.4880, G Loss: 2.7699, AE Loss: 0.5457\n",
            "Epoch 2, D Loss: 0.3454, G Loss: 2.6145, AE Loss: 0.6227\n",
            "Epoch 2, D Loss: 1.1245, G Loss: 2.3009, AE Loss: 0.6089\n",
            "Epoch 2, D Loss: 0.4383, G Loss: 2.2755, AE Loss: 0.4535\n",
            "Epoch 2, D Loss: 0.3492, G Loss: 2.4653, AE Loss: 0.4667\n",
            "Epoch 2, D Loss: 0.8556, G Loss: 2.8360, AE Loss: 0.4780\n",
            "Epoch 2, D Loss: 0.4693, G Loss: 2.1267, AE Loss: 0.4361\n",
            "Epoch 2, D Loss: 1.1096, G Loss: 1.8500, AE Loss: 0.5060\n",
            "Epoch 2, D Loss: 0.3543, G Loss: 1.9684, AE Loss: 0.5856\n",
            "Epoch 2, D Loss: 0.9870, G Loss: 2.5122, AE Loss: 0.6151\n",
            "Epoch 2, D Loss: 0.5008, G Loss: 2.1353, AE Loss: 0.5040\n",
            "Epoch 2, D Loss: 0.4080, G Loss: 2.0014, AE Loss: 0.5242\n",
            "Epoch 2, D Loss: 0.3932, G Loss: 2.3024, AE Loss: 5.5849\n",
            "Epoch 2, D Loss: 0.8149, G Loss: 1.9363, AE Loss: 0.4958\n",
            "Epoch 2, D Loss: 0.6441, G Loss: 1.8244, AE Loss: 0.6085\n",
            "Epoch 2, D Loss: 1.5248, G Loss: 2.1091, AE Loss: 0.7510\n",
            "Epoch 2, D Loss: 0.9929, G Loss: 1.7343, AE Loss: 0.4194\n",
            "Epoch 2, D Loss: 0.6835, G Loss: 1.5695, AE Loss: 0.7385\n",
            "Epoch 2, D Loss: 0.8365, G Loss: 1.7845, AE Loss: 0.6114\n",
            "Epoch 2, D Loss: 0.5875, G Loss: 1.2971, AE Loss: 0.6289\n",
            "Epoch 2, D Loss: 0.6556, G Loss: 1.8255, AE Loss: 0.7524\n",
            "Epoch 2, D Loss: 1.1992, G Loss: 1.0383, AE Loss: 0.5584\n",
            "Epoch 2, D Loss: 0.7549, G Loss: 1.4037, AE Loss: 0.6296\n",
            "Epoch 2, D Loss: 0.9396, G Loss: 1.0837, AE Loss: 0.5225\n",
            "Epoch 2, D Loss: 0.6952, G Loss: 1.5500, AE Loss: 0.5852\n",
            "Epoch 2, D Loss: 1.5165, G Loss: 1.1140, AE Loss: 0.4414\n",
            "Epoch 2, D Loss: 1.4057, G Loss: 1.4685, AE Loss: 0.5016\n",
            "Epoch 2, D Loss: 0.9257, G Loss: 1.0409, AE Loss: 0.5488\n",
            "Epoch 2, D Loss: 0.8600, G Loss: 1.3125, AE Loss: 0.5262\n",
            "Epoch 2, D Loss: 2.0730, G Loss: 1.2098, AE Loss: 0.6643\n",
            "Epoch 2, D Loss: 0.9998, G Loss: 1.1690, AE Loss: 0.6336\n",
            "Epoch 2, D Loss: 0.7332, G Loss: 1.1138, AE Loss: 0.5087\n",
            "Epoch 2, D Loss: 2.1218, G Loss: 1.0573, AE Loss: 0.6194\n",
            "Epoch 2, D Loss: 2.0971, G Loss: 0.7797, AE Loss: 0.6378\n",
            "Epoch 2, D Loss: 1.1881, G Loss: 1.4469, AE Loss: 0.4891\n",
            "Epoch 2, D Loss: 1.4270, G Loss: 1.0045, AE Loss: 0.5998\n",
            "Epoch 2, D Loss: 1.1646, G Loss: 0.7705, AE Loss: 0.4998\n",
            "Epoch 2, D Loss: 1.4024, G Loss: 1.3708, AE Loss: 0.5827\n",
            "Epoch 2, D Loss: 1.2294, G Loss: 1.2467, AE Loss: 0.6265\n",
            "Epoch 2, D Loss: 1.5408, G Loss: 1.1151, AE Loss: 0.5897\n",
            "Epoch 2, D Loss: 0.9256, G Loss: 1.3278, AE Loss: 0.4595\n",
            "Epoch 2, D Loss: 1.0630, G Loss: 1.3150, AE Loss: 0.6292\n",
            "Epoch 2, D Loss: 0.7955, G Loss: 1.2871, AE Loss: 0.4603\n",
            "Epoch 2, D Loss: 1.2726, G Loss: 1.3931, AE Loss: 0.7221\n",
            "Epoch 2, D Loss: 1.0704, G Loss: 1.0409, AE Loss: 0.7121\n",
            "Epoch 2, D Loss: 2.1228, G Loss: 1.5896, AE Loss: 0.5419\n",
            "Epoch 2, D Loss: 0.5790, G Loss: 1.4998, AE Loss: 0.5389\n",
            "Epoch 2, D Loss: 1.3459, G Loss: 1.6892, AE Loss: 0.6217\n",
            "Epoch 2, D Loss: 0.5150, G Loss: 1.8692, AE Loss: 0.5656\n",
            "Epoch 2, D Loss: 0.9011, G Loss: 1.4691, AE Loss: 0.6130\n",
            "Epoch 2, D Loss: 0.5282, G Loss: 1.6056, AE Loss: 0.6067\n",
            "Epoch 2, D Loss: 1.3755, G Loss: 1.5824, AE Loss: 0.5547\n",
            "Epoch 2, D Loss: 1.3221, G Loss: 1.4890, AE Loss: 0.4460\n",
            "Epoch 2, D Loss: 0.8258, G Loss: 2.0780, AE Loss: 0.5218\n",
            "Epoch 2, D Loss: 2.6700, G Loss: 1.5210, AE Loss: 0.6388\n",
            "Epoch 2, D Loss: 0.9684, G Loss: 1.5501, AE Loss: 0.5019\n",
            "Epoch 2, D Loss: 1.1527, G Loss: 1.5029, AE Loss: 0.7011\n",
            "Epoch 2, D Loss: 0.9384, G Loss: 1.8679, AE Loss: 0.5287\n",
            "Epoch 2, D Loss: 0.5231, G Loss: 1.8500, AE Loss: 0.5848\n",
            "Epoch 2, D Loss: 0.7502, G Loss: 1.8917, AE Loss: 0.7167\n",
            "Epoch 2, D Loss: 0.5627, G Loss: 1.6240, AE Loss: 0.4609\n",
            "Epoch 2, D Loss: 2.1382, G Loss: 1.5755, AE Loss: 0.5764\n",
            "Epoch 2, D Loss: 0.8795, G Loss: 1.9208, AE Loss: 0.5606\n",
            "Epoch 2, D Loss: 1.8639, G Loss: 1.5930, AE Loss: 0.6462\n",
            "Epoch 2, D Loss: 2.1390, G Loss: 1.3685, AE Loss: 0.5978\n",
            "Epoch 2, D Loss: 1.2970, G Loss: 1.8305, AE Loss: 0.5311\n",
            "Epoch 2, D Loss: 1.9760, G Loss: 1.8676, AE Loss: 0.5309\n",
            "Epoch 2, D Loss: 1.1735, G Loss: 1.8469, AE Loss: 0.4936\n",
            "Epoch 2, D Loss: 1.7162, G Loss: 1.5197, AE Loss: 0.5770\n",
            "Epoch 2, D Loss: 0.9636, G Loss: 1.3240, AE Loss: 0.6671\n",
            "Epoch 2, D Loss: 1.0670, G Loss: 1.6678, AE Loss: 0.4760\n",
            "Epoch 2, D Loss: 1.3449, G Loss: 1.6565, AE Loss: 0.4876\n",
            "Epoch 2, D Loss: 0.4797, G Loss: 2.2920, AE Loss: 0.5549\n",
            "Epoch 2, D Loss: 1.0893, G Loss: 1.8025, AE Loss: 0.6261\n",
            "Epoch 2, D Loss: 1.5561, G Loss: 2.1854, AE Loss: 0.5100\n",
            "Epoch 2, D Loss: 1.2695, G Loss: 1.4903, AE Loss: 0.5698\n",
            "Epoch 2, D Loss: 0.4989, G Loss: 2.1524, AE Loss: 0.5876\n",
            "Epoch 2, D Loss: 1.4694, G Loss: 1.7760, AE Loss: 0.4805\n",
            "Epoch 2, D Loss: 1.1212, G Loss: 1.6372, AE Loss: 0.4027\n",
            "Epoch 2, D Loss: 0.7116, G Loss: 1.7662, AE Loss: 0.5512\n",
            "Epoch 2, D Loss: 1.5641, G Loss: 1.6921, AE Loss: 0.5044\n",
            "Epoch 2, D Loss: 0.7397, G Loss: 1.9984, AE Loss: 0.6044\n",
            "Epoch 2, D Loss: 0.4812, G Loss: 2.2286, AE Loss: 0.5152\n",
            "Epoch 2, D Loss: 0.8885, G Loss: 2.4821, AE Loss: 0.5191\n",
            "Epoch 2, D Loss: 1.8440, G Loss: 2.0158, AE Loss: 0.5494\n",
            "Epoch 2, D Loss: 0.7839, G Loss: 2.2824, AE Loss: 0.5413\n",
            "Epoch 2, D Loss: 0.9617, G Loss: 1.9585, AE Loss: 0.4389\n",
            "Epoch 2, D Loss: 0.9038, G Loss: 2.2267, AE Loss: 0.5600\n",
            "Epoch 2, D Loss: 1.5570, G Loss: 1.7927, AE Loss: 0.5916\n",
            "Epoch 2, D Loss: 0.2701, G Loss: 2.1321, AE Loss: 0.5283\n",
            "Epoch 2, D Loss: 0.8775, G Loss: 1.6755, AE Loss: 0.5569\n",
            "Epoch 2, D Loss: 1.2451, G Loss: 1.7168, AE Loss: 0.4709\n",
            "Epoch 2, D Loss: 0.6523, G Loss: 1.8246, AE Loss: 0.4864\n",
            "Epoch 2, D Loss: 2.1119, G Loss: 1.7240, AE Loss: 0.4815\n",
            "Epoch 2, D Loss: 1.1718, G Loss: 1.8390, AE Loss: 0.5416\n",
            "Epoch 2, D Loss: 1.2754, G Loss: 1.9234, AE Loss: 0.5712\n",
            "Epoch 2, D Loss: 0.5119, G Loss: 1.6492, AE Loss: 0.4241\n",
            "Epoch 2, D Loss: 0.5183, G Loss: 1.4856, AE Loss: 0.4556\n",
            "Epoch 2, D Loss: 0.8876, G Loss: 1.8022, AE Loss: 0.4835\n",
            "Epoch 2, D Loss: 0.3446, G Loss: 1.7876, AE Loss: 0.4779\n",
            "Epoch 2, D Loss: 0.6045, G Loss: 1.5791, AE Loss: 0.5498\n",
            "Epoch 2, D Loss: 0.4560, G Loss: 1.6464, AE Loss: 0.6106\n",
            "Epoch 2, D Loss: 1.9229, G Loss: 1.5395, AE Loss: 0.6192\n",
            "Epoch 2, D Loss: 1.1748, G Loss: 1.9792, AE Loss: 0.5839\n",
            "Epoch 2, D Loss: 0.8849, G Loss: 1.7667, AE Loss: 0.6623\n",
            "Epoch 2, D Loss: 1.1699, G Loss: 1.9162, AE Loss: 0.5259\n",
            "Epoch 2, D Loss: 0.7203, G Loss: 1.4410, AE Loss: 0.5933\n",
            "Epoch 2, D Loss: 0.3524, G Loss: 1.8175, AE Loss: 0.7751\n",
            "Epoch 2, D Loss: 0.4609, G Loss: 1.9005, AE Loss: 0.4780\n",
            "Epoch 2, D Loss: 0.4661, G Loss: 1.5870, AE Loss: 0.5697\n",
            "Epoch 2, D Loss: 0.6643, G Loss: 1.9072, AE Loss: 0.6073\n",
            "Epoch 2, D Loss: 0.8372, G Loss: 1.7208, AE Loss: 0.4806\n",
            "Epoch 2, D Loss: 0.3200, G Loss: 1.9837, AE Loss: 0.4817\n",
            "Epoch 2, D Loss: 1.1838, G Loss: 1.7352, AE Loss: 0.4264\n",
            "Epoch 2, D Loss: 1.3723, G Loss: 1.7355, AE Loss: 0.5743\n",
            "Epoch 2, D Loss: 0.7992, G Loss: 1.8254, AE Loss: 0.5425\n",
            "Epoch 2, D Loss: 1.2209, G Loss: 2.0477, AE Loss: 0.6110\n",
            "Epoch 2, D Loss: 1.5880, G Loss: 1.5555, AE Loss: 0.6398\n",
            "Epoch 2, D Loss: 1.8443, G Loss: 1.7784, AE Loss: 0.4800\n",
            "Epoch 2, D Loss: 0.5205, G Loss: 1.9223, AE Loss: 0.4614\n",
            "Epoch 2, D Loss: 0.6307, G Loss: 1.4939, AE Loss: 0.6800\n",
            "Epoch 2, D Loss: 1.3499, G Loss: 1.7201, AE Loss: 0.6447\n",
            "Epoch 2, D Loss: 0.8971, G Loss: 1.5305, AE Loss: 0.6552\n",
            "Epoch 2, D Loss: 2.2383, G Loss: 1.6453, AE Loss: 0.5689\n",
            "Epoch 2, D Loss: 0.7360, G Loss: 1.4836, AE Loss: 0.4986\n",
            "Epoch 2, D Loss: 0.5864, G Loss: 1.8353, AE Loss: 0.4350\n",
            "Epoch 2, D Loss: 0.8687, G Loss: 1.4026, AE Loss: 0.6365\n",
            "Epoch 2, D Loss: 0.7773, G Loss: 2.0215, AE Loss: 0.5950\n",
            "Epoch 2, D Loss: 1.0681, G Loss: 1.6102, AE Loss: 0.6174\n",
            "Epoch 2, D Loss: 0.9052, G Loss: 1.5039, AE Loss: 0.5700\n",
            "Epoch 2, D Loss: 0.8352, G Loss: 1.7041, AE Loss: 0.5722\n",
            "Epoch 2, D Loss: 0.4644, G Loss: 1.9584, AE Loss: 0.6227\n",
            "Epoch 2, D Loss: 0.7943, G Loss: 1.6729, AE Loss: 0.6772\n",
            "Epoch 2, D Loss: 0.6709, G Loss: 1.5301, AE Loss: 0.4303\n",
            "Epoch 2, D Loss: 0.5595, G Loss: 1.5090, AE Loss: 0.5022\n",
            "Epoch 2, D Loss: 1.8140, G Loss: 1.6247, AE Loss: 0.5642\n",
            "Epoch 2, D Loss: 0.9749, G Loss: 1.7893, AE Loss: 0.6654\n",
            "Epoch 2, D Loss: 1.0672, G Loss: 1.5426, AE Loss: 0.6986\n",
            "Epoch 2, D Loss: 1.1047, G Loss: 1.6573, AE Loss: 0.5264\n",
            "Epoch 2, D Loss: 0.4141, G Loss: 1.5213, AE Loss: 0.7576\n",
            "Epoch 2, D Loss: 0.4153, G Loss: 1.8165, AE Loss: 0.6842\n",
            "Epoch 2, D Loss: 0.6906, G Loss: 1.7297, AE Loss: 0.5462\n",
            "Epoch 2, D Loss: 1.3495, G Loss: 1.5206, AE Loss: 0.6206\n",
            "Epoch 2, D Loss: 0.9340, G Loss: 1.7790, AE Loss: 0.5589\n",
            "Epoch 2, D Loss: 1.1524, G Loss: 1.8202, AE Loss: 0.5143\n",
            "Epoch 2, D Loss: 0.3986, G Loss: 2.0765, AE Loss: 0.5162\n",
            "Epoch 2, D Loss: 0.3065, G Loss: 1.9859, AE Loss: 0.6144\n",
            "Epoch 2, D Loss: 0.5132, G Loss: 1.7287, AE Loss: 0.5793\n",
            "Epoch 2, D Loss: 0.5683, G Loss: 1.8795, AE Loss: 0.5553\n",
            "Epoch 2, D Loss: 0.7837, G Loss: 1.8723, AE Loss: 0.5770\n",
            "Epoch 2, D Loss: 0.5918, G Loss: 1.9373, AE Loss: 0.5587\n",
            "Epoch 2, D Loss: 1.4893, G Loss: 1.8343, AE Loss: 0.5433\n",
            "Epoch 2, D Loss: 0.8875, G Loss: 1.8227, AE Loss: 0.6321\n",
            "Epoch 2, D Loss: 0.7167, G Loss: 1.7099, AE Loss: 0.5664\n",
            "Epoch 2, D Loss: 0.6051, G Loss: 1.8121, AE Loss: 0.5903\n",
            "Epoch 2, D Loss: 1.3297, G Loss: 1.8270, AE Loss: 0.5832\n",
            "Epoch 2, D Loss: 0.8555, G Loss: 1.8022, AE Loss: 0.6525\n",
            "Epoch 2, D Loss: 0.6277, G Loss: 1.6827, AE Loss: 0.5633\n",
            "Epoch 2, D Loss: 0.6665, G Loss: 1.5002, AE Loss: 0.6238\n",
            "Epoch 2, D Loss: 1.0628, G Loss: 1.4892, AE Loss: 0.6928\n",
            "Epoch 2, D Loss: 0.7632, G Loss: 1.8868, AE Loss: 0.5958\n",
            "Epoch 2, D Loss: 0.3912, G Loss: 1.6799, AE Loss: 0.6002\n",
            "Epoch 2, D Loss: 0.3583, G Loss: 1.6028, AE Loss: 0.6296\n",
            "Epoch 2, D Loss: 1.1167, G Loss: 1.6669, AE Loss: 0.5991\n",
            "Epoch 2, D Loss: 1.0044, G Loss: 1.5247, AE Loss: 0.6095\n",
            "Epoch 2, D Loss: 0.4269, G Loss: 1.6233, AE Loss: 0.5285\n",
            "Epoch 2, D Loss: 1.2013, G Loss: 1.6139, AE Loss: 0.4992\n",
            "Epoch 2, D Loss: 0.9041, G Loss: 1.8612, AE Loss: 0.7177\n",
            "Epoch 2, D Loss: 0.5501, G Loss: 1.7072, AE Loss: 0.5992\n",
            "Epoch 2, D Loss: 0.9218, G Loss: 1.7174, AE Loss: 0.5087\n",
            "Epoch 2, D Loss: 0.3242, G Loss: 1.9042, AE Loss: 0.6040\n",
            "Epoch 2, D Loss: 0.3571, G Loss: 1.7894, AE Loss: 0.5786\n",
            "Epoch 2, D Loss: 0.6619, G Loss: 1.6704, AE Loss: 0.5154\n",
            "Epoch 2, D Loss: 0.2194, G Loss: 2.1095, AE Loss: 0.6638\n",
            "Epoch 2, D Loss: 0.3471, G Loss: 2.0207, AE Loss: 0.4491\n",
            "Epoch 2, D Loss: 0.5063, G Loss: 2.1248, AE Loss: 0.6886\n",
            "Epoch 2, D Loss: 0.3435, G Loss: 2.1679, AE Loss: 0.6467\n",
            "Epoch 2, D Loss: 1.2072, G Loss: 2.2344, AE Loss: 0.6119\n",
            "Epoch 2, D Loss: 0.5840, G Loss: 2.0887, AE Loss: 0.5685\n",
            "Epoch 2, D Loss: 0.2590, G Loss: 2.0644, AE Loss: 0.5804\n",
            "Epoch 2, D Loss: 0.2205, G Loss: 2.3517, AE Loss: 0.6551\n",
            "Epoch 2, D Loss: 0.3865, G Loss: 2.2532, AE Loss: 0.6549\n",
            "Epoch 2, D Loss: 0.2685, G Loss: 2.3424, AE Loss: 0.5872\n",
            "Epoch 2, D Loss: 1.0391, G Loss: 2.2535, AE Loss: 0.4475\n",
            "Epoch 2, D Loss: 0.2895, G Loss: 2.3604, AE Loss: 0.5661\n",
            "Epoch 2, D Loss: 0.7302, G Loss: 2.2547, AE Loss: 0.5202\n",
            "Epoch 2, D Loss: 0.2178, G Loss: 2.2332, AE Loss: 0.5731\n",
            "Epoch 2, D Loss: 1.2688, G Loss: 2.3205, AE Loss: 0.5606\n",
            "Epoch 2, D Loss: 0.6513, G Loss: 2.5927, AE Loss: 0.4718\n",
            "Epoch 2, D Loss: 0.2967, G Loss: 2.3202, AE Loss: 0.5492\n",
            "Epoch 2, D Loss: 0.6633, G Loss: 2.3612, AE Loss: 0.6258\n",
            "Epoch 2, D Loss: 0.6194, G Loss: 2.3736, AE Loss: 0.5833\n",
            "Epoch 2, D Loss: 0.2321, G Loss: 2.3651, AE Loss: 0.4797\n",
            "Epoch 2, D Loss: 0.5959, G Loss: 2.2462, AE Loss: 0.5582\n",
            "Epoch 2, D Loss: 0.8122, G Loss: 2.3232, AE Loss: 0.5972\n",
            "Epoch 2, D Loss: 0.5093, G Loss: 2.2136, AE Loss: 0.5299\n",
            "Epoch 2, D Loss: 0.1902, G Loss: 2.3939, AE Loss: 0.6721\n",
            "Epoch 2, D Loss: 0.6489, G Loss: 2.4156, AE Loss: 0.6358\n",
            "Epoch 2, D Loss: 0.6266, G Loss: 2.4056, AE Loss: 0.4172\n",
            "Epoch 2, D Loss: 0.6210, G Loss: 2.2850, AE Loss: 0.5673\n",
            "Epoch 2, D Loss: 0.2519, G Loss: 2.3676, AE Loss: 0.5150\n",
            "Epoch 2, D Loss: 0.6271, G Loss: 2.3060, AE Loss: 0.4226\n",
            "Epoch 2, D Loss: 0.4530, G Loss: 2.2215, AE Loss: 0.5371\n",
            "Epoch 2, D Loss: 0.7926, G Loss: 2.3987, AE Loss: 0.4720\n",
            "Epoch 2, D Loss: 0.6496, G Loss: 2.2907, AE Loss: 0.6172\n",
            "Epoch 2, D Loss: 0.2685, G Loss: 2.3557, AE Loss: 0.5814\n",
            "Epoch 2, D Loss: 0.8251, G Loss: 2.3085, AE Loss: 0.5142\n",
            "Epoch 2, D Loss: 0.5514, G Loss: 2.2758, AE Loss: 0.6137\n",
            "Epoch 2, D Loss: 0.6198, G Loss: 2.2671, AE Loss: 0.6495\n",
            "Epoch 2, D Loss: 0.5395, G Loss: 2.2465, AE Loss: 0.5033\n",
            "Epoch 2, D Loss: 0.3305, G Loss: 2.3089, AE Loss: 0.4663\n",
            "Epoch 2, D Loss: 0.7279, G Loss: 2.3190, AE Loss: 0.5467\n",
            "Epoch 2, D Loss: 0.6276, G Loss: 2.3513, AE Loss: 0.6116\n",
            "Epoch 2, D Loss: 0.4477, G Loss: 2.1660, AE Loss: 0.5692\n",
            "Epoch 2, D Loss: 0.5571, G Loss: 2.2484, AE Loss: 0.4263\n",
            "Epoch 2, D Loss: 0.6310, G Loss: 2.1961, AE Loss: 0.4418\n",
            "Epoch 2, D Loss: 0.3440, G Loss: 2.2082, AE Loss: 0.6416\n",
            "Epoch 2, D Loss: 1.1510, G Loss: 2.2459, AE Loss: 0.5586\n",
            "Epoch 2, D Loss: 0.9748, G Loss: 2.1981, AE Loss: 0.6319\n",
            "Epoch 2, D Loss: 0.2898, G Loss: 2.2167, AE Loss: 0.4779\n",
            "Epoch 2, D Loss: 0.7256, G Loss: 2.2138, AE Loss: 0.5925\n",
            "Epoch 2, D Loss: 0.3328, G Loss: 2.1460, AE Loss: 0.5492\n",
            "Epoch 2, D Loss: 0.7949, G Loss: 2.0948, AE Loss: 0.4887\n",
            "Epoch 2, D Loss: 0.2032, G Loss: 2.2494, AE Loss: 0.4805\n",
            "Epoch 2, D Loss: 0.4034, G Loss: 2.2873, AE Loss: 0.5317\n",
            "Epoch 2, D Loss: 0.4593, G Loss: 2.2493, AE Loss: 0.5369\n",
            "Epoch 2, D Loss: 0.6215, G Loss: 2.1848, AE Loss: 0.5058\n",
            "Epoch 2, D Loss: 0.3524, G Loss: 2.1738, AE Loss: 0.4579\n",
            "Epoch 2, D Loss: 0.6802, G Loss: 2.2013, AE Loss: 0.4477\n",
            "Epoch 2, D Loss: 0.9742, G Loss: 2.1010, AE Loss: 0.5450\n",
            "Epoch 2, D Loss: 0.5920, G Loss: 2.2051, AE Loss: 0.5461\n",
            "Epoch 2, D Loss: 0.9007, G Loss: 2.1055, AE Loss: 0.5700\n",
            "Epoch 2, D Loss: 0.3480, G Loss: 2.1536, AE Loss: 0.7636\n",
            "Epoch 2, D Loss: 0.4530, G Loss: 2.2517, AE Loss: 0.5864\n",
            "Epoch 2, D Loss: 0.3815, G Loss: 2.1163, AE Loss: 0.5573\n",
            "Epoch 2, D Loss: 0.3199, G Loss: 2.0720, AE Loss: 0.5783\n",
            "Epoch 2, D Loss: 0.4639, G Loss: 1.9453, AE Loss: 0.5069\n",
            "Epoch 2, D Loss: 0.2981, G Loss: 2.1359, AE Loss: 0.4666\n",
            "Epoch 2, D Loss: 0.9903, G Loss: 2.0406, AE Loss: 0.5350\n",
            "Epoch 2, D Loss: 0.2245, G Loss: 2.0113, AE Loss: 0.4908\n",
            "Epoch 2, D Loss: 0.6977, G Loss: 2.0806, AE Loss: 0.4813\n",
            "Epoch 2, D Loss: 0.6264, G Loss: 2.0637, AE Loss: 0.5689\n",
            "Epoch 2, D Loss: 0.4218, G Loss: 2.0070, AE Loss: 0.5218\n",
            "Epoch 2, D Loss: 0.2141, G Loss: 2.0695, AE Loss: 0.4688\n",
            "Epoch 2, D Loss: 0.4479, G Loss: 2.0523, AE Loss: 0.6108\n",
            "Epoch 2, D Loss: 0.4394, G Loss: 2.0480, AE Loss: 0.7156\n",
            "Epoch 2, D Loss: 0.9310, G Loss: 1.9470, AE Loss: 0.4667\n",
            "Epoch 2, D Loss: 0.4804, G Loss: 1.9489, AE Loss: 0.5806\n",
            "Epoch 2, D Loss: 1.0034, G Loss: 1.9785, AE Loss: 0.5172\n",
            "Epoch 2, D Loss: 0.6105, G Loss: 1.9693, AE Loss: 0.5198\n",
            "Epoch 2, D Loss: 0.2626, G Loss: 1.9433, AE Loss: 0.5533\n",
            "Epoch 2, D Loss: 0.2407, G Loss: 1.9129, AE Loss: 0.4499\n",
            "Epoch 2, D Loss: 0.9550, G Loss: 1.8740, AE Loss: 0.5160\n",
            "Epoch 2, D Loss: 0.4890, G Loss: 1.8370, AE Loss: 0.5170\n",
            "Epoch 2, D Loss: 0.2483, G Loss: 1.9469, AE Loss: 0.5394\n",
            "Epoch 2, D Loss: 0.7372, G Loss: 1.9006, AE Loss: 0.5435\n",
            "Epoch 2, D Loss: 0.2392, G Loss: 1.9908, AE Loss: 0.5964\n",
            "Epoch 2, D Loss: 0.2904, G Loss: 2.0034, AE Loss: 0.5639\n",
            "Epoch 2, D Loss: 0.2374, G Loss: 1.8741, AE Loss: 0.4376\n",
            "Epoch 2, D Loss: 0.4498, G Loss: 2.0583, AE Loss: 0.5075\n",
            "Epoch 2, D Loss: 0.3309, G Loss: 1.8241, AE Loss: 0.5184\n",
            "Epoch 2, D Loss: 0.3230, G Loss: 1.9222, AE Loss: 0.5040\n",
            "Epoch 2, D Loss: 1.0364, G Loss: 1.9216, AE Loss: 0.5589\n",
            "Epoch 2, D Loss: 0.5162, G Loss: 1.8828, AE Loss: 0.4943\n",
            "Epoch 2, D Loss: 0.4372, G Loss: 1.8938, AE Loss: 0.6645\n",
            "Epoch 2, D Loss: 0.2113, G Loss: 1.7732, AE Loss: 0.3870\n",
            "Epoch 2, D Loss: 0.2466, G Loss: 1.8902, AE Loss: 0.5179\n",
            "Epoch 2, D Loss: 0.7843, G Loss: 1.8680, AE Loss: 0.5979\n",
            "Epoch 2, D Loss: 0.1700, G Loss: 1.9682, AE Loss: 0.5274\n",
            "Epoch 2, D Loss: 0.4623, G Loss: 1.8770, AE Loss: 0.6979\n",
            "Epoch 2, D Loss: 0.7118, G Loss: 1.9061, AE Loss: 0.6498\n",
            "Epoch 2, D Loss: 1.0671, G Loss: 1.9621, AE Loss: 0.6313\n",
            "Epoch 2, D Loss: 0.4898, G Loss: 2.0766, AE Loss: 0.6298\n",
            "Epoch 2, D Loss: 0.4282, G Loss: 1.8722, AE Loss: 0.5520\n",
            "Epoch 2, D Loss: 0.3789, G Loss: 1.8978, AE Loss: 0.4961\n",
            "Epoch 2, D Loss: 0.3165, G Loss: 1.7290, AE Loss: 0.5202\n",
            "Epoch 2, D Loss: 0.1867, G Loss: 1.9133, AE Loss: 0.5360\n",
            "Epoch 2, D Loss: 0.7973, G Loss: 1.8124, AE Loss: 0.5801\n",
            "Epoch 2, D Loss: 1.0592, G Loss: 1.6729, AE Loss: 0.5029\n",
            "Epoch 2, D Loss: 0.2780, G Loss: 1.8650, AE Loss: 0.4172\n",
            "Epoch 2, D Loss: 0.3579, G Loss: 1.7887, AE Loss: 0.5404\n",
            "Epoch 2, D Loss: 0.4852, G Loss: 1.6185, AE Loss: 0.5393\n",
            "Epoch 2, D Loss: 0.4171, G Loss: 1.6808, AE Loss: 0.6013\n",
            "Epoch 2, D Loss: 0.4624, G Loss: 1.8085, AE Loss: 0.5177\n",
            "Epoch 2, D Loss: 0.3340, G Loss: 1.5292, AE Loss: 0.4856\n",
            "Epoch 2, D Loss: 0.8854, G Loss: 1.5364, AE Loss: 0.6155\n",
            "Epoch 2, D Loss: 0.4591, G Loss: 1.8589, AE Loss: 0.5555\n",
            "Epoch 2, D Loss: 1.3064, G Loss: 1.4228, AE Loss: 0.5378\n",
            "Epoch 2, D Loss: 0.8025, G Loss: 1.4900, AE Loss: 0.6230\n",
            "Epoch 2, D Loss: 0.3525, G Loss: 1.3425, AE Loss: 0.5919\n",
            "Epoch 2, D Loss: 0.5354, G Loss: 1.4871, AE Loss: 0.4035\n",
            "Epoch 2, D Loss: 0.5974, G Loss: 1.3331, AE Loss: 0.5475\n",
            "Epoch 2, D Loss: 0.5685, G Loss: 1.4908, AE Loss: 0.3757\n",
            "Epoch 2, D Loss: 0.4330, G Loss: 1.4485, AE Loss: 0.4837\n",
            "Epoch 2, D Loss: 0.3478, G Loss: 1.3637, AE Loss: 0.4821\n",
            "Epoch 2, D Loss: 0.9531, G Loss: 1.2521, AE Loss: 0.6317\n",
            "Epoch 2, D Loss: 0.5542, G Loss: 1.2258, AE Loss: 0.6632\n",
            "Epoch 2, D Loss: 0.5411, G Loss: 1.3815, AE Loss: 0.6285\n",
            "Epoch 2, D Loss: 0.4127, G Loss: 1.3337, AE Loss: 0.5440\n",
            "Epoch 2, D Loss: 0.4324, G Loss: 1.2881, AE Loss: 0.6001\n",
            "Epoch 2, D Loss: 0.7233, G Loss: 1.1586, AE Loss: 0.6578\n",
            "Epoch 2, D Loss: 1.0172, G Loss: 1.1133, AE Loss: 0.5095\n",
            "Epoch 2, D Loss: 0.7335, G Loss: 1.2330, AE Loss: 0.6265\n",
            "Epoch 2, D Loss: 0.9140, G Loss: 1.2503, AE Loss: 0.4591\n",
            "Epoch 2, D Loss: 0.7638, G Loss: 1.2995, AE Loss: 0.5421\n",
            "Epoch 2, D Loss: 0.6679, G Loss: 1.3362, AE Loss: 0.5141\n",
            "Epoch 2, D Loss: 0.4927, G Loss: 1.3340, AE Loss: 0.8031\n",
            "Epoch 2, D Loss: 0.4872, G Loss: 1.3331, AE Loss: 0.6330\n",
            "Epoch 2, D Loss: 1.0792, G Loss: 1.4028, AE Loss: 0.5679\n",
            "Epoch 2, D Loss: 0.9358, G Loss: 1.4743, AE Loss: 0.4859\n",
            "Epoch 2, D Loss: 0.3812, G Loss: 1.3798, AE Loss: 0.6475\n",
            "Epoch 2, D Loss: 0.9346, G Loss: 1.4290, AE Loss: 0.5475\n",
            "Epoch 2, D Loss: 1.0158, G Loss: 1.4134, AE Loss: 0.6224\n",
            "Epoch 2, D Loss: 0.3603, G Loss: 1.5317, AE Loss: 0.4853\n",
            "Epoch 2, D Loss: 1.5629, G Loss: 1.5030, AE Loss: 0.6965\n",
            "Epoch 2, D Loss: 0.4748, G Loss: 1.4924, AE Loss: 0.5996\n",
            "Epoch 2, D Loss: 0.3647, G Loss: 1.6059, AE Loss: 0.5841\n",
            "Epoch 2, D Loss: 1.4182, G Loss: 1.4588, AE Loss: 0.5524\n",
            "Epoch 2, D Loss: 0.3841, G Loss: 1.5650, AE Loss: 0.5871\n",
            "Epoch 2, D Loss: 0.2918, G Loss: 1.4894, AE Loss: 0.6977\n",
            "Epoch 2, D Loss: 0.6136, G Loss: 1.4904, AE Loss: 0.5636\n",
            "Epoch 2, D Loss: 0.4624, G Loss: 1.4050, AE Loss: 0.5189\n",
            "Epoch 2, D Loss: 1.3320, G Loss: 1.5172, AE Loss: 0.5855\n",
            "Epoch 2, D Loss: 0.5494, G Loss: 1.5008, AE Loss: 0.5977\n",
            "Epoch 2, D Loss: 0.6839, G Loss: 1.5213, AE Loss: 0.5955\n",
            "Epoch 2, D Loss: 0.9965, G Loss: 1.4103, AE Loss: 0.5467\n",
            "Epoch 2, D Loss: 0.5889, G Loss: 1.4181, AE Loss: 0.5892\n",
            "Epoch 2, D Loss: 0.5789, G Loss: 1.5857, AE Loss: 0.4706\n",
            "Epoch 2, D Loss: 0.4640, G Loss: 1.5251, AE Loss: 0.5504\n",
            "Epoch 2, D Loss: 0.5005, G Loss: 1.5659, AE Loss: 0.5760\n",
            "Epoch 2, D Loss: 1.1491, G Loss: 1.3357, AE Loss: 0.5507\n",
            "Epoch 2, D Loss: 0.6588, G Loss: 1.4552, AE Loss: 0.6018\n",
            "Epoch 2, D Loss: 0.4198, G Loss: 1.4453, AE Loss: 0.5543\n",
            "Epoch 2, D Loss: 0.7634, G Loss: 1.3683, AE Loss: 0.4777\n",
            "Epoch 2, D Loss: 0.4461, G Loss: 1.4072, AE Loss: 0.5822\n",
            "Epoch 2, D Loss: 0.5770, G Loss: 1.3670, AE Loss: 0.5256\n",
            "Epoch 2, D Loss: 0.7822, G Loss: 1.3383, AE Loss: 0.5062\n",
            "Epoch 2, D Loss: 0.4604, G Loss: 1.4494, AE Loss: 0.4798\n",
            "Epoch 2, D Loss: 0.5411, G Loss: 1.3183, AE Loss: 0.6234\n",
            "Epoch 2, D Loss: 0.9040, G Loss: 1.3709, AE Loss: 0.4721\n",
            "Epoch 2, D Loss: 0.5200, G Loss: 1.3965, AE Loss: 0.4925\n",
            "Epoch 2, D Loss: 0.4809, G Loss: 1.3547, AE Loss: 0.5817\n",
            "Epoch 2, D Loss: 0.3632, G Loss: 1.3691, AE Loss: 0.5800\n",
            "Epoch 2, D Loss: 0.8839, G Loss: 1.2682, AE Loss: 0.7243\n",
            "Epoch 2, D Loss: 1.0267, G Loss: 1.3874, AE Loss: 0.6480\n",
            "Epoch 2, D Loss: 0.4509, G Loss: 1.3298, AE Loss: 0.5970\n",
            "Epoch 2, D Loss: 1.6782, G Loss: 1.3922, AE Loss: 0.5543\n",
            "Epoch 2, D Loss: 0.2894, G Loss: 1.4762, AE Loss: 0.5825\n",
            "Epoch 2, D Loss: 0.3095, G Loss: 1.4426, AE Loss: 0.5481\n",
            "Epoch 2, D Loss: 1.0147, G Loss: 1.3905, AE Loss: 0.5046\n",
            "Epoch 2, D Loss: 0.4640, G Loss: 1.3238, AE Loss: 0.4442\n",
            "Epoch 2, D Loss: 1.1354, G Loss: 1.2597, AE Loss: 0.6437\n",
            "Epoch 2, D Loss: 0.8833, G Loss: 1.3450, AE Loss: 0.7083\n",
            "Epoch 2, D Loss: 0.4897, G Loss: 1.3849, AE Loss: 0.5820\n",
            "Epoch 2, D Loss: 1.3171, G Loss: 1.3406, AE Loss: 0.4713\n",
            "Epoch 2, D Loss: 1.0502, G Loss: 1.3743, AE Loss: 0.4816\n",
            "Epoch 2, D Loss: 0.7809, G Loss: 1.4405, AE Loss: 0.6100\n",
            "Epoch 2, D Loss: 0.7923, G Loss: 1.3743, AE Loss: 0.4966\n",
            "Epoch 2, D Loss: 1.3701, G Loss: 1.3417, AE Loss: 0.5541\n",
            "Epoch 2, D Loss: 0.5708, G Loss: 1.4208, AE Loss: 0.5654\n",
            "Epoch 2, D Loss: 0.9847, G Loss: 1.4423, AE Loss: 0.6425\n",
            "Epoch 2, D Loss: 0.6031, G Loss: 1.3650, AE Loss: 0.4960\n",
            "Epoch 2, D Loss: 1.0951, G Loss: 1.4074, AE Loss: 0.5476\n",
            "Epoch 2, D Loss: 0.6190, G Loss: 1.4190, AE Loss: 0.5257\n",
            "Epoch 2, D Loss: 0.7967, G Loss: 1.4664, AE Loss: 0.6463\n",
            "Epoch 2, D Loss: 0.9527, G Loss: 1.5806, AE Loss: 0.5082\n",
            "Epoch 2, D Loss: 1.2196, G Loss: 1.4032, AE Loss: 0.4952\n",
            "Epoch 2, D Loss: 0.9441, G Loss: 1.3907, AE Loss: 0.5377\n",
            "Epoch 2, D Loss: 0.6398, G Loss: 1.4294, AE Loss: 0.5156\n",
            "Epoch 2, D Loss: 1.1164, G Loss: 1.5499, AE Loss: 0.6026\n",
            "Epoch 2, D Loss: 0.3753, G Loss: 1.4698, AE Loss: 0.4849\n",
            "Epoch 2, D Loss: 0.2832, G Loss: 1.4555, AE Loss: 0.5835\n",
            "Epoch 2, D Loss: 0.9306, G Loss: 1.4062, AE Loss: 0.5125\n",
            "Epoch 2, D Loss: 0.4597, G Loss: 1.4836, AE Loss: 0.6093\n",
            "Epoch 2, D Loss: 0.2931, G Loss: 1.4894, AE Loss: 0.5534\n",
            "Epoch 2, D Loss: 0.5590, G Loss: 1.5607, AE Loss: 0.4960\n",
            "Epoch 2, D Loss: 0.7686, G Loss: 1.4327, AE Loss: 0.5035\n",
            "Epoch 2, D Loss: 0.2836, G Loss: 1.5092, AE Loss: 0.5065\n",
            "Epoch 2, D Loss: 0.6790, G Loss: 1.4640, AE Loss: 0.5503\n",
            "Epoch 2, D Loss: 0.5990, G Loss: 1.5155, AE Loss: 0.5572\n",
            "Epoch 2, D Loss: 1.1997, G Loss: 1.4266, AE Loss: 0.4937\n",
            "Epoch 2, D Loss: 0.3342, G Loss: 1.5260, AE Loss: 0.5552\n",
            "Epoch 2, D Loss: 0.4196, G Loss: 1.4629, AE Loss: 0.5958\n",
            "Epoch 2, D Loss: 0.5959, G Loss: 1.5105, AE Loss: 0.5338\n",
            "Epoch 2, D Loss: 0.5665, G Loss: 1.5564, AE Loss: 0.4639\n",
            "Epoch 2, D Loss: 0.8449, G Loss: 1.4467, AE Loss: 0.5569\n",
            "Epoch 2, D Loss: 0.5991, G Loss: 1.4837, AE Loss: 0.5056\n",
            "Epoch 2, D Loss: 1.1720, G Loss: 1.4701, AE Loss: 0.5322\n",
            "Epoch 2, D Loss: 0.2799, G Loss: 1.4545, AE Loss: 0.5440\n",
            "Epoch 2, D Loss: 0.4163, G Loss: 1.4171, AE Loss: 0.5403\n",
            "Epoch 2, D Loss: 0.6994, G Loss: 1.4489, AE Loss: 0.6087\n",
            "Epoch 2, D Loss: 0.7281, G Loss: 1.4513, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 0.9216, G Loss: 1.5708, AE Loss: 0.6057\n",
            "Epoch 2, D Loss: 0.9762, G Loss: 1.4592, AE Loss: 0.5165\n",
            "Epoch 2, D Loss: 0.5171, G Loss: 1.5525, AE Loss: 0.5909\n",
            "Epoch 2, D Loss: 0.3638, G Loss: 1.4108, AE Loss: 0.5972\n",
            "Epoch 2, D Loss: 0.6271, G Loss: 1.5038, AE Loss: 0.5211\n",
            "Epoch 2, D Loss: 0.6059, G Loss: 1.4819, AE Loss: 0.5002\n",
            "Epoch 2, D Loss: 0.3645, G Loss: 1.4699, AE Loss: 0.6100\n",
            "Epoch 2, D Loss: 0.4131, G Loss: 1.4262, AE Loss: 0.5465\n",
            "Epoch 2, D Loss: 0.4075, G Loss: 1.4915, AE Loss: 0.5482\n",
            "Epoch 2, D Loss: 0.3594, G Loss: 1.5668, AE Loss: 0.4914\n",
            "Epoch 2, D Loss: 0.8370, G Loss: 1.5365, AE Loss: 0.5971\n",
            "Epoch 2, D Loss: 0.6339, G Loss: 1.5297, AE Loss: 0.5441\n",
            "Epoch 2, D Loss: 0.3996, G Loss: 1.5220, AE Loss: 0.5502\n",
            "Epoch 2, D Loss: 0.3990, G Loss: 1.5424, AE Loss: 0.5435\n",
            "Epoch 2, D Loss: 0.7966, G Loss: 1.5428, AE Loss: 0.5706\n",
            "Epoch 2, D Loss: 0.2685, G Loss: 1.5357, AE Loss: 0.7047\n",
            "Epoch 2, D Loss: 0.2971, G Loss: 1.5746, AE Loss: 0.6385\n",
            "Epoch 2, D Loss: 1.2541, G Loss: 1.6168, AE Loss: 0.5482\n",
            "Epoch 2, D Loss: 0.5367, G Loss: 1.5185, AE Loss: 0.5552\n",
            "Epoch 2, D Loss: 0.4228, G Loss: 1.6354, AE Loss: 0.5183\n",
            "Epoch 2, D Loss: 0.3899, G Loss: 1.6102, AE Loss: 0.6142\n",
            "Epoch 2, D Loss: 0.4925, G Loss: 1.6002, AE Loss: 0.4820\n",
            "Epoch 2, D Loss: 0.2832, G Loss: 1.5956, AE Loss: 0.5574\n",
            "Epoch 2, D Loss: 0.4118, G Loss: 1.6886, AE Loss: 0.6012\n",
            "Epoch 2, D Loss: 0.7312, G Loss: 1.6470, AE Loss: 0.4460\n",
            "Epoch 2, D Loss: 0.4254, G Loss: 1.6167, AE Loss: 0.5048\n",
            "Epoch 2, D Loss: 0.9484, G Loss: 1.6311, AE Loss: 0.5501\n",
            "Epoch 2, D Loss: 0.3998, G Loss: 1.6888, AE Loss: 0.5033\n",
            "Epoch 2, D Loss: 0.2310, G Loss: 1.6782, AE Loss: 0.6066\n",
            "Epoch 2, D Loss: 0.5276, G Loss: 1.6935, AE Loss: 0.6182\n",
            "Epoch 2, D Loss: 0.5517, G Loss: 1.6382, AE Loss: 0.7101\n",
            "Epoch 2, D Loss: 0.3866, G Loss: 1.7229, AE Loss: 0.5043\n",
            "Epoch 2, D Loss: 0.4473, G Loss: 1.6625, AE Loss: 0.4968\n",
            "Epoch 2, D Loss: 0.2248, G Loss: 1.6695, AE Loss: 0.5132\n",
            "Epoch 2, D Loss: 0.6802, G Loss: 1.6596, AE Loss: 0.4844\n",
            "Epoch 2, D Loss: 0.5611, G Loss: 1.6560, AE Loss: 0.4750\n",
            "Epoch 2, D Loss: 0.3514, G Loss: 1.7145, AE Loss: 0.5748\n",
            "Epoch 2, D Loss: 1.1844, G Loss: 1.5994, AE Loss: 0.5766\n",
            "Epoch 2, D Loss: 0.7936, G Loss: 1.6709, AE Loss: 0.6019\n",
            "Epoch 2, D Loss: 0.2824, G Loss: 1.6818, AE Loss: 0.4730\n",
            "Epoch 2, D Loss: 0.2696, G Loss: 1.6340, AE Loss: 0.5330\n",
            "Epoch 2, D Loss: 0.4840, G Loss: 1.6015, AE Loss: 0.5690\n",
            "Epoch 2, D Loss: 1.2555, G Loss: 1.6048, AE Loss: 0.6325\n",
            "Epoch 2, D Loss: 0.3872, G Loss: 1.5647, AE Loss: 0.4837\n",
            "Epoch 2, D Loss: 0.7056, G Loss: 1.5922, AE Loss: 0.4835\n",
            "Epoch 2, D Loss: 0.6698, G Loss: 1.5149, AE Loss: 0.5168\n",
            "Epoch 2, D Loss: 0.6036, G Loss: 1.5649, AE Loss: 0.6185\n",
            "Epoch 2, D Loss: 0.6856, G Loss: 1.5706, AE Loss: 0.6208\n",
            "Epoch 2, D Loss: 0.6720, G Loss: 1.5172, AE Loss: 0.5132\n",
            "Epoch 2, D Loss: 0.3716, G Loss: 1.5831, AE Loss: 0.5735\n",
            "Epoch 2, D Loss: 0.4596, G Loss: 1.6016, AE Loss: 0.5262\n",
            "Epoch 2, D Loss: 0.9280, G Loss: 1.5601, AE Loss: 0.4779\n",
            "Epoch 2, D Loss: 0.4734, G Loss: 1.6128, AE Loss: 0.5114\n",
            "Epoch 2, D Loss: 0.5934, G Loss: 1.5748, AE Loss: 0.6096\n",
            "Epoch 2, D Loss: 0.8804, G Loss: 1.5526, AE Loss: 0.5301\n",
            "Epoch 2, D Loss: 0.6123, G Loss: 1.5280, AE Loss: 0.7382\n",
            "Epoch 2, D Loss: 0.4556, G Loss: 1.5111, AE Loss: 0.5869\n",
            "Epoch 2, D Loss: 0.5712, G Loss: 1.5189, AE Loss: 0.5159\n",
            "Epoch 2, D Loss: 0.6711, G Loss: 1.6252, AE Loss: 0.5411\n",
            "Epoch 2, D Loss: 0.5695, G Loss: 1.6330, AE Loss: 0.4729\n",
            "Epoch 2, D Loss: 0.8347, G Loss: 1.5630, AE Loss: 0.5615\n",
            "Epoch 2, D Loss: 0.9100, G Loss: 1.6137, AE Loss: 0.4978\n",
            "Epoch 2, D Loss: 0.4733, G Loss: 1.5727, AE Loss: 0.6399\n",
            "Epoch 2, D Loss: 0.7903, G Loss: 1.6431, AE Loss: 0.5277\n",
            "Epoch 2, D Loss: 0.5864, G Loss: 1.6496, AE Loss: 0.5220\n",
            "Epoch 2, D Loss: 0.3436, G Loss: 1.6581, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 0.4163, G Loss: 1.5039, AE Loss: 0.5370\n",
            "Epoch 2, D Loss: 0.9258, G Loss: 1.6310, AE Loss: 0.3749\n",
            "Epoch 2, D Loss: 0.6969, G Loss: 1.5289, AE Loss: 0.6177\n",
            "Epoch 2, D Loss: 0.7175, G Loss: 1.4984, AE Loss: 0.6393\n",
            "Epoch 2, D Loss: 0.6162, G Loss: 1.5510, AE Loss: 0.5165\n",
            "Epoch 2, D Loss: 0.8491, G Loss: 1.6424, AE Loss: 0.5940\n",
            "Epoch 2, D Loss: 0.8325, G Loss: 1.5171, AE Loss: 0.5620\n",
            "Epoch 2, D Loss: 0.3586, G Loss: 1.5322, AE Loss: 0.4604\n",
            "Epoch 2, D Loss: 0.8552, G Loss: 1.4248, AE Loss: 0.5305\n",
            "Epoch 2, D Loss: 0.7249, G Loss: 1.5434, AE Loss: 0.4774\n",
            "Epoch 2, D Loss: 0.6579, G Loss: 1.3143, AE Loss: 0.5214\n",
            "Epoch 2, D Loss: 0.6562, G Loss: 1.5651, AE Loss: 0.4904\n",
            "Epoch 2, D Loss: 0.6306, G Loss: 1.4966, AE Loss: 0.4911\n",
            "Epoch 2, D Loss: 0.8822, G Loss: 1.5553, AE Loss: 0.6068\n",
            "Epoch 2, D Loss: 0.3934, G Loss: 1.5378, AE Loss: 0.5173\n",
            "Epoch 2, D Loss: 0.4221, G Loss: 1.4685, AE Loss: 0.5810\n",
            "Epoch 2, D Loss: 0.7145, G Loss: 1.4546, AE Loss: 0.5550\n",
            "Epoch 2, D Loss: 0.7214, G Loss: 1.5748, AE Loss: 0.5155\n",
            "Epoch 2, D Loss: 0.6540, G Loss: 1.4808, AE Loss: 0.4592\n",
            "Epoch 2, D Loss: 0.6501, G Loss: 1.5155, AE Loss: 0.5433\n",
            "Epoch 2, D Loss: 1.5798, G Loss: 1.6115, AE Loss: 0.5546\n",
            "Epoch 2, D Loss: 0.3896, G Loss: 1.4735, AE Loss: 0.5362\n",
            "Epoch 2, D Loss: 0.5905, G Loss: 1.6148, AE Loss: 0.5009\n",
            "Epoch 2, D Loss: 0.6451, G Loss: 1.6951, AE Loss: 0.4763\n",
            "Epoch 2, D Loss: 0.3694, G Loss: 1.6623, AE Loss: 0.6119\n",
            "Epoch 2, D Loss: 1.0654, G Loss: 1.6512, AE Loss: 0.5668\n",
            "Epoch 2, D Loss: 0.2554, G Loss: 1.6501, AE Loss: 0.8266\n",
            "Epoch 2, D Loss: 0.5974, G Loss: 1.5692, AE Loss: 0.5319\n",
            "Epoch 2, D Loss: 0.8880, G Loss: 1.6622, AE Loss: 0.4809\n",
            "Epoch 2, D Loss: 0.2601, G Loss: 1.7702, AE Loss: 0.5815\n",
            "Epoch 2, D Loss: 0.3654, G Loss: 1.6943, AE Loss: 0.6122\n",
            "Epoch 2, D Loss: 1.3770, G Loss: 1.9043, AE Loss: 0.6006\n",
            "Epoch 2, D Loss: 0.3669, G Loss: 1.8119, AE Loss: 0.6720\n",
            "Epoch 2, D Loss: 0.7962, G Loss: 1.9973, AE Loss: 0.5173\n",
            "Epoch 2, D Loss: 0.9988, G Loss: 2.0260, AE Loss: 0.6659\n",
            "Epoch 2, D Loss: 0.3280, G Loss: 1.8949, AE Loss: 0.6287\n",
            "Epoch 2, D Loss: 1.2566, G Loss: 1.9884, AE Loss: 0.6426\n",
            "Epoch 2, D Loss: 0.6734, G Loss: 1.8369, AE Loss: 0.4949\n",
            "Epoch 2, D Loss: 0.9208, G Loss: 1.7269, AE Loss: 0.6137\n",
            "Epoch 2, D Loss: 0.9514, G Loss: 1.9484, AE Loss: 0.4564\n",
            "Epoch 2, D Loss: 1.0469, G Loss: 1.9673, AE Loss: 0.5913\n",
            "Epoch 2, D Loss: 0.4973, G Loss: 1.7097, AE Loss: 0.6005\n",
            "Epoch 2, D Loss: 0.9902, G Loss: 1.9989, AE Loss: 0.4355\n",
            "Epoch 2, D Loss: 1.4437, G Loss: 1.7310, AE Loss: 0.4557\n",
            "Epoch 2, D Loss: 0.7752, G Loss: 1.8732, AE Loss: 0.5957\n",
            "Epoch 2, D Loss: 0.5056, G Loss: 1.9037, AE Loss: 0.5387\n",
            "Epoch 2, D Loss: 1.1656, G Loss: 1.7708, AE Loss: 0.6331\n",
            "Epoch 2, D Loss: 0.6467, G Loss: 1.7790, AE Loss: 0.5146\n",
            "Epoch 2, D Loss: 0.5941, G Loss: 1.7490, AE Loss: 0.5126\n",
            "Epoch 2, D Loss: 0.7936, G Loss: 1.7867, AE Loss: 0.5468\n",
            "Epoch 2, D Loss: 0.8989, G Loss: 1.8048, AE Loss: 0.5872\n",
            "Epoch 2, D Loss: 0.8700, G Loss: 1.7155, AE Loss: 0.5376\n",
            "Epoch 2, D Loss: 0.6121, G Loss: 1.7708, AE Loss: 0.5252\n",
            "Epoch 2, D Loss: 1.7061, G Loss: 1.6896, AE Loss: 0.6191\n",
            "Epoch 2, D Loss: 0.3477, G Loss: 1.7366, AE Loss: 0.4577\n",
            "Epoch 2, D Loss: 0.8596, G Loss: 1.6991, AE Loss: 0.6013\n",
            "Epoch 2, D Loss: 0.8555, G Loss: 1.6036, AE Loss: 0.5532\n",
            "Epoch 2, D Loss: 1.2781, G Loss: 1.7181, AE Loss: 0.5211\n",
            "Epoch 2, D Loss: 1.2864, G Loss: 1.6187, AE Loss: 0.5095\n",
            "Epoch 2, D Loss: 0.3192, G Loss: 1.5567, AE Loss: 0.3800\n",
            "Epoch 2, D Loss: 0.6617, G Loss: 1.6282, AE Loss: 0.5284\n",
            "Epoch 2, D Loss: 0.5955, G Loss: 1.7045, AE Loss: 0.5121\n",
            "Epoch 2, D Loss: 0.8173, G Loss: 1.6725, AE Loss: 0.4907\n",
            "Epoch 2, D Loss: 0.6712, G Loss: 1.9142, AE Loss: 0.4933\n",
            "Epoch 2, D Loss: 0.4780, G Loss: 1.9605, AE Loss: 0.5492\n",
            "Epoch 2, D Loss: 0.7395, G Loss: 1.9155, AE Loss: 0.4794\n",
            "Epoch 2, D Loss: 0.7821, G Loss: 1.7470, AE Loss: 0.5171\n",
            "Epoch 2, D Loss: 1.1702, G Loss: 2.0404, AE Loss: 0.5335\n",
            "Epoch 2, D Loss: 0.5489, G Loss: 2.2681, AE Loss: 0.5530\n",
            "Epoch 2, D Loss: 0.6986, G Loss: 1.9945, AE Loss: 0.5140\n",
            "Epoch 2, D Loss: 0.7614, G Loss: 1.9549, AE Loss: 0.4987\n",
            "Epoch 2, D Loss: 0.2875, G Loss: 2.2096, AE Loss: 0.5999\n",
            "Epoch 2, D Loss: 0.4426, G Loss: 2.0374, AE Loss: 0.5660\n",
            "Epoch 2, D Loss: 0.4513, G Loss: 2.2659, AE Loss: 0.6323\n",
            "Epoch 2, D Loss: 0.6227, G Loss: 2.1413, AE Loss: 0.5347\n",
            "Epoch 2, D Loss: 0.4479, G Loss: 2.1257, AE Loss: 0.5300\n",
            "Epoch 2, D Loss: 0.1456, G Loss: 2.2026, AE Loss: 0.4846\n",
            "Epoch 2, D Loss: 1.1021, G Loss: 2.2985, AE Loss: 0.5610\n",
            "Epoch 2, D Loss: 0.6012, G Loss: 2.4793, AE Loss: 0.5771\n",
            "Epoch 2, D Loss: 0.3897, G Loss: 2.3245, AE Loss: 0.7444\n",
            "Epoch 2, D Loss: 0.3153, G Loss: 2.2616, AE Loss: 0.6255\n",
            "Epoch 2, D Loss: 0.4634, G Loss: 2.2061, AE Loss: 0.5464\n",
            "Epoch 2, D Loss: 0.5921, G Loss: 2.5234, AE Loss: 0.4955\n",
            "Epoch 2, D Loss: 0.5274, G Loss: 2.2630, AE Loss: 0.4941\n",
            "Epoch 2, D Loss: 0.4370, G Loss: 2.2936, AE Loss: 0.5540\n",
            "Epoch 2, D Loss: 0.6824, G Loss: 2.3728, AE Loss: 0.5960\n",
            "Epoch 2, D Loss: 0.1662, G Loss: 2.3644, AE Loss: 0.6392\n",
            "Epoch 2, D Loss: 0.2651, G Loss: 2.5304, AE Loss: 0.5143\n",
            "Epoch 2, D Loss: 0.5318, G Loss: 2.3693, AE Loss: 0.5739\n",
            "Epoch 2, D Loss: 0.4930, G Loss: 2.4603, AE Loss: 0.5617\n",
            "Epoch 2, D Loss: 0.3717, G Loss: 2.4294, AE Loss: 0.5089\n",
            "Epoch 2, D Loss: 0.9458, G Loss: 2.3118, AE Loss: 0.5055\n",
            "Epoch 2, D Loss: 0.7298, G Loss: 2.3201, AE Loss: 0.5655\n",
            "Epoch 2, D Loss: 0.5087, G Loss: 2.3327, AE Loss: 0.6740\n",
            "Epoch 2, D Loss: 0.4914, G Loss: 2.2573, AE Loss: 0.5740\n",
            "Epoch 2, D Loss: 0.6765, G Loss: 2.4484, AE Loss: 0.5235\n",
            "Epoch 2, D Loss: 1.0959, G Loss: 2.4040, AE Loss: 0.6255\n",
            "Epoch 2, D Loss: 0.2681, G Loss: 2.3547, AE Loss: 0.5446\n",
            "Epoch 2, D Loss: 1.0578, G Loss: 2.3401, AE Loss: 0.5967\n",
            "Epoch 2, D Loss: 0.7022, G Loss: 2.3630, AE Loss: 0.6616\n",
            "Epoch 2, D Loss: 0.6048, G Loss: 2.3768, AE Loss: 0.5117\n",
            "Epoch 2, D Loss: 0.6636, G Loss: 2.2569, AE Loss: 0.4539\n",
            "Epoch 2, D Loss: 0.8130, G Loss: 2.3301, AE Loss: 0.6464\n",
            "Epoch 2, D Loss: 0.6706, G Loss: 2.5035, AE Loss: 0.5747\n",
            "Epoch 2, D Loss: 0.3525, G Loss: 2.5273, AE Loss: 0.6474\n",
            "Epoch 2, D Loss: 0.8027, G Loss: 2.5105, AE Loss: 0.5371\n",
            "Epoch 2, D Loss: 0.7796, G Loss: 2.4505, AE Loss: 0.5770\n",
            "Epoch 2, D Loss: 0.7712, G Loss: 2.4267, AE Loss: 0.5149\n",
            "Epoch 2, D Loss: 0.1303, G Loss: 2.3637, AE Loss: 0.5580\n",
            "Epoch 2, D Loss: 0.2165, G Loss: 2.3410, AE Loss: 0.4873\n",
            "Epoch 2, D Loss: 0.8196, G Loss: 2.5087, AE Loss: 0.5045\n",
            "Epoch 2, D Loss: 0.7514, G Loss: 2.2227, AE Loss: 0.6235\n",
            "Epoch 2, D Loss: 0.9151, G Loss: 2.3315, AE Loss: 0.6018\n",
            "Epoch 2, D Loss: 0.6235, G Loss: 2.3376, AE Loss: 0.5256\n",
            "Epoch 2, D Loss: 0.6783, G Loss: 2.3932, AE Loss: 0.5385\n",
            "Epoch 2, D Loss: 0.2470, G Loss: 2.4843, AE Loss: 0.4286\n",
            "Epoch 2, D Loss: 0.6882, G Loss: 2.6266, AE Loss: 0.4839\n",
            "Epoch 2, D Loss: 0.6942, G Loss: 2.4437, AE Loss: 0.5322\n",
            "Epoch 2, D Loss: 0.1364, G Loss: 2.3881, AE Loss: 0.5555\n",
            "Epoch 2, D Loss: 1.1228, G Loss: 2.4715, AE Loss: 0.7702\n",
            "Epoch 2, D Loss: 0.3390, G Loss: 2.4173, AE Loss: 0.6390\n",
            "Epoch 2, D Loss: 0.3092, G Loss: 2.4407, AE Loss: 0.5558\n",
            "Epoch 2, D Loss: 0.1911, G Loss: 2.3169, AE Loss: 0.5657\n",
            "Epoch 2, D Loss: 0.4746, G Loss: 2.5500, AE Loss: 0.5380\n",
            "Epoch 2, D Loss: 0.2160, G Loss: 2.4577, AE Loss: 0.5290\n",
            "Epoch 2, D Loss: 0.4340, G Loss: 2.5056, AE Loss: 0.5458\n",
            "Epoch 2, D Loss: 0.2354, G Loss: 2.4383, AE Loss: 0.6315\n",
            "Epoch 2, D Loss: 0.5794, G Loss: 2.6077, AE Loss: 0.4539\n",
            "Epoch 2, D Loss: 0.2289, G Loss: 2.5539, AE Loss: 0.5325\n",
            "Epoch 2, D Loss: 0.1180, G Loss: 2.6091, AE Loss: 0.5863\n",
            "Epoch 2, D Loss: 0.7805, G Loss: 2.6053, AE Loss: 0.5974\n",
            "Epoch 2, D Loss: 0.2122, G Loss: 2.6383, AE Loss: 0.4494\n",
            "Epoch 2, D Loss: 0.4619, G Loss: 2.7140, AE Loss: 0.6192\n",
            "Epoch 2, D Loss: 0.1778, G Loss: 2.7492, AE Loss: 0.6184\n",
            "Epoch 2, D Loss: 0.4485, G Loss: 2.7958, AE Loss: 0.5894\n",
            "Epoch 2, D Loss: 1.2385, G Loss: 2.6702, AE Loss: 0.4252\n",
            "Epoch 2, D Loss: 0.4207, G Loss: 2.6604, AE Loss: 0.5146\n",
            "Epoch 2, D Loss: 0.7068, G Loss: 2.7084, AE Loss: 0.5477\n",
            "Epoch 2, D Loss: 0.6742, G Loss: 2.7079, AE Loss: 0.4555\n",
            "Epoch 2, D Loss: 0.0985, G Loss: 2.6863, AE Loss: 0.6009\n",
            "Epoch 2, D Loss: 0.1130, G Loss: 2.7412, AE Loss: 0.4694\n",
            "Epoch 2, D Loss: 0.4279, G Loss: 2.7397, AE Loss: 0.4870\n",
            "Epoch 2, D Loss: 0.6588, G Loss: 2.6647, AE Loss: 0.5995\n",
            "Epoch 2, D Loss: 0.5212, G Loss: 2.7786, AE Loss: 0.5167\n",
            "Epoch 2, D Loss: 0.4967, G Loss: 2.7738, AE Loss: 0.4695\n",
            "Epoch 2, D Loss: 0.2189, G Loss: 2.7531, AE Loss: 0.6158\n",
            "Epoch 2, D Loss: 0.0744, G Loss: 2.6823, AE Loss: 0.5765\n",
            "Epoch 2, D Loss: 0.2739, G Loss: 2.7169, AE Loss: 0.5487\n",
            "Epoch 2, D Loss: 0.4968, G Loss: 2.7165, AE Loss: 0.4881\n",
            "Epoch 2, D Loss: 0.1525, G Loss: 2.6951, AE Loss: 0.5875\n",
            "Epoch 2, D Loss: 0.8307, G Loss: 2.6879, AE Loss: 0.6703\n",
            "Epoch 2, D Loss: 0.1128, G Loss: 2.7084, AE Loss: 0.5871\n",
            "Epoch 2, D Loss: 0.1878, G Loss: 2.7925, AE Loss: 0.5030\n",
            "Epoch 2, D Loss: 0.2120, G Loss: 2.6484, AE Loss: 0.5808\n",
            "Epoch 2, D Loss: 0.2924, G Loss: 2.7650, AE Loss: 0.4889\n",
            "Epoch 2, D Loss: 0.5230, G Loss: 2.6670, AE Loss: 0.5119\n",
            "Epoch 2, D Loss: 0.0880, G Loss: 2.8055, AE Loss: 0.5511\n",
            "Epoch 2, D Loss: 0.3653, G Loss: 2.7285, AE Loss: 0.5401\n",
            "Epoch 2, D Loss: 0.5626, G Loss: 2.7903, AE Loss: 0.5098\n",
            "Epoch 2, D Loss: 0.4128, G Loss: 2.6753, AE Loss: 0.5811\n",
            "Epoch 2, D Loss: 0.2387, G Loss: 2.6689, AE Loss: 0.6147\n",
            "Epoch 2, D Loss: 0.3127, G Loss: 2.6917, AE Loss: 0.6089\n",
            "Epoch 2, D Loss: 0.0823, G Loss: 2.7695, AE Loss: 0.5573\n",
            "Epoch 2, D Loss: 0.0850, G Loss: 2.6918, AE Loss: 0.4988\n",
            "Epoch 2, D Loss: 0.0902, G Loss: 2.7842, AE Loss: 0.5296\n",
            "Epoch 2, D Loss: 0.6456, G Loss: 2.8576, AE Loss: 0.5758\n",
            "Epoch 2, D Loss: 0.6108, G Loss: 2.8362, AE Loss: 0.5427\n",
            "Epoch 2, D Loss: 0.3486, G Loss: 2.7396, AE Loss: 0.5006\n",
            "Epoch 2, D Loss: 0.5244, G Loss: 2.7044, AE Loss: 0.4843\n",
            "Epoch 2, D Loss: 0.3976, G Loss: 2.7553, AE Loss: 0.4888\n",
            "Epoch 2, D Loss: 0.1312, G Loss: 2.8133, AE Loss: 0.6640\n",
            "Epoch 2, D Loss: 0.6269, G Loss: 2.7584, AE Loss: 0.5142\n",
            "Epoch 2, D Loss: 0.2158, G Loss: 2.7317, AE Loss: 0.4692\n",
            "Epoch 2, D Loss: 0.6159, G Loss: 2.8537, AE Loss: 0.4648\n",
            "Epoch 2, D Loss: 0.3137, G Loss: 2.8980, AE Loss: 0.5486\n",
            "Epoch 2, D Loss: 1.0689, G Loss: 2.8056, AE Loss: 0.4831\n",
            "Epoch 2, D Loss: 0.2096, G Loss: 2.6909, AE Loss: 0.5557\n",
            "Epoch 2, D Loss: 0.2861, G Loss: 2.7625, AE Loss: 0.4956\n",
            "Epoch 2, D Loss: 0.3071, G Loss: 2.6816, AE Loss: 0.5589\n",
            "Epoch 2, D Loss: 0.1331, G Loss: 2.6903, AE Loss: 0.5292\n",
            "Epoch 2, D Loss: 0.4506, G Loss: 2.7570, AE Loss: 0.5109\n",
            "Epoch 2, D Loss: 0.2337, G Loss: 2.6605, AE Loss: 0.5542\n",
            "Epoch 2, D Loss: 0.2947, G Loss: 2.4802, AE Loss: 0.4006\n",
            "Epoch 2, D Loss: 0.3513, G Loss: 2.5952, AE Loss: 0.5254\n",
            "Epoch 2, D Loss: 0.1596, G Loss: 2.5187, AE Loss: 0.6587\n",
            "Epoch 2, D Loss: 0.1468, G Loss: 2.4542, AE Loss: 0.5174\n",
            "Epoch 2, D Loss: 0.1929, G Loss: 2.4977, AE Loss: 0.4964\n",
            "Epoch 2, D Loss: 0.1748, G Loss: 2.4863, AE Loss: 0.4936\n",
            "Epoch 2, D Loss: 0.2046, G Loss: 2.4077, AE Loss: 0.5382\n",
            "Epoch 2, D Loss: 0.3159, G Loss: 2.3347, AE Loss: 0.6108\n",
            "Epoch 2, D Loss: 0.2039, G Loss: 2.4083, AE Loss: 0.5677\n",
            "Epoch 2, D Loss: 0.2795, G Loss: 2.2894, AE Loss: 0.6525\n",
            "Epoch 2, D Loss: 0.1932, G Loss: 2.3887, AE Loss: 0.5788\n",
            "Epoch 2, D Loss: 0.6929, G Loss: 2.1420, AE Loss: 0.4664\n",
            "Epoch 2, D Loss: 0.5066, G Loss: 2.0959, AE Loss: 0.6105\n",
            "Epoch 2, D Loss: 0.1541, G Loss: 2.1026, AE Loss: 0.5684\n",
            "Epoch 2, D Loss: 0.2613, G Loss: 2.0848, AE Loss: 0.4966\n",
            "Epoch 2, D Loss: 0.4069, G Loss: 1.8749, AE Loss: 0.6252\n",
            "Epoch 2, D Loss: 0.2195, G Loss: 2.0314, AE Loss: 0.6147\n",
            "Epoch 2, D Loss: 0.3057, G Loss: 1.9693, AE Loss: 0.5837\n",
            "Epoch 2, D Loss: 0.2242, G Loss: 1.7798, AE Loss: 0.5526\n",
            "Epoch 2, D Loss: 0.4991, G Loss: 1.7954, AE Loss: 0.5633\n",
            "Epoch 2, D Loss: 0.7033, G Loss: 1.8693, AE Loss: 0.5308\n",
            "Epoch 2, D Loss: 0.3472, G Loss: 1.9899, AE Loss: 0.5401\n",
            "Epoch 2, D Loss: 0.8062, G Loss: 1.7755, AE Loss: 0.5822\n",
            "Epoch 2, D Loss: 0.7023, G Loss: 1.5413, AE Loss: 0.5808\n",
            "Epoch 2, D Loss: 0.4514, G Loss: 1.5941, AE Loss: 0.6916\n",
            "Epoch 2, D Loss: 0.6351, G Loss: 1.6411, AE Loss: 0.5013\n",
            "Epoch 2, D Loss: 0.7047, G Loss: 1.4238, AE Loss: 0.5072\n",
            "Epoch 2, D Loss: 0.4751, G Loss: 1.4545, AE Loss: 0.4640\n",
            "Epoch 2, D Loss: 0.7057, G Loss: 1.3825, AE Loss: 0.5705\n",
            "Epoch 2, D Loss: 0.3803, G Loss: 1.4667, AE Loss: 0.5456\n",
            "Epoch 2, D Loss: 0.5886, G Loss: 1.6869, AE Loss: 0.4506\n",
            "Epoch 2, D Loss: 0.4829, G Loss: 1.5127, AE Loss: 0.6497\n",
            "Epoch 2, D Loss: 0.5105, G Loss: 1.5883, AE Loss: 0.4560\n",
            "Epoch 2, D Loss: 0.6558, G Loss: 1.4283, AE Loss: 0.5028\n",
            "Epoch 2, D Loss: 0.9427, G Loss: 1.2358, AE Loss: 0.6746\n",
            "Epoch 2, D Loss: 1.2965, G Loss: 1.1750, AE Loss: 0.6647\n",
            "Epoch 2, D Loss: 0.4181, G Loss: 1.4158, AE Loss: 0.5085\n",
            "Epoch 2, D Loss: 0.6793, G Loss: 1.5678, AE Loss: 0.5475\n",
            "Epoch 2, D Loss: 0.6705, G Loss: 1.1958, AE Loss: 0.6116\n",
            "Epoch 2, D Loss: 1.1272, G Loss: 1.3439, AE Loss: 0.8006\n",
            "Epoch 2, D Loss: 1.0504, G Loss: 1.1770, AE Loss: 0.4486\n",
            "Epoch 2, D Loss: 1.7890, G Loss: 1.0519, AE Loss: 0.6891\n",
            "Epoch 2, D Loss: 0.5410, G Loss: 1.3335, AE Loss: 0.4436\n",
            "Epoch 2, D Loss: 0.8055, G Loss: 0.9867, AE Loss: 0.6416\n",
            "Epoch 2, D Loss: 0.7749, G Loss: 1.1121, AE Loss: 0.7041\n",
            "Epoch 2, D Loss: 1.1314, G Loss: 1.1479, AE Loss: 0.5554\n",
            "Epoch 2, D Loss: 0.9062, G Loss: 0.8794, AE Loss: 0.6643\n",
            "Epoch 2, D Loss: 0.7565, G Loss: 1.1317, AE Loss: 0.6431\n",
            "Epoch 2, D Loss: 1.2784, G Loss: 1.0969, AE Loss: 0.6641\n",
            "Epoch 2, D Loss: 1.2114, G Loss: 1.1650, AE Loss: 0.5827\n",
            "Epoch 2, D Loss: 0.5901, G Loss: 1.3030, AE Loss: 0.5471\n",
            "Epoch 2, D Loss: 0.9905, G Loss: 1.1391, AE Loss: 0.4945\n",
            "Epoch 2, D Loss: 0.5903, G Loss: 1.4022, AE Loss: 0.4828\n",
            "Epoch 2, D Loss: 0.9648, G Loss: 1.2072, AE Loss: 0.5469\n",
            "Epoch 2, D Loss: 0.7320, G Loss: 1.2154, AE Loss: 0.4564\n",
            "Epoch 2, D Loss: 0.8461, G Loss: 1.0612, AE Loss: 0.6249\n",
            "Epoch 2, D Loss: 1.0018, G Loss: 1.1886, AE Loss: 0.5134\n",
            "Epoch 2, D Loss: 1.3025, G Loss: 1.2610, AE Loss: 0.5569\n",
            "Epoch 2, D Loss: 1.3328, G Loss: 0.9917, AE Loss: 0.5180\n",
            "Epoch 2, D Loss: 0.5997, G Loss: 1.2491, AE Loss: 0.6309\n",
            "Epoch 2, D Loss: 1.3240, G Loss: 1.0741, AE Loss: 0.5715\n",
            "Epoch 2, D Loss: 1.1731, G Loss: 1.0596, AE Loss: 0.6523\n",
            "Epoch 2, D Loss: 0.7124, G Loss: 1.1114, AE Loss: 0.4763\n",
            "Epoch 2, D Loss: 1.4488, G Loss: 1.2659, AE Loss: 0.5430\n",
            "Epoch 2, D Loss: 1.0024, G Loss: 1.2878, AE Loss: 0.5426\n",
            "Epoch 2, D Loss: 1.5375, G Loss: 1.3389, AE Loss: 0.5274\n",
            "Epoch 2, D Loss: 0.9131, G Loss: 1.5044, AE Loss: 0.6705\n",
            "Epoch 2, D Loss: 1.1183, G Loss: 1.4782, AE Loss: 0.4859\n",
            "Epoch 2, D Loss: 0.7866, G Loss: 1.4442, AE Loss: 0.6387\n",
            "Epoch 2, D Loss: 0.6377, G Loss: 1.0583, AE Loss: 0.6175\n",
            "Epoch 2, D Loss: 1.9426, G Loss: 1.2599, AE Loss: 0.5421\n",
            "Epoch 2, D Loss: 1.2909, G Loss: 1.3155, AE Loss: 0.5625\n",
            "Epoch 2, D Loss: 1.6382, G Loss: 1.3779, AE Loss: 0.8206\n",
            "Epoch 2, D Loss: 1.0372, G Loss: 1.1830, AE Loss: 0.4665\n",
            "Epoch 2, D Loss: 0.5576, G Loss: 1.3647, AE Loss: 0.6570\n",
            "Epoch 2, D Loss: 1.2497, G Loss: 0.9892, AE Loss: 0.5554\n",
            "Epoch 2, D Loss: 1.3885, G Loss: 1.0866, AE Loss: 0.5925\n",
            "Epoch 2, D Loss: 0.5233, G Loss: 1.3547, AE Loss: 0.6101\n",
            "Epoch 2, D Loss: 1.0021, G Loss: 1.5553, AE Loss: 0.5605\n",
            "Epoch 2, D Loss: 1.5202, G Loss: 1.0523, AE Loss: 0.5687\n",
            "Epoch 2, D Loss: 2.0213, G Loss: 0.9934, AE Loss: 0.4509\n",
            "Epoch 2, D Loss: 0.8886, G Loss: 1.4331, AE Loss: 0.4978\n",
            "Epoch 2, D Loss: 1.4649, G Loss: 1.3493, AE Loss: 0.5316\n",
            "Epoch 2, D Loss: 0.4741, G Loss: 1.5372, AE Loss: 0.5128\n",
            "Epoch 2, D Loss: 0.7287, G Loss: 1.3082, AE Loss: 0.6586\n",
            "Epoch 2, D Loss: 1.4089, G Loss: 1.2402, AE Loss: 0.4476\n",
            "Epoch 2, D Loss: 0.5312, G Loss: 1.4363, AE Loss: 0.5274\n",
            "Epoch 2, D Loss: 0.6592, G Loss: 1.5112, AE Loss: 0.6109\n",
            "Epoch 2, D Loss: 0.4705, G Loss: 1.5696, AE Loss: 0.6312\n",
            "Epoch 2, D Loss: 1.6513, G Loss: 1.3278, AE Loss: 0.5716\n",
            "Epoch 2, D Loss: 0.5661, G Loss: 1.2087, AE Loss: 0.6196\n",
            "Epoch 2, D Loss: 0.7370, G Loss: 1.5328, AE Loss: 0.4634\n",
            "Epoch 2, D Loss: 1.1029, G Loss: 1.2952, AE Loss: 0.6533\n",
            "Epoch 2, D Loss: 0.5966, G Loss: 1.2604, AE Loss: 0.6161\n",
            "Epoch 2, D Loss: 1.1757, G Loss: 1.5591, AE Loss: 0.5906\n",
            "Epoch 2, D Loss: 0.7190, G Loss: 1.4235, AE Loss: 0.6139\n",
            "Epoch 2, D Loss: 1.6571, G Loss: 0.9511, AE Loss: 0.4967\n",
            "Epoch 2, D Loss: 1.5895, G Loss: 1.5006, AE Loss: 0.5065\n",
            "Epoch 2, D Loss: 1.1580, G Loss: 1.4195, AE Loss: 0.5358\n",
            "Epoch 2, D Loss: 0.5478, G Loss: 1.4950, AE Loss: 0.5937\n",
            "Epoch 2, D Loss: 1.0471, G Loss: 1.0368, AE Loss: 0.6504\n",
            "Epoch 2, D Loss: 0.9134, G Loss: 1.4377, AE Loss: 0.5555\n",
            "Epoch 2, D Loss: 1.1839, G Loss: 1.6405, AE Loss: 0.7529\n",
            "Epoch 2, D Loss: 0.9679, G Loss: 1.5804, AE Loss: 0.5531\n",
            "Epoch 2, D Loss: 1.1891, G Loss: 1.5487, AE Loss: 0.5716\n",
            "Epoch 2, D Loss: 1.7754, G Loss: 1.6223, AE Loss: 0.4911\n",
            "Epoch 2, D Loss: 2.0529, G Loss: 1.8225, AE Loss: 0.6012\n",
            "Epoch 2, D Loss: 0.8839, G Loss: 1.7883, AE Loss: 0.5987\n",
            "Epoch 2, D Loss: 1.1720, G Loss: 1.6074, AE Loss: 0.5067\n",
            "Epoch 2, D Loss: 1.7293, G Loss: 1.8825, AE Loss: 0.5570\n",
            "Epoch 2, D Loss: 0.5695, G Loss: 1.6282, AE Loss: 0.5500\n",
            "Epoch 2, D Loss: 0.8676, G Loss: 1.6192, AE Loss: 0.5211\n",
            "Epoch 2, D Loss: 1.0027, G Loss: 1.4382, AE Loss: 0.5338\n",
            "Epoch 2, D Loss: 0.2836, G Loss: 1.8747, AE Loss: 0.5648\n",
            "Epoch 2, D Loss: 1.0063, G Loss: 1.6772, AE Loss: 0.5803\n",
            "Epoch 2, D Loss: 0.6423, G Loss: 1.5516, AE Loss: 0.4685\n",
            "Epoch 2, D Loss: 1.2726, G Loss: 1.9319, AE Loss: 0.5169\n",
            "Epoch 2, D Loss: 0.8659, G Loss: 1.9053, AE Loss: 0.4449\n",
            "Epoch 2, D Loss: 0.4008, G Loss: 1.7425, AE Loss: 0.6239\n",
            "Epoch 2, D Loss: 1.9039, G Loss: 1.4012, AE Loss: 0.5171\n",
            "Epoch 2, D Loss: 1.0384, G Loss: 1.4681, AE Loss: 0.6286\n",
            "Epoch 2, D Loss: 1.1489, G Loss: 1.3508, AE Loss: 0.4607\n",
            "Epoch 2, D Loss: 1.2969, G Loss: 1.6098, AE Loss: 0.5720\n",
            "Epoch 2, D Loss: 0.7496, G Loss: 1.3431, AE Loss: 0.6168\n",
            "Epoch 2, D Loss: 1.2869, G Loss: 1.2006, AE Loss: 0.5653\n",
            "Epoch 2, D Loss: 1.9621, G Loss: 1.1493, AE Loss: 0.4830\n",
            "Epoch 2, D Loss: 1.6190, G Loss: 0.9696, AE Loss: 0.5389\n",
            "Epoch 2, D Loss: 1.9621, G Loss: 0.9837, AE Loss: 0.4931\n",
            "Epoch 2, D Loss: 2.8431, G Loss: 0.7877, AE Loss: 0.7115\n",
            "Epoch 2, D Loss: 0.8530, G Loss: 1.1272, AE Loss: 0.7842\n",
            "Epoch 2, D Loss: 2.4562, G Loss: 0.9088, AE Loss: 0.5185\n",
            "Epoch 2, D Loss: 1.3458, G Loss: 1.1638, AE Loss: 0.5575\n",
            "Epoch 2, D Loss: 1.6127, G Loss: 1.0435, AE Loss: 0.4223\n",
            "Epoch 2, D Loss: 1.7300, G Loss: 1.2487, AE Loss: 0.5534\n",
            "Epoch 2, D Loss: 1.0974, G Loss: 1.3110, AE Loss: 0.5643\n",
            "Epoch 2, D Loss: 1.4829, G Loss: 1.4491, AE Loss: 0.5506\n",
            "Epoch 2, D Loss: 0.9187, G Loss: 1.7268, AE Loss: 0.6526\n",
            "Epoch 2, D Loss: 2.3864, G Loss: 1.5326, AE Loss: 0.5470\n",
            "Epoch 2, D Loss: 1.9593, G Loss: 1.4081, AE Loss: 0.5409\n",
            "Epoch 2, D Loss: 1.2905, G Loss: 1.4945, AE Loss: 0.4487\n",
            "Epoch 2, D Loss: 1.6882, G Loss: 1.6924, AE Loss: 0.6214\n",
            "Epoch 2, D Loss: 1.3127, G Loss: 1.5353, AE Loss: 0.4284\n",
            "Epoch 2, D Loss: 0.6654, G Loss: 1.6892, AE Loss: 0.4663\n",
            "Epoch 2, D Loss: 0.6467, G Loss: 1.5362, AE Loss: 0.6381\n",
            "Epoch 2, D Loss: 2.2251, G Loss: 1.5115, AE Loss: 0.4819\n",
            "Epoch 2, D Loss: 1.5247, G Loss: 1.7552, AE Loss: 0.4486\n",
            "Epoch 2, D Loss: 1.8144, G Loss: 1.5248, AE Loss: 0.6240\n",
            "Epoch 2, D Loss: 0.8742, G Loss: 1.2745, AE Loss: 0.4680\n",
            "Epoch 2, D Loss: 0.8938, G Loss: 1.4235, AE Loss: 0.4851\n",
            "Epoch 2, D Loss: 1.5491, G Loss: 1.6043, AE Loss: 0.8242\n",
            "Epoch 2, D Loss: 1.2716, G Loss: 1.5001, AE Loss: 0.6371\n",
            "Epoch 2, D Loss: 1.5518, G Loss: 1.7231, AE Loss: 0.5616\n",
            "Epoch 2, D Loss: 1.0199, G Loss: 1.8583, AE Loss: 0.6446\n",
            "Epoch 2, D Loss: 1.2171, G Loss: 1.6450, AE Loss: 0.5016\n",
            "Epoch 2, D Loss: 0.8340, G Loss: 1.8038, AE Loss: 0.4568\n",
            "Epoch 2, D Loss: 1.1302, G Loss: 1.8203, AE Loss: 0.5172\n",
            "Epoch 2, D Loss: 1.6879, G Loss: 1.8660, AE Loss: 0.6019\n",
            "Epoch 2, D Loss: 0.9073, G Loss: 1.5869, AE Loss: 0.5158\n",
            "Epoch 2, D Loss: 1.6915, G Loss: 1.6176, AE Loss: 0.6351\n",
            "Epoch 2, D Loss: 1.3256, G Loss: 1.6098, AE Loss: 0.5104\n",
            "Epoch 2, D Loss: 0.7066, G Loss: 1.6730, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 0.6866, G Loss: 1.6507, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 1.1062, G Loss: 1.7418, AE Loss: 0.5919\n",
            "Epoch 2, D Loss: 2.6659, G Loss: 1.6120, AE Loss: 0.4527\n",
            "Epoch 2, D Loss: 0.8850, G Loss: 1.6043, AE Loss: 0.5411\n",
            "Epoch 2, D Loss: 0.8109, G Loss: 1.7409, AE Loss: 0.5710\n",
            "Epoch 2, D Loss: 0.7073, G Loss: 1.6967, AE Loss: 0.7028\n",
            "Epoch 2, D Loss: 1.5509, G Loss: 1.8430, AE Loss: 0.5017\n",
            "Epoch 2, D Loss: 0.9818, G Loss: 1.6085, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 0.7756, G Loss: 1.8194, AE Loss: 0.6137\n",
            "Epoch 2, D Loss: 0.6318, G Loss: 1.8378, AE Loss: 0.5754\n",
            "Epoch 2, D Loss: 1.7037, G Loss: 1.9254, AE Loss: 0.5006\n",
            "Epoch 2, D Loss: 0.8213, G Loss: 1.8607, AE Loss: 0.5370\n",
            "Epoch 2, D Loss: 1.2494, G Loss: 1.5968, AE Loss: 0.5299\n",
            "Epoch 2, D Loss: 1.0474, G Loss: 1.7607, AE Loss: 0.5528\n",
            "Epoch 2, D Loss: 1.2185, G Loss: 1.6115, AE Loss: 0.6324\n",
            "Epoch 2, D Loss: 0.5689, G Loss: 1.6293, AE Loss: 0.4588\n",
            "Epoch 2, D Loss: 0.5052, G Loss: 1.5140, AE Loss: 0.4880\n",
            "Epoch 2, D Loss: 1.4213, G Loss: 1.4483, AE Loss: 0.6696\n",
            "Epoch 2, D Loss: 0.9758, G Loss: 1.6459, AE Loss: 0.5256\n",
            "Epoch 2, D Loss: 0.8111, G Loss: 1.4632, AE Loss: 0.5274\n",
            "Epoch 2, D Loss: 0.7920, G Loss: 1.4734, AE Loss: 0.5584\n",
            "Epoch 2, D Loss: 1.0931, G Loss: 1.4619, AE Loss: 0.6518\n",
            "Epoch 2, D Loss: 0.7497, G Loss: 1.4763, AE Loss: 0.6281\n",
            "Epoch 2, D Loss: 1.9032, G Loss: 1.7481, AE Loss: 0.5346\n",
            "Epoch 2, D Loss: 1.3861, G Loss: 1.7670, AE Loss: 0.4553\n",
            "Epoch 2, D Loss: 0.7486, G Loss: 1.7323, AE Loss: 0.5381\n",
            "Epoch 2, D Loss: 1.7785, G Loss: 1.6828, AE Loss: 0.5639\n",
            "Epoch 2, D Loss: 1.8192, G Loss: 1.7798, AE Loss: 0.5679\n",
            "Epoch 2, D Loss: 0.2526, G Loss: 1.8058, AE Loss: 0.4488\n",
            "Epoch 2, D Loss: 0.9210, G Loss: 1.7160, AE Loss: 0.6828\n",
            "Epoch 2, D Loss: 0.5089, G Loss: 1.8878, AE Loss: 0.4967\n",
            "Epoch 2, D Loss: 0.9115, G Loss: 1.6332, AE Loss: 0.4776\n",
            "Epoch 2, D Loss: 1.9645, G Loss: 1.7244, AE Loss: 0.5442\n",
            "Epoch 2, D Loss: 0.7007, G Loss: 1.7679, AE Loss: 0.6361\n",
            "Epoch 2, D Loss: 0.6134, G Loss: 1.6923, AE Loss: 0.6117\n",
            "Epoch 2, D Loss: 1.2119, G Loss: 1.9005, AE Loss: 0.5055\n",
            "Epoch 2, D Loss: 1.1586, G Loss: 1.6498, AE Loss: 0.5569\n",
            "Epoch 2, D Loss: 0.9412, G Loss: 1.6476, AE Loss: 0.5194\n",
            "Epoch 2, D Loss: 0.6517, G Loss: 1.6334, AE Loss: 0.4670\n",
            "Epoch 2, D Loss: 0.9224, G Loss: 1.6488, AE Loss: 0.6034\n",
            "Epoch 2, D Loss: 1.3656, G Loss: 1.7800, AE Loss: 0.5326\n",
            "Epoch 2, D Loss: 0.4560, G Loss: 1.6495, AE Loss: 0.6693\n",
            "Epoch 2, D Loss: 1.0899, G Loss: 1.7038, AE Loss: 0.6152\n",
            "Epoch 2, D Loss: 0.6553, G Loss: 1.4073, AE Loss: 0.5650\n",
            "Epoch 2, D Loss: 0.4757, G Loss: 1.4172, AE Loss: 0.5111\n",
            "Epoch 2, D Loss: 1.9047, G Loss: 1.5898, AE Loss: 0.6018\n",
            "Epoch 2, D Loss: 1.1218, G Loss: 1.5107, AE Loss: 0.4690\n",
            "Epoch 2, D Loss: 0.7322, G Loss: 1.5534, AE Loss: 0.6230\n",
            "Epoch 2, D Loss: 2.0480, G Loss: 1.5758, AE Loss: 0.6066\n",
            "Epoch 2, D Loss: 0.7073, G Loss: 1.5645, AE Loss: 0.5247\n",
            "Epoch 2, D Loss: 1.0620, G Loss: 1.5056, AE Loss: 0.6061\n",
            "Epoch 2, D Loss: 1.6308, G Loss: 1.5522, AE Loss: 0.4237\n",
            "Epoch 2, D Loss: 0.9447, G Loss: 1.5681, AE Loss: 0.5208\n",
            "Epoch 2, D Loss: 0.6594, G Loss: 1.4591, AE Loss: 0.4169\n",
            "Epoch 2, D Loss: 1.8277, G Loss: 1.4747, AE Loss: 0.4744\n",
            "Epoch 2, D Loss: 0.8126, G Loss: 1.4087, AE Loss: 0.4551\n",
            "Epoch 2, D Loss: 1.0848, G Loss: 1.5866, AE Loss: 0.5392\n",
            "Epoch 2, D Loss: 0.9515, G Loss: 1.6363, AE Loss: 0.5001\n",
            "Epoch 2, D Loss: 0.7404, G Loss: 1.6010, AE Loss: 0.5714\n",
            "Epoch 2, D Loss: 1.3654, G Loss: 1.4486, AE Loss: 0.6131\n",
            "Epoch 2, D Loss: 0.5893, G Loss: 1.4913, AE Loss: 0.5642\n",
            "Epoch 2, D Loss: 0.9565, G Loss: 1.5934, AE Loss: 0.4748\n",
            "Epoch 2, D Loss: 0.4504, G Loss: 1.5251, AE Loss: 0.6210\n",
            "Epoch 2, D Loss: 0.7161, G Loss: 1.4854, AE Loss: 0.6715\n",
            "Epoch 2, D Loss: 1.5748, G Loss: 1.4927, AE Loss: 0.7475\n",
            "Epoch 2, D Loss: 1.0675, G Loss: 1.6858, AE Loss: 0.5558\n",
            "Epoch 2, D Loss: 0.7059, G Loss: 1.7358, AE Loss: 0.6421\n",
            "Epoch 2, D Loss: 1.3896, G Loss: 1.5769, AE Loss: 0.5487\n",
            "Epoch 2, D Loss: 0.8984, G Loss: 1.7762, AE Loss: 0.5809\n",
            "Epoch 2, D Loss: 2.0808, G Loss: 1.6447, AE Loss: 0.4280\n",
            "Epoch 2, D Loss: 0.6147, G Loss: 1.8170, AE Loss: 0.6614\n",
            "Epoch 2, D Loss: 0.6076, G Loss: 1.8642, AE Loss: 0.4627\n",
            "Epoch 2, D Loss: 0.9771, G Loss: 1.7290, AE Loss: 0.6568\n",
            "Epoch 2, D Loss: 0.2812, G Loss: 1.6181, AE Loss: 0.5370\n",
            "Epoch 2, D Loss: 0.2657, G Loss: 1.7110, AE Loss: 0.6492\n",
            "Epoch 2, D Loss: 1.5793, G Loss: 1.8045, AE Loss: 0.5669\n",
            "Epoch 2, D Loss: 0.8406, G Loss: 1.7559, AE Loss: 0.5410\n",
            "Epoch 2, D Loss: 0.8002, G Loss: 1.7049, AE Loss: 0.4915\n",
            "Epoch 2, D Loss: 0.9016, G Loss: 1.7011, AE Loss: 0.5135\n",
            "Epoch 2, D Loss: 0.8462, G Loss: 1.8261, AE Loss: 0.5666\n",
            "Epoch 2, D Loss: 0.4806, G Loss: 1.8336, AE Loss: 0.6095\n",
            "Epoch 2, D Loss: 1.5256, G Loss: 1.7741, AE Loss: 0.4931\n",
            "Epoch 2, D Loss: 0.8529, G Loss: 1.7807, AE Loss: 0.5119\n",
            "Epoch 2, D Loss: 0.3648, G Loss: 1.8283, AE Loss: 0.7295\n",
            "Epoch 2, D Loss: 0.9714, G Loss: 1.7407, AE Loss: 0.6334\n",
            "Epoch 2, D Loss: 0.7584, G Loss: 1.8188, AE Loss: 0.7169\n",
            "Epoch 2, D Loss: 0.9735, G Loss: 1.5989, AE Loss: 0.6018\n",
            "Epoch 2, D Loss: 0.7567, G Loss: 1.7504, AE Loss: 0.4516\n",
            "Epoch 2, D Loss: 0.6292, G Loss: 1.8199, AE Loss: 0.5940\n",
            "Epoch 2, D Loss: 0.7766, G Loss: 1.8429, AE Loss: 0.5178\n",
            "Epoch 2, D Loss: 1.4864, G Loss: 1.7685, AE Loss: 0.4455\n",
            "Epoch 2, D Loss: 0.8406, G Loss: 1.7169, AE Loss: 0.5656\n",
            "Epoch 2, D Loss: 0.9778, G Loss: 1.8427, AE Loss: 0.6493\n",
            "Epoch 2, D Loss: 0.6859, G Loss: 1.7879, AE Loss: 0.4979\n",
            "Epoch 2, D Loss: 0.2942, G Loss: 1.8444, AE Loss: 0.5301\n",
            "Epoch 2, D Loss: 0.9788, G Loss: 1.6955, AE Loss: 0.6085\n",
            "Epoch 2, D Loss: 1.1054, G Loss: 1.9797, AE Loss: 0.5223\n",
            "Epoch 2, D Loss: 0.6756, G Loss: 1.7709, AE Loss: 0.5558\n",
            "Epoch 2, D Loss: 0.9291, G Loss: 1.8339, AE Loss: 0.5776\n",
            "Epoch 2, D Loss: 0.6155, G Loss: 1.8056, AE Loss: 0.5732\n",
            "Epoch 2, D Loss: 1.4924, G Loss: 1.8316, AE Loss: 0.5607\n",
            "Epoch 2, D Loss: 0.7169, G Loss: 1.8406, AE Loss: 0.6166\n",
            "Epoch 2, D Loss: 0.9802, G Loss: 2.0555, AE Loss: 0.6009\n",
            "Epoch 2, D Loss: 0.2784, G Loss: 1.8248, AE Loss: 0.5087\n",
            "Epoch 2, D Loss: 0.8860, G Loss: 1.8215, AE Loss: 0.5320\n",
            "Epoch 2, D Loss: 1.2182, G Loss: 1.8997, AE Loss: 0.5011\n",
            "Epoch 2, D Loss: 0.4490, G Loss: 1.9258, AE Loss: 0.5839\n",
            "Epoch 2, D Loss: 0.8557, G Loss: 1.9350, AE Loss: 0.4530\n",
            "Epoch 2, D Loss: 0.2879, G Loss: 1.9510, AE Loss: 0.5645\n",
            "Epoch 2, D Loss: 0.6147, G Loss: 2.0590, AE Loss: 0.4928\n",
            "Epoch 2, D Loss: 0.8304, G Loss: 1.9803, AE Loss: 0.5798\n",
            "Epoch 2, D Loss: 0.5769, G Loss: 2.0786, AE Loss: 0.5314\n",
            "Epoch 2, D Loss: 0.8609, G Loss: 2.0346, AE Loss: 0.5810\n",
            "Epoch 2, D Loss: 0.3998, G Loss: 2.0267, AE Loss: 0.5749\n",
            "Epoch 2, D Loss: 1.6780, G Loss: 2.0055, AE Loss: 0.5285\n",
            "Epoch 2, D Loss: 0.6148, G Loss: 2.1051, AE Loss: 0.5691\n",
            "Epoch 2, D Loss: 1.2206, G Loss: 2.1712, AE Loss: 0.5622\n",
            "Epoch 2, D Loss: 1.0479, G Loss: 2.1156, AE Loss: 0.5911\n",
            "Epoch 2, D Loss: 0.3275, G Loss: 2.1325, AE Loss: 0.4407\n",
            "Epoch 2, D Loss: 0.4537, G Loss: 2.0547, AE Loss: 0.5439\n",
            "Epoch 2, D Loss: 0.8150, G Loss: 2.1887, AE Loss: 0.5347\n",
            "Epoch 2, D Loss: 0.1318, G Loss: 2.2352, AE Loss: 0.6108\n",
            "Epoch 2, D Loss: 1.4730, G Loss: 2.2078, AE Loss: 0.6555\n",
            "Epoch 2, D Loss: 0.1833, G Loss: 2.1462, AE Loss: 0.6533\n",
            "Epoch 2, D Loss: 0.8415, G Loss: 2.1021, AE Loss: 0.4576\n",
            "Epoch 2, D Loss: 0.8688, G Loss: 2.2021, AE Loss: 0.5060\n",
            "Epoch 2, D Loss: 0.2172, G Loss: 2.3341, AE Loss: 0.5702\n",
            "Epoch 2, D Loss: 0.8338, G Loss: 2.1688, AE Loss: 0.4561\n",
            "Epoch 2, D Loss: 0.4995, G Loss: 2.0850, AE Loss: 0.5021\n",
            "Epoch 2, D Loss: 0.8991, G Loss: 2.1401, AE Loss: 0.5259\n",
            "Epoch 2, D Loss: 0.1572, G Loss: 2.2202, AE Loss: 0.5047\n",
            "Epoch 2, D Loss: 0.4578, G Loss: 2.1864, AE Loss: 0.4589\n",
            "Epoch 2, D Loss: 0.6043, G Loss: 2.0892, AE Loss: 0.5328\n",
            "Epoch 2, D Loss: 0.1707, G Loss: 2.2185, AE Loss: 0.6146\n",
            "Epoch 2, D Loss: 0.5712, G Loss: 2.2008, AE Loss: 0.5459\n",
            "Epoch 2, D Loss: 0.3136, G Loss: 2.2210, AE Loss: 0.5182\n",
            "Epoch 2, D Loss: 0.4073, G Loss: 2.1382, AE Loss: 0.4535\n",
            "Epoch 2, D Loss: 0.6167, G Loss: 2.1003, AE Loss: 0.5786\n",
            "Epoch 2, D Loss: 0.1606, G Loss: 2.1299, AE Loss: 0.4750\n",
            "Epoch 2, D Loss: 0.4112, G Loss: 2.3374, AE Loss: 0.5992\n",
            "Epoch 2, D Loss: 0.4473, G Loss: 2.1424, AE Loss: 0.5353\n",
            "Epoch 2, D Loss: 0.3326, G Loss: 2.3456, AE Loss: 0.4612\n",
            "Epoch 2, D Loss: 0.7004, G Loss: 2.2497, AE Loss: 0.5290\n",
            "Epoch 2, D Loss: 0.8648, G Loss: 2.3202, AE Loss: 0.6591\n",
            "Epoch 2, D Loss: 0.1400, G Loss: 2.1711, AE Loss: 0.6200\n",
            "Epoch 2, D Loss: 0.2593, G Loss: 2.3002, AE Loss: 0.5147\n",
            "Epoch 2, D Loss: 0.1763, G Loss: 2.2829, AE Loss: 0.5022\n",
            "Epoch 2, D Loss: 0.2263, G Loss: 2.3479, AE Loss: 0.5209\n",
            "Epoch 2, D Loss: 0.3331, G Loss: 2.1117, AE Loss: 0.5070\n",
            "Epoch 2, D Loss: 0.8894, G Loss: 2.3940, AE Loss: 0.6241\n",
            "Epoch 2, D Loss: 0.4646, G Loss: 2.3479, AE Loss: 0.5488\n",
            "Epoch 2, D Loss: 0.4311, G Loss: 2.3299, AE Loss: 0.6088\n",
            "Epoch 2, D Loss: 0.3979, G Loss: 2.4165, AE Loss: 0.4495\n",
            "Epoch 2, D Loss: 0.7187, G Loss: 2.4956, AE Loss: 0.5166\n",
            "Epoch 2, D Loss: 0.3943, G Loss: 2.4170, AE Loss: 0.5610\n",
            "Epoch 2, D Loss: 0.1551, G Loss: 2.3249, AE Loss: 0.5832\n",
            "Epoch 2, D Loss: 0.4226, G Loss: 2.4530, AE Loss: 0.5339\n",
            "Epoch 2, D Loss: 0.4121, G Loss: 2.4683, AE Loss: 0.6062\n",
            "Epoch 2, D Loss: 0.1776, G Loss: 2.8465, AE Loss: 0.5909\n",
            "Epoch 2, D Loss: 0.8859, G Loss: 2.4526, AE Loss: 0.7031\n",
            "Epoch 2, D Loss: 0.5650, G Loss: 2.3534, AE Loss: 0.5420\n",
            "Epoch 2, D Loss: 0.3316, G Loss: 2.3212, AE Loss: 0.4933\n",
            "Epoch 2, D Loss: 0.3437, G Loss: 2.2970, AE Loss: 0.4843\n",
            "Epoch 2, D Loss: 1.0099, G Loss: 2.4200, AE Loss: 0.5491\n",
            "Epoch 2, D Loss: 0.5365, G Loss: 2.4572, AE Loss: 0.6265\n",
            "Epoch 2, D Loss: 0.4427, G Loss: 2.4904, AE Loss: 0.5327\n",
            "Epoch 2, D Loss: 0.4559, G Loss: 2.2502, AE Loss: 0.4560\n",
            "Epoch 2, D Loss: 0.7062, G Loss: 2.1037, AE Loss: 0.4525\n",
            "Epoch 2, D Loss: 0.6844, G Loss: 2.2724, AE Loss: 0.4462\n",
            "Epoch 2, D Loss: 1.0796, G Loss: 2.2868, AE Loss: 0.5130\n",
            "Epoch 2, D Loss: 0.5941, G Loss: 2.0368, AE Loss: 0.5487\n",
            "Epoch 2, D Loss: 0.5430, G Loss: 2.3188, AE Loss: 0.5258\n",
            "Epoch 2, D Loss: 0.3794, G Loss: 2.2385, AE Loss: 0.5044\n",
            "Epoch 2, D Loss: 0.7346, G Loss: 2.3872, AE Loss: 0.5717\n",
            "Epoch 2, D Loss: 0.4751, G Loss: 2.1804, AE Loss: 0.6028\n",
            "Epoch 2, D Loss: 0.9623, G Loss: 2.1904, AE Loss: 0.5965\n",
            "Epoch 2, D Loss: 0.4727, G Loss: 2.2786, AE Loss: 0.5434\n",
            "Epoch 2, D Loss: 1.0569, G Loss: 2.3431, AE Loss: 0.5787\n",
            "Epoch 2, D Loss: 0.5411, G Loss: 2.1139, AE Loss: 0.5286\n",
            "Epoch 2, D Loss: 0.8076, G Loss: 2.1539, AE Loss: 0.5430\n",
            "Epoch 2, D Loss: 0.3605, G Loss: 2.1859, AE Loss: 0.5125\n",
            "Epoch 2, D Loss: 0.4322, G Loss: 2.0973, AE Loss: 0.5944\n",
            "Epoch 2, D Loss: 0.5112, G Loss: 2.1519, AE Loss: 0.5454\n",
            "Epoch 2, D Loss: 0.6030, G Loss: 2.1945, AE Loss: 0.6172\n",
            "Epoch 2, D Loss: 0.2143, G Loss: 2.6037, AE Loss: 0.4710\n",
            "Epoch 2, D Loss: 0.4740, G Loss: 2.2253, AE Loss: 0.6237\n",
            "Epoch 2, D Loss: 0.5751, G Loss: 2.3026, AE Loss: 0.4490\n",
            "Epoch 2, D Loss: 0.5644, G Loss: 1.9818, AE Loss: 0.5494\n",
            "Epoch 2, D Loss: 0.2538, G Loss: 2.2101, AE Loss: 0.5584\n",
            "Epoch 2, D Loss: 0.8023, G Loss: 2.6115, AE Loss: 0.5414\n",
            "Epoch 2, D Loss: 0.8929, G Loss: 2.0357, AE Loss: 0.6777\n",
            "Epoch 2, D Loss: 0.3256, G Loss: 2.2937, AE Loss: 0.6974\n",
            "Epoch 2, D Loss: 0.3346, G Loss: 2.1409, AE Loss: 0.6153\n",
            "Epoch 2, D Loss: 0.2575, G Loss: 2.3672, AE Loss: 0.6460\n",
            "Epoch 2, D Loss: 0.4577, G Loss: 2.1428, AE Loss: 0.5963\n",
            "Epoch 2, D Loss: 0.3427, G Loss: 2.2851, AE Loss: 0.5289\n",
            "Epoch 2, D Loss: 0.4020, G Loss: 2.6054, AE Loss: 0.5273\n",
            "Epoch 2, D Loss: 0.3585, G Loss: 2.2174, AE Loss: 0.5457\n",
            "Epoch 2, D Loss: 0.8346, G Loss: 2.3036, AE Loss: 0.6066\n",
            "Epoch 2, D Loss: 0.5527, G Loss: 2.4390, AE Loss: 0.4263\n",
            "Epoch 2, D Loss: 0.1552, G Loss: 2.2901, AE Loss: 0.5858\n",
            "Epoch 2, D Loss: 0.8240, G Loss: 2.2971, AE Loss: 0.5071\n",
            "Epoch 2, D Loss: 0.5871, G Loss: 2.4227, AE Loss: 0.5314\n",
            "Epoch 2, D Loss: 0.4604, G Loss: 2.1007, AE Loss: 0.5606\n",
            "Epoch 2, D Loss: 0.3452, G Loss: 2.4871, AE Loss: 0.5122\n",
            "Epoch 2, D Loss: 0.2960, G Loss: 2.7489, AE Loss: 0.5373\n",
            "Epoch 2, D Loss: 0.2767, G Loss: 2.5328, AE Loss: 0.5189\n",
            "Epoch 2, D Loss: 1.2953, G Loss: 2.4113, AE Loss: 0.5683\n",
            "Epoch 2, D Loss: 0.8177, G Loss: 2.3084, AE Loss: 0.6161\n",
            "Epoch 2, D Loss: 0.6685, G Loss: 2.2500, AE Loss: 0.6157\n",
            "Epoch 2, D Loss: 0.5779, G Loss: 2.1340, AE Loss: 0.5684\n",
            "Epoch 2, D Loss: 0.6289, G Loss: 2.3478, AE Loss: 0.6974\n",
            "Epoch 2, D Loss: 0.4518, G Loss: 2.1819, AE Loss: 0.5493\n",
            "Epoch 2, D Loss: 0.9431, G Loss: 2.1352, AE Loss: 0.5774\n",
            "Epoch 2, D Loss: 0.8081, G Loss: 2.2920, AE Loss: 0.4877\n",
            "Epoch 2, D Loss: 0.5131, G Loss: 2.3020, AE Loss: 0.5201\n",
            "Epoch 2, D Loss: 0.6029, G Loss: 2.1302, AE Loss: 0.5554\n",
            "Epoch 2, D Loss: 0.2551, G Loss: 2.3413, AE Loss: 0.5714\n",
            "Epoch 2, D Loss: 0.6549, G Loss: 2.4089, AE Loss: 0.5056\n",
            "Epoch 2, D Loss: 0.3208, G Loss: 2.3144, AE Loss: 0.6304\n",
            "Epoch 2, D Loss: 0.2629, G Loss: 2.4892, AE Loss: 0.4245\n",
            "Epoch 2, D Loss: 0.3515, G Loss: 2.1174, AE Loss: 0.6485\n",
            "Epoch 2, D Loss: 0.7075, G Loss: 2.1055, AE Loss: 0.5306\n",
            "Epoch 2, D Loss: 0.2602, G Loss: 2.3018, AE Loss: 0.3916\n",
            "Epoch 2, D Loss: 0.4011, G Loss: 2.7684, AE Loss: 0.5363\n",
            "Epoch 2, D Loss: 0.7723, G Loss: 2.4472, AE Loss: 0.4493\n",
            "Epoch 2, D Loss: 0.5998, G Loss: 2.4275, AE Loss: 0.5638\n",
            "Epoch 2, D Loss: 0.3560, G Loss: 2.4505, AE Loss: 0.4707\n",
            "Epoch 2, D Loss: 0.4630, G Loss: 2.6011, AE Loss: 0.5894\n",
            "Epoch 2, D Loss: 0.8707, G Loss: 2.7355, AE Loss: 0.4897\n",
            "Epoch 2, D Loss: 0.9767, G Loss: 2.0168, AE Loss: 0.6048\n",
            "Epoch 2, D Loss: 0.7094, G Loss: 2.6811, AE Loss: 0.5482\n",
            "Epoch 2, D Loss: 0.5705, G Loss: 2.3469, AE Loss: 0.5820\n",
            "Epoch 2, D Loss: 0.7390, G Loss: 2.2931, AE Loss: 0.6960\n",
            "Epoch 2, D Loss: 0.3261, G Loss: 2.3237, AE Loss: 0.5662\n",
            "Epoch 2, D Loss: 0.7227, G Loss: 2.2420, AE Loss: 0.6362\n",
            "Epoch 2, D Loss: 0.6030, G Loss: 1.9909, AE Loss: 0.5178\n",
            "Epoch 2, D Loss: 0.7320, G Loss: 2.2206, AE Loss: 0.4948\n",
            "Epoch 2, D Loss: 0.4853, G Loss: 2.5820, AE Loss: 0.7694\n",
            "Epoch 2, D Loss: 0.3597, G Loss: 2.2301, AE Loss: 0.6080\n",
            "Epoch 2, D Loss: 0.9328, G Loss: 2.5934, AE Loss: 0.5328\n",
            "Epoch 2, D Loss: 0.2852, G Loss: 2.4948, AE Loss: 0.5792\n",
            "Epoch 2, D Loss: 0.4246, G Loss: 2.2849, AE Loss: 0.5331\n",
            "Epoch 2, D Loss: 0.3096, G Loss: 2.3868, AE Loss: 0.6306\n",
            "Epoch 2, D Loss: 0.4217, G Loss: 2.4402, AE Loss: 0.6415\n",
            "Epoch 2, D Loss: 0.2933, G Loss: 2.4875, AE Loss: 0.6032\n",
            "Epoch 2, D Loss: 0.8792, G Loss: 2.2447, AE Loss: 0.5822\n",
            "Epoch 2, D Loss: 0.4306, G Loss: 2.8082, AE Loss: 0.4690\n",
            "Epoch 2, D Loss: 0.6193, G Loss: 2.5457, AE Loss: 0.5535\n",
            "Epoch 2, D Loss: 0.3577, G Loss: 2.3333, AE Loss: 0.5045\n",
            "Epoch 2, D Loss: 0.6532, G Loss: 2.4419, AE Loss: 0.4657\n",
            "Epoch 2, D Loss: 0.8886, G Loss: 2.2353, AE Loss: 0.5387\n",
            "Epoch 2, D Loss: 1.2318, G Loss: 2.3176, AE Loss: 0.5348\n",
            "Epoch 2, D Loss: 0.1860, G Loss: 2.5755, AE Loss: 0.5436\n",
            "Epoch 2, D Loss: 0.7435, G Loss: 2.2990, AE Loss: 0.5154\n",
            "Epoch 2, D Loss: 0.7586, G Loss: 2.4464, AE Loss: 0.5560\n",
            "Epoch 2, D Loss: 0.4114, G Loss: 2.1144, AE Loss: 0.6812\n",
            "Epoch 2, D Loss: 0.3382, G Loss: 2.2738, AE Loss: 0.7787\n",
            "Epoch 2, D Loss: 0.5037, G Loss: 2.2036, AE Loss: 0.7525\n",
            "Epoch 2, D Loss: 0.3080, G Loss: 2.3159, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 0.7058, G Loss: 2.4415, AE Loss: 0.6605\n",
            "Epoch 2, D Loss: 0.6229, G Loss: 2.4338, AE Loss: 0.5013\n",
            "Epoch 2, D Loss: 0.8738, G Loss: 2.4304, AE Loss: 0.5869\n",
            "Epoch 2, D Loss: 0.8173, G Loss: 2.3185, AE Loss: 0.5162\n",
            "Epoch 2, D Loss: 0.6926, G Loss: 2.2382, AE Loss: 0.6913\n",
            "Epoch 2, D Loss: 1.1588, G Loss: 2.3474, AE Loss: 0.5047\n",
            "Epoch 2, D Loss: 0.7701, G Loss: 2.4942, AE Loss: 0.5959\n",
            "Epoch 2, D Loss: 0.9569, G Loss: 2.4162, AE Loss: 0.6173\n",
            "Epoch 2, D Loss: 0.1689, G Loss: 2.5319, AE Loss: 0.3895\n",
            "Epoch 2, D Loss: 0.5351, G Loss: 2.3770, AE Loss: 0.4605\n",
            "Epoch 2, D Loss: 0.1877, G Loss: 2.2533, AE Loss: 0.4735\n",
            "Epoch 2, D Loss: 0.3825, G Loss: 2.3671, AE Loss: 0.7714\n",
            "Epoch 2, D Loss: 1.0862, G Loss: 2.0942, AE Loss: 0.5654\n",
            "Epoch 2, D Loss: 0.7956, G Loss: 2.0625, AE Loss: 0.5708\n",
            "Epoch 2, D Loss: 0.8637, G Loss: 2.2558, AE Loss: 0.5541\n",
            "Epoch 2, D Loss: 0.5421, G Loss: 2.2747, AE Loss: 0.5064\n",
            "Epoch 2, D Loss: 0.2145, G Loss: 2.3039, AE Loss: 0.5697\n",
            "Epoch 2, D Loss: 0.1780, G Loss: 2.3426, AE Loss: 0.5602\n",
            "Epoch 2, D Loss: 1.1734, G Loss: 2.0143, AE Loss: 0.4923\n",
            "Epoch 2, D Loss: 0.4621, G Loss: 2.4079, AE Loss: 0.5330\n",
            "Epoch 2, D Loss: 0.5267, G Loss: 2.1437, AE Loss: 0.6282\n",
            "Epoch 2, D Loss: 0.3012, G Loss: 2.1642, AE Loss: 0.6445\n",
            "Epoch 2, D Loss: 0.1421, G Loss: 2.6723, AE Loss: 0.5430\n",
            "Epoch 2, D Loss: 0.2266, G Loss: 2.0962, AE Loss: 0.8229\n",
            "Epoch 2, D Loss: 0.4083, G Loss: 2.0955, AE Loss: 0.5359\n",
            "Epoch 2, D Loss: 1.0169, G Loss: 2.0866, AE Loss: 0.6142\n",
            "Epoch 2, D Loss: 0.3150, G Loss: 2.4267, AE Loss: 0.5450\n",
            "Epoch 2, D Loss: 0.5235, G Loss: 2.1194, AE Loss: 0.4450\n",
            "Epoch 2, D Loss: 0.3165, G Loss: 2.4091, AE Loss: 0.7546\n",
            "Epoch 2, D Loss: 0.9258, G Loss: 2.2101, AE Loss: 0.5429\n",
            "Epoch 2, D Loss: 0.5956, G Loss: 2.6011, AE Loss: 0.6854\n",
            "Epoch 2, D Loss: 0.1956, G Loss: 2.3011, AE Loss: 0.4989\n",
            "Epoch 2, D Loss: 0.7331, G Loss: 2.1983, AE Loss: 0.3858\n",
            "Epoch 2, D Loss: 0.7439, G Loss: 2.2100, AE Loss: 0.5689\n",
            "Epoch 2, D Loss: 0.4998, G Loss: 2.0841, AE Loss: 0.6116\n",
            "Epoch 2, D Loss: 0.4285, G Loss: 2.3564, AE Loss: 0.5269\n",
            "Epoch 2, D Loss: 0.3172, G Loss: 2.1943, AE Loss: 0.6185\n",
            "Epoch 2, D Loss: 0.4947, G Loss: 2.0763, AE Loss: 0.4572\n",
            "Epoch 2, D Loss: 0.4403, G Loss: 2.0455, AE Loss: 0.5520\n",
            "Epoch 2, D Loss: 0.2620, G Loss: 2.1396, AE Loss: 0.5126\n",
            "Epoch 2, D Loss: 0.4086, G Loss: 1.8902, AE Loss: 0.4590\n",
            "Epoch 2, D Loss: 0.5067, G Loss: 2.0821, AE Loss: 0.5934\n",
            "Epoch 2, D Loss: 0.2806, G Loss: 1.9798, AE Loss: 0.4130\n",
            "Epoch 2, D Loss: 1.1357, G Loss: 1.7645, AE Loss: 0.6241\n",
            "Epoch 2, D Loss: 1.2953, G Loss: 1.9427, AE Loss: 0.5841\n",
            "Epoch 2, D Loss: 0.3779, G Loss: 1.9049, AE Loss: 0.5013\n",
            "Epoch 2, D Loss: 0.2633, G Loss: 2.1846, AE Loss: 0.6297\n",
            "Epoch 2, D Loss: 0.7962, G Loss: 1.8424, AE Loss: 0.3957\n",
            "Epoch 2, D Loss: 0.3440, G Loss: 2.0034, AE Loss: 0.6245\n",
            "Epoch 2, D Loss: 0.5525, G Loss: 2.1287, AE Loss: 0.5018\n",
            "Epoch 2, D Loss: 0.8336, G Loss: 2.3208, AE Loss: 0.6405\n",
            "Epoch 2, D Loss: 0.9569, G Loss: 2.3200, AE Loss: 0.5850\n",
            "Epoch 2, D Loss: 0.4286, G Loss: 2.0038, AE Loss: 0.6644\n",
            "Epoch 2, D Loss: 0.5222, G Loss: 1.9896, AE Loss: 0.4139\n",
            "Epoch 2, D Loss: 0.2651, G Loss: 2.2328, AE Loss: 0.4861\n",
            "Epoch 2, D Loss: 1.0192, G Loss: 2.4423, AE Loss: 0.4575\n",
            "Epoch 2, D Loss: 0.5205, G Loss: 2.4471, AE Loss: 0.4847\n",
            "Epoch 2, D Loss: 0.8788, G Loss: 1.9063, AE Loss: 0.6796\n",
            "Epoch 2, D Loss: 0.2914, G Loss: 2.2899, AE Loss: 0.6927\n",
            "Epoch 2, D Loss: 0.3808, G Loss: 1.9655, AE Loss: 0.6669\n",
            "Epoch 2, D Loss: 0.9577, G Loss: 1.8314, AE Loss: 0.6907\n",
            "Epoch 2, D Loss: 1.0613, G Loss: 1.6972, AE Loss: 0.5438\n",
            "Epoch 2, D Loss: 0.5159, G Loss: 1.9242, AE Loss: 0.5563\n",
            "Epoch 2, D Loss: 0.4641, G Loss: 2.0580, AE Loss: 0.6630\n",
            "Epoch 2, D Loss: 0.2477, G Loss: 2.0521, AE Loss: 0.5390\n",
            "Epoch 2, D Loss: 1.7589, G Loss: 1.8852, AE Loss: 0.5038\n",
            "Epoch 2, D Loss: 0.9663, G Loss: 1.7376, AE Loss: 0.7783\n",
            "Epoch 2, D Loss: 0.5074, G Loss: 2.2908, AE Loss: 0.6634\n",
            "Epoch 2, D Loss: 0.7852, G Loss: 2.0188, AE Loss: 0.4829\n",
            "Epoch 2, D Loss: 1.2772, G Loss: 1.7353, AE Loss: 0.7032\n",
            "Epoch 2, D Loss: 1.3297, G Loss: 2.0243, AE Loss: 0.4304\n",
            "Epoch 2, D Loss: 1.1336, G Loss: 2.1169, AE Loss: 0.6053\n",
            "Epoch 2, D Loss: 0.6852, G Loss: 1.7847, AE Loss: 0.7222\n",
            "Epoch 2, D Loss: 0.4028, G Loss: 2.0366, AE Loss: 0.5863\n",
            "Epoch 2, D Loss: 0.7003, G Loss: 2.1634, AE Loss: 0.5904\n",
            "Epoch 2, D Loss: 0.8077, G Loss: 1.9583, AE Loss: 0.5948\n",
            "Epoch 2, D Loss: 0.2886, G Loss: 2.0016, AE Loss: 0.6857\n",
            "Epoch 2, D Loss: 0.5098, G Loss: 2.3417, AE Loss: 0.5601\n",
            "Epoch 2, D Loss: 0.5698, G Loss: 1.9847, AE Loss: 0.4208\n",
            "Epoch 2, D Loss: 0.5103, G Loss: 1.9126, AE Loss: 0.5620\n",
            "Epoch 2, D Loss: 0.9840, G Loss: 1.8396, AE Loss: 0.5765\n",
            "Epoch 2, D Loss: 0.9359, G Loss: 1.7346, AE Loss: 0.5479\n",
            "Epoch 2, D Loss: 0.9572, G Loss: 1.7718, AE Loss: 0.6338\n",
            "Epoch 2, D Loss: 0.7280, G Loss: 2.0913, AE Loss: 0.5188\n",
            "Epoch 2, D Loss: 1.9083, G Loss: 1.9351, AE Loss: 0.5298\n",
            "Epoch 2, D Loss: 0.2944, G Loss: 2.2196, AE Loss: 0.5253\n",
            "Epoch 2, D Loss: 0.3766, G Loss: 2.0160, AE Loss: 0.7484\n",
            "Epoch 2, D Loss: 0.4734, G Loss: 2.0120, AE Loss: 0.5111\n",
            "Epoch 2, D Loss: 0.7581, G Loss: 2.0308, AE Loss: 0.6479\n",
            "Epoch 2, D Loss: 0.3824, G Loss: 2.2407, AE Loss: 0.4185\n",
            "Epoch 2, D Loss: 1.2243, G Loss: 2.7065, AE Loss: 0.5570\n",
            "Epoch 2, D Loss: 0.2237, G Loss: 2.4137, AE Loss: 0.5058\n",
            "Epoch 2, D Loss: 1.3343, G Loss: 2.2216, AE Loss: 0.5904\n",
            "Epoch 2, D Loss: 0.7764, G Loss: 2.1908, AE Loss: 0.5860\n",
            "Epoch 2, D Loss: 0.3307, G Loss: 2.6075, AE Loss: 0.5486\n",
            "Epoch 2, D Loss: 0.5308, G Loss: 2.3263, AE Loss: 0.5265\n",
            "Epoch 2, D Loss: 0.3348, G Loss: 2.3821, AE Loss: 0.6794\n",
            "Epoch 2, D Loss: 0.4370, G Loss: 2.2727, AE Loss: 0.6010\n",
            "Epoch 2, D Loss: 1.4850, G Loss: 2.2948, AE Loss: 0.4792\n",
            "Epoch 2, D Loss: 0.2606, G Loss: 2.1540, AE Loss: 0.6226\n",
            "Epoch 2, D Loss: 0.7848, G Loss: 2.1789, AE Loss: 0.5013\n",
            "Epoch 2, D Loss: 0.1794, G Loss: 2.1721, AE Loss: 0.4216\n",
            "Epoch 2, D Loss: 0.4603, G Loss: 2.2259, AE Loss: 0.4793\n",
            "Epoch 2, D Loss: 0.2486, G Loss: 2.2598, AE Loss: 0.5062\n",
            "Epoch 2, D Loss: 1.1639, G Loss: 2.2534, AE Loss: 0.6650\n",
            "Epoch 2, D Loss: 0.2539, G Loss: 2.2881, AE Loss: 0.5963\n",
            "Epoch 2, D Loss: 0.1808, G Loss: 2.1877, AE Loss: 0.4649\n",
            "Epoch 2, D Loss: 0.6865, G Loss: 2.4400, AE Loss: 0.5831\n",
            "Epoch 2, D Loss: 1.1813, G Loss: 2.2851, AE Loss: 0.5242\n",
            "Epoch 2, D Loss: 0.4533, G Loss: 2.2595, AE Loss: 0.6017\n",
            "Epoch 2, D Loss: 0.3982, G Loss: 2.2062, AE Loss: 0.4693\n",
            "Epoch 2, D Loss: 0.7445, G Loss: 2.2815, AE Loss: 0.4844\n",
            "Epoch 2, D Loss: 0.2896, G Loss: 2.3181, AE Loss: 0.4587\n",
            "Epoch 2, D Loss: 0.8712, G Loss: 2.2138, AE Loss: 0.7518\n",
            "Epoch 2, D Loss: 0.7975, G Loss: 2.2945, AE Loss: 0.5025\n",
            "Epoch 2, D Loss: 0.4103, G Loss: 2.1359, AE Loss: 0.5845\n",
            "Epoch 2, D Loss: 0.4968, G Loss: 2.2914, AE Loss: 0.5147\n",
            "Epoch 2, D Loss: 1.0330, G Loss: 2.0184, AE Loss: 0.6961\n",
            "Epoch 2, D Loss: 0.1785, G Loss: 2.2416, AE Loss: 0.4726\n",
            "Epoch 2, D Loss: 0.6150, G Loss: 2.0949, AE Loss: 0.5739\n",
            "Epoch 2, D Loss: 0.2435, G Loss: 2.2173, AE Loss: 0.5905\n",
            "Epoch 2, D Loss: 0.4194, G Loss: 2.3660, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 0.3608, G Loss: 2.1979, AE Loss: 0.5353\n",
            "Epoch 2, D Loss: 0.4721, G Loss: 2.4373, AE Loss: 0.5429\n",
            "Epoch 2, D Loss: 0.6779, G Loss: 2.1325, AE Loss: 0.4884\n",
            "Epoch 2, D Loss: 0.1841, G Loss: 2.0922, AE Loss: 0.6631\n",
            "Epoch 2, D Loss: 0.4900, G Loss: 2.2891, AE Loss: 0.5562\n",
            "Epoch 2, D Loss: 0.6488, G Loss: 2.0450, AE Loss: 0.6861\n",
            "Epoch 2, D Loss: 0.9570, G Loss: 2.2971, AE Loss: 0.5705\n",
            "Epoch 2, D Loss: 1.6687, G Loss: 2.1095, AE Loss: 0.5109\n",
            "Epoch 2, D Loss: 0.2372, G Loss: 2.5546, AE Loss: 0.6213\n",
            "Epoch 2, D Loss: 1.6783, G Loss: 2.0473, AE Loss: 0.4309\n",
            "Epoch 2, D Loss: 1.2991, G Loss: 2.1141, AE Loss: 0.6045\n",
            "Epoch 2, D Loss: 0.5580, G Loss: 1.9814, AE Loss: 0.6588\n",
            "Epoch 2, D Loss: 0.5189, G Loss: 1.7529, AE Loss: 0.5580\n",
            "Epoch 2, D Loss: 0.2603, G Loss: 2.0693, AE Loss: 0.6408\n",
            "Epoch 2, D Loss: 0.4092, G Loss: 2.4676, AE Loss: 0.5940\n",
            "Epoch 2, D Loss: 0.7848, G Loss: 1.9544, AE Loss: 0.4344\n",
            "Epoch 2, D Loss: 0.7318, G Loss: 2.0684, AE Loss: 0.5347\n",
            "Epoch 2, D Loss: 0.8692, G Loss: 2.2182, AE Loss: 0.6239\n",
            "Epoch 2, D Loss: 0.4237, G Loss: 1.7787, AE Loss: 0.7117\n",
            "Epoch 2, D Loss: 0.5402, G Loss: 1.9693, AE Loss: 0.5592\n",
            "Epoch 2, D Loss: 0.4216, G Loss: 2.0841, AE Loss: 0.6032\n",
            "Epoch 2, D Loss: 0.4443, G Loss: 1.8962, AE Loss: 0.5058\n",
            "Epoch 2, D Loss: 1.4339, G Loss: 1.6788, AE Loss: 0.5138\n",
            "Epoch 2, D Loss: 0.3633, G Loss: 1.7692, AE Loss: 0.5237\n",
            "Epoch 2, D Loss: 0.6337, G Loss: 1.6944, AE Loss: 0.5063\n",
            "Epoch 2, D Loss: 0.6823, G Loss: 1.7131, AE Loss: 0.5913\n",
            "Epoch 2, D Loss: 0.7422, G Loss: 1.7728, AE Loss: 0.5328\n",
            "Epoch 2, D Loss: 1.1715, G Loss: 1.4004, AE Loss: 0.3577\n",
            "Epoch 2, D Loss: 1.3969, G Loss: 1.2836, AE Loss: 0.5452\n",
            "Epoch 2, D Loss: 0.4908, G Loss: 1.6599, AE Loss: 0.5125\n",
            "Epoch 2, D Loss: 0.7056, G Loss: 1.5127, AE Loss: 0.5444\n",
            "Epoch 2, D Loss: 0.7940, G Loss: 1.4834, AE Loss: 0.6615\n",
            "Epoch 2, D Loss: 0.5919, G Loss: 1.4561, AE Loss: 0.5660\n",
            "Epoch 2, D Loss: 0.9306, G Loss: 1.2052, AE Loss: 0.5690\n",
            "Epoch 2, D Loss: 0.7246, G Loss: 1.0588, AE Loss: 0.4482\n",
            "Epoch 2, D Loss: 1.3905, G Loss: 1.3425, AE Loss: 0.5496\n",
            "Epoch 2, D Loss: 0.8222, G Loss: 0.9382, AE Loss: 0.5809\n",
            "Epoch 2, D Loss: 1.0850, G Loss: 0.9132, AE Loss: 0.5664\n",
            "Epoch 2, D Loss: 1.1135, G Loss: 0.8654, AE Loss: 0.5371\n",
            "Epoch 2, D Loss: 0.9991, G Loss: 0.7602, AE Loss: 0.4661\n",
            "Epoch 2, D Loss: 0.8879, G Loss: 0.8661, AE Loss: 0.6275\n",
            "Epoch 2, D Loss: 1.6919, G Loss: 0.6087, AE Loss: 0.6085\n",
            "Epoch 2, D Loss: 1.7225, G Loss: 0.7197, AE Loss: 0.5338\n",
            "Epoch 2, D Loss: 1.2072, G Loss: 0.6661, AE Loss: 0.7289\n",
            "Epoch 2, D Loss: 1.3750, G Loss: 0.5751, AE Loss: 0.5567\n",
            "Epoch 2, D Loss: 1.4700, G Loss: 1.0547, AE Loss: 0.5175\n",
            "Epoch 2, D Loss: 1.1683, G Loss: 0.8895, AE Loss: 0.5770\n",
            "Epoch 2, D Loss: 1.5294, G Loss: 0.9234, AE Loss: 0.5732\n",
            "Epoch 2, D Loss: 1.7729, G Loss: 0.6166, AE Loss: 0.5490\n",
            "Epoch 2, D Loss: 1.6240, G Loss: 0.8892, AE Loss: 0.5533\n",
            "Epoch 2, D Loss: 1.9462, G Loss: 0.9058, AE Loss: 0.5831\n",
            "Epoch 2, D Loss: 0.8684, G Loss: 0.9060, AE Loss: 0.5119\n",
            "Epoch 2, D Loss: 1.1548, G Loss: 1.0735, AE Loss: 0.4941\n",
            "Epoch 2, D Loss: 0.5202, G Loss: 1.2737, AE Loss: 0.5315\n",
            "Epoch 2, D Loss: 1.5157, G Loss: 1.0679, AE Loss: 0.6109\n",
            "Epoch 2, D Loss: 1.1830, G Loss: 1.0438, AE Loss: 0.6072\n",
            "Epoch 2, D Loss: 1.2037, G Loss: 0.8607, AE Loss: 0.4648\n",
            "Epoch 2, D Loss: 0.9771, G Loss: 1.0504, AE Loss: 0.5195\n",
            "Epoch 2, D Loss: 1.0324, G Loss: 1.0583, AE Loss: 0.3004\n",
            "Epoch 2, D Loss: 1.2484, G Loss: 0.8944, AE Loss: 0.4534\n",
            "Epoch 2, D Loss: 1.2226, G Loss: 1.0373, AE Loss: 0.5048\n",
            "Epoch 2, D Loss: 0.7760, G Loss: 0.8346, AE Loss: 0.4259\n",
            "Epoch 2, D Loss: 1.1930, G Loss: 0.8566, AE Loss: 0.5576\n",
            "Epoch 2, D Loss: 1.0078, G Loss: 0.8957, AE Loss: 0.5472\n",
            "Epoch 2, D Loss: 1.3147, G Loss: 0.9311, AE Loss: 0.7014\n",
            "Epoch 2, D Loss: 1.3107, G Loss: 0.9826, AE Loss: 0.5655\n",
            "Epoch 2, D Loss: 1.4421, G Loss: 0.9795, AE Loss: 0.4071\n",
            "Epoch 2, D Loss: 0.8705, G Loss: 1.0304, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 0.7115, G Loss: 0.9404, AE Loss: 0.5887\n",
            "Epoch 2, D Loss: 1.2415, G Loss: 1.0111, AE Loss: 0.5933\n",
            "Epoch 2, D Loss: 1.9425, G Loss: 0.7967, AE Loss: 0.4532\n",
            "Epoch 2, D Loss: 1.0875, G Loss: 0.9295, AE Loss: 0.5164\n",
            "Epoch 2, D Loss: 1.4362, G Loss: 0.9157, AE Loss: 0.5846\n",
            "Epoch 2, D Loss: 1.0743, G Loss: 0.8830, AE Loss: 0.7212\n",
            "Epoch 2, D Loss: 0.8355, G Loss: 0.9172, AE Loss: 0.6516\n",
            "Epoch 2, D Loss: 1.2098, G Loss: 0.8524, AE Loss: 0.6073\n",
            "Epoch 2, D Loss: 0.9563, G Loss: 0.9799, AE Loss: 0.5959\n",
            "Epoch 2, D Loss: 0.9197, G Loss: 0.8027, AE Loss: 0.5341\n",
            "Epoch 2, D Loss: 1.0435, G Loss: 0.8219, AE Loss: 0.5729\n",
            "Epoch 2, D Loss: 1.5094, G Loss: 0.9459, AE Loss: 0.5592\n",
            "Epoch 2, D Loss: 0.9709, G Loss: 0.9468, AE Loss: 0.5456\n",
            "Epoch 2, D Loss: 1.3748, G Loss: 0.7415, AE Loss: 0.5075\n",
            "Epoch 2, D Loss: 1.4837, G Loss: 0.7430, AE Loss: 0.6067\n",
            "Epoch 2, D Loss: 1.0142, G Loss: 0.9163, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 1.0233, G Loss: 1.0478, AE Loss: 0.6307\n",
            "Epoch 2, D Loss: 1.4927, G Loss: 0.9741, AE Loss: 0.6516\n",
            "Epoch 2, D Loss: 1.8224, G Loss: 0.8655, AE Loss: 0.5454\n",
            "Epoch 2, D Loss: 1.2344, G Loss: 0.9899, AE Loss: 0.5835\n",
            "Epoch 2, D Loss: 1.3265, G Loss: 1.0158, AE Loss: 2.1248\n",
            "Epoch 2, D Loss: 1.4962, G Loss: 0.9535, AE Loss: 0.5439\n",
            "Epoch 2, D Loss: 1.0623, G Loss: 0.9058, AE Loss: 0.4978\n",
            "Epoch 2, D Loss: 1.4888, G Loss: 1.1071, AE Loss: 0.6022\n",
            "Epoch 2, D Loss: 1.7499, G Loss: 0.9923, AE Loss: 0.4860\n",
            "Epoch 2, D Loss: 1.3655, G Loss: 0.9948, AE Loss: 0.5698\n",
            "Epoch 2, D Loss: 0.8793, G Loss: 0.9986, AE Loss: 0.5783\n",
            "Epoch 2, D Loss: 2.1307, G Loss: 1.0064, AE Loss: 0.6558\n",
            "Epoch 2, D Loss: 1.0256, G Loss: 0.9097, AE Loss: 0.5660\n",
            "Epoch 2, D Loss: 0.7988, G Loss: 1.0850, AE Loss: 0.6060\n",
            "Epoch 2, D Loss: 0.8584, G Loss: 1.0349, AE Loss: 0.5680\n",
            "Epoch 2, D Loss: 1.0628, G Loss: 1.0828, AE Loss: 0.4276\n",
            "Epoch 2, D Loss: 0.9636, G Loss: 1.0552, AE Loss: 0.5902\n",
            "Epoch 2, D Loss: 0.7702, G Loss: 1.0263, AE Loss: 0.6438\n",
            "Epoch 2, D Loss: 1.3561, G Loss: 1.0535, AE Loss: 0.6093\n",
            "Epoch 2, D Loss: 1.2444, G Loss: 1.1120, AE Loss: 0.4601\n",
            "Epoch 2, D Loss: 1.3644, G Loss: 1.1367, AE Loss: 0.6040\n",
            "Epoch 2, D Loss: 0.6330, G Loss: 1.2081, AE Loss: 0.5362\n",
            "Epoch 2, D Loss: 0.9217, G Loss: 1.2191, AE Loss: 0.6851\n",
            "Epoch 2, D Loss: 0.9027, G Loss: 1.1868, AE Loss: 0.5228\n",
            "Epoch 2, D Loss: 0.8928, G Loss: 1.2246, AE Loss: 0.5945\n",
            "Epoch 2, D Loss: 1.0220, G Loss: 1.1646, AE Loss: 0.6429\n",
            "Epoch 2, D Loss: 1.7402, G Loss: 1.1335, AE Loss: 0.5802\n",
            "Epoch 2, D Loss: 0.7713, G Loss: 1.2604, AE Loss: 0.5515\n",
            "Epoch 2, D Loss: 0.7329, G Loss: 1.2852, AE Loss: 0.4676\n",
            "Epoch 2, D Loss: 0.7106, G Loss: 1.2550, AE Loss: 0.5893\n",
            "Epoch 2, D Loss: 1.4300, G Loss: 1.2446, AE Loss: 0.6103\n",
            "Epoch 2, D Loss: 0.5649, G Loss: 1.2162, AE Loss: 0.5389\n",
            "Epoch 2, D Loss: 1.0512, G Loss: 1.3390, AE Loss: 0.5291\n",
            "Epoch 2, D Loss: 1.2497, G Loss: 1.2862, AE Loss: 0.5589\n",
            "Epoch 2, D Loss: 1.0411, G Loss: 1.2253, AE Loss: 0.5510\n",
            "Epoch 2, D Loss: 0.4814, G Loss: 1.2555, AE Loss: 0.5342\n",
            "Epoch 2, D Loss: 1.0269, G Loss: 1.2937, AE Loss: 0.6199\n",
            "Epoch 2, D Loss: 0.5194, G Loss: 1.3453, AE Loss: 0.4755\n",
            "Epoch 2, D Loss: 0.7577, G Loss: 1.2691, AE Loss: 0.5505\n",
            "Epoch 2, D Loss: 1.1077, G Loss: 1.2227, AE Loss: 0.5601\n",
            "Epoch 2, D Loss: 0.6066, G Loss: 1.2095, AE Loss: 0.5825\n",
            "Epoch 2, D Loss: 0.8602, G Loss: 1.3005, AE Loss: 0.4980\n",
            "Epoch 2, D Loss: 0.5215, G Loss: 1.2390, AE Loss: 0.5099\n",
            "Epoch 2, D Loss: 0.7958, G Loss: 1.2832, AE Loss: 0.5050\n",
            "Epoch 2, D Loss: 1.0121, G Loss: 1.1921, AE Loss: 0.5254\n",
            "Epoch 2, D Loss: 0.8161, G Loss: 1.2803, AE Loss: 0.5775\n",
            "Epoch 2, D Loss: 1.1524, G Loss: 1.2094, AE Loss: 0.5952\n",
            "Epoch 2, D Loss: 1.3833, G Loss: 1.2549, AE Loss: 0.5873\n",
            "Epoch 2, D Loss: 0.7082, G Loss: 1.3783, AE Loss: 0.6393\n",
            "Epoch 2, D Loss: 0.5067, G Loss: 1.3377, AE Loss: 0.5691\n",
            "Epoch 2, D Loss: 1.5387, G Loss: 1.3248, AE Loss: 0.5372\n",
            "Epoch 2, D Loss: 0.8111, G Loss: 1.2636, AE Loss: 0.5400\n",
            "Epoch 2, D Loss: 0.9954, G Loss: 1.3294, AE Loss: 0.4594\n",
            "Epoch 2, D Loss: 0.5735, G Loss: 1.3698, AE Loss: 0.5890\n",
            "Epoch 2, D Loss: 1.3516, G Loss: 1.2872, AE Loss: 0.5567\n",
            "Epoch 2, D Loss: 1.2395, G Loss: 1.2386, AE Loss: 0.5028\n",
            "Epoch 2, D Loss: 1.4615, G Loss: 1.2473, AE Loss: 0.5170\n",
            "Epoch 2, D Loss: 0.6505, G Loss: 1.3344, AE Loss: 0.5561\n",
            "Epoch 2, D Loss: 1.0722, G Loss: 1.1782, AE Loss: 0.4695\n",
            "Epoch 2, D Loss: 1.0661, G Loss: 1.3590, AE Loss: 0.4822\n",
            "Epoch 2, D Loss: 0.5152, G Loss: 1.2609, AE Loss: 0.5120\n",
            "Epoch 2, D Loss: 1.0692, G Loss: 1.1297, AE Loss: 0.5529\n",
            "Epoch 2, D Loss: 0.5247, G Loss: 1.1701, AE Loss: 0.4313\n",
            "Epoch 2, D Loss: 0.9649, G Loss: 1.1115, AE Loss: 0.6643\n",
            "Epoch 2, D Loss: 0.8200, G Loss: 1.3193, AE Loss: 0.5108\n",
            "Epoch 2, D Loss: 0.4774, G Loss: 1.3112, AE Loss: 0.5478\n",
            "Epoch 2, D Loss: 0.7654, G Loss: 1.3416, AE Loss: 0.5016\n",
            "Epoch 2, D Loss: 0.6184, G Loss: 1.2833, AE Loss: 0.5028\n",
            "Epoch 2, D Loss: 0.7281, G Loss: 1.3182, AE Loss: 0.5736\n",
            "Epoch 2, D Loss: 0.8009, G Loss: 1.2051, AE Loss: 0.5272\n",
            "Epoch 2, D Loss: 1.0142, G Loss: 1.1581, AE Loss: 0.4415\n",
            "Epoch 2, D Loss: 0.5225, G Loss: 1.2194, AE Loss: 0.4240\n",
            "Epoch 2, D Loss: 1.6061, G Loss: 1.1646, AE Loss: 0.4876\n",
            "Epoch 2, D Loss: 0.5282, G Loss: 1.2557, AE Loss: 0.5358\n",
            "Epoch 2, D Loss: 0.9320, G Loss: 1.2430, AE Loss: 0.5557\n",
            "Epoch 2, D Loss: 0.9936, G Loss: 1.2572, AE Loss: 0.4651\n",
            "Epoch 2, D Loss: 0.9448, G Loss: 1.1012, AE Loss: 0.5597\n",
            "Epoch 2, D Loss: 0.4552, G Loss: 1.1646, AE Loss: 0.4795\n",
            "Epoch 2, D Loss: 0.9716, G Loss: 1.2264, AE Loss: 0.6718\n",
            "Epoch 2, D Loss: 0.7678, G Loss: 1.3443, AE Loss: 0.5657\n",
            "Epoch 2, D Loss: 1.0256, G Loss: 1.1539, AE Loss: 0.6510\n",
            "Epoch 2, D Loss: 0.4796, G Loss: 1.1408, AE Loss: 0.6513\n",
            "Epoch 2, D Loss: 1.8929, G Loss: 1.2335, AE Loss: 0.5464\n",
            "Epoch 2, D Loss: 1.1298, G Loss: 1.2762, AE Loss: 0.5368\n",
            "Epoch 2, D Loss: 0.4423, G Loss: 1.4151, AE Loss: 0.5717\n",
            "Epoch 2, D Loss: 0.8350, G Loss: 1.2697, AE Loss: 0.5084\n",
            "Epoch 2, D Loss: 0.9341, G Loss: 1.2282, AE Loss: 0.5683\n",
            "Epoch 2, D Loss: 0.8188, G Loss: 1.3808, AE Loss: 0.6589\n",
            "Epoch 2, D Loss: 1.1732, G Loss: 1.2095, AE Loss: 0.6181\n",
            "Epoch 2, D Loss: 0.6973, G Loss: 1.4204, AE Loss: 0.4097\n",
            "Epoch 2, D Loss: 0.6554, G Loss: 1.3186, AE Loss: 0.5300\n",
            "Epoch 2, D Loss: 0.9878, G Loss: 1.2294, AE Loss: 0.6057\n",
            "Epoch 2, D Loss: 0.8214, G Loss: 1.2100, AE Loss: 0.5189\n",
            "Epoch 2, D Loss: 0.9834, G Loss: 1.3233, AE Loss: 0.6665\n",
            "Epoch 2, D Loss: 0.8177, G Loss: 1.3215, AE Loss: 0.5974\n",
            "Epoch 2, D Loss: 1.0551, G Loss: 1.2999, AE Loss: 0.5181\n",
            "Epoch 2, D Loss: 1.1328, G Loss: 1.3775, AE Loss: 0.6709\n",
            "Epoch 2, D Loss: 0.7938, G Loss: 1.2658, AE Loss: 0.5616\n",
            "Epoch 2, D Loss: 0.8225, G Loss: 1.2545, AE Loss: 0.5604\n",
            "Epoch 2, D Loss: 0.5603, G Loss: 1.3250, AE Loss: 0.6083\n",
            "Epoch 2, D Loss: 0.9287, G Loss: 1.2542, AE Loss: 0.4625\n",
            "Epoch 2, D Loss: 1.0233, G Loss: 1.2633, AE Loss: 0.6091\n",
            "Epoch 2, D Loss: 0.9850, G Loss: 1.2260, AE Loss: 0.5023\n",
            "Epoch 2, D Loss: 1.5278, G Loss: 1.3070, AE Loss: 0.6003\n",
            "Epoch 2, D Loss: 0.3991, G Loss: 1.3522, AE Loss: 0.5552\n",
            "Epoch 2, D Loss: 0.8088, G Loss: 1.2955, AE Loss: 0.4777\n",
            "Epoch 2, D Loss: 1.2710, G Loss: 1.2763, AE Loss: 0.6043\n",
            "Epoch 2, D Loss: 0.9696, G Loss: 1.1741, AE Loss: 0.4804\n",
            "Epoch 2, D Loss: 0.4637, G Loss: 1.3026, AE Loss: 0.5038\n",
            "Epoch 2, D Loss: 1.6057, G Loss: 1.5112, AE Loss: 0.5756\n",
            "Epoch 2, D Loss: 0.8326, G Loss: 1.1282, AE Loss: 0.5302\n",
            "Epoch 2, D Loss: 0.9706, G Loss: 1.1625, AE Loss: 0.5847\n",
            "Epoch 2, D Loss: 1.1767, G Loss: 1.1840, AE Loss: 0.5391\n",
            "Epoch 2, D Loss: 0.8436, G Loss: 1.1954, AE Loss: 0.5040\n",
            "Epoch 2, D Loss: 0.7813, G Loss: 1.0982, AE Loss: 0.5936\n",
            "Epoch 2, D Loss: 0.8769, G Loss: 1.0687, AE Loss: 0.5231\n",
            "Epoch 2, D Loss: 0.9051, G Loss: 1.0998, AE Loss: 0.6664\n",
            "Epoch 2, D Loss: 1.6290, G Loss: 1.2562, AE Loss: 0.5096\n",
            "Epoch 2, D Loss: 1.2332, G Loss: 1.2313, AE Loss: 0.5598\n",
            "Epoch 2, D Loss: 0.9485, G Loss: 1.1339, AE Loss: 0.5679\n",
            "Epoch 2, D Loss: 0.8533, G Loss: 1.2776, AE Loss: 0.4786\n",
            "Epoch 2, D Loss: 0.7789, G Loss: 1.2677, AE Loss: 0.5898\n",
            "Epoch 2, D Loss: 1.0449, G Loss: 1.2981, AE Loss: 0.5508\n",
            "Epoch 2, D Loss: 1.1179, G Loss: 1.3927, AE Loss: 0.4467\n",
            "Epoch 2, D Loss: 0.5841, G Loss: 1.2373, AE Loss: 0.5710\n",
            "Epoch 2, D Loss: 0.6986, G Loss: 1.2347, AE Loss: 0.5460\n",
            "Epoch 2, D Loss: 0.8846, G Loss: 1.3791, AE Loss: 0.5418\n",
            "Epoch 2, D Loss: 0.8773, G Loss: 1.3119, AE Loss: 0.4983\n",
            "Epoch 2, D Loss: 1.6735, G Loss: 1.1934, AE Loss: 0.5654\n",
            "Epoch 2, D Loss: 1.0496, G Loss: 1.2412, AE Loss: 0.7405\n",
            "Epoch 2, D Loss: 1.2549, G Loss: 1.3059, AE Loss: 0.5995\n",
            "Epoch 2, D Loss: 1.6095, G Loss: 1.3959, AE Loss: 0.4628\n",
            "Epoch 2, D Loss: 1.5371, G Loss: 1.2956, AE Loss: 0.4793\n",
            "Epoch 2, D Loss: 0.5989, G Loss: 1.3190, AE Loss: 0.5302\n",
            "Epoch 2, D Loss: 1.3309, G Loss: 1.3514, AE Loss: 0.5106\n",
            "Epoch 2, D Loss: 0.8977, G Loss: 1.2642, AE Loss: 0.5484\n",
            "Epoch 2, D Loss: 1.3599, G Loss: 1.3444, AE Loss: 0.5811\n",
            "Epoch 2, D Loss: 1.1115, G Loss: 1.4230, AE Loss: 0.4835\n",
            "Epoch 2, D Loss: 0.4261, G Loss: 1.3309, AE Loss: 0.5694\n",
            "Epoch 2, D Loss: 1.3646, G Loss: 1.3363, AE Loss: 0.5286\n",
            "Epoch 2, D Loss: 0.7815, G Loss: 1.3825, AE Loss: 0.6289\n",
            "Epoch 2, D Loss: 0.5058, G Loss: 1.3842, AE Loss: 0.4773\n",
            "Epoch 2, D Loss: 1.0633, G Loss: 1.4462, AE Loss: 0.5191\n",
            "Epoch 2, D Loss: 0.4999, G Loss: 1.4559, AE Loss: 0.5958\n",
            "Epoch 2, D Loss: 1.0748, G Loss: 1.4960, AE Loss: 0.7786\n",
            "Epoch 2, D Loss: 0.9190, G Loss: 1.3758, AE Loss: 0.5580\n",
            "Epoch 2, D Loss: 1.5742, G Loss: 1.4539, AE Loss: 0.5032\n",
            "Epoch 2, D Loss: 0.8630, G Loss: 1.5195, AE Loss: 0.5589\n",
            "Epoch 2, D Loss: 1.1072, G Loss: 1.5098, AE Loss: 0.4898\n",
            "Epoch 2, D Loss: 0.6019, G Loss: 1.5240, AE Loss: 0.4888\n",
            "Epoch 2, D Loss: 0.4101, G Loss: 1.4552, AE Loss: 0.4820\n",
            "Epoch 2, D Loss: 1.2431, G Loss: 1.4436, AE Loss: 0.5125\n",
            "Epoch 2, D Loss: 0.8107, G Loss: 1.4312, AE Loss: 0.5441\n",
            "Epoch 2, D Loss: 0.6137, G Loss: 1.4293, AE Loss: 0.6244\n",
            "Epoch 2, D Loss: 1.1665, G Loss: 1.5011, AE Loss: 0.5623\n",
            "Epoch 2, D Loss: 1.2627, G Loss: 1.5893, AE Loss: 0.5645\n",
            "Epoch 2, D Loss: 0.4187, G Loss: 1.6027, AE Loss: 0.5529\n",
            "Epoch 2, D Loss: 0.6611, G Loss: 1.5587, AE Loss: 0.4856\n",
            "Epoch 2, D Loss: 0.5840, G Loss: 1.5055, AE Loss: 0.4706\n",
            "Epoch 2, D Loss: 0.9118, G Loss: 1.4341, AE Loss: 0.4805\n",
            "Epoch 2, D Loss: 0.2841, G Loss: 1.5655, AE Loss: 0.6933\n",
            "Epoch 2, D Loss: 0.7356, G Loss: 1.6833, AE Loss: 0.5350\n",
            "Epoch 2, D Loss: 0.3616, G Loss: 1.5881, AE Loss: 0.5492\n",
            "Epoch 2, D Loss: 0.5594, G Loss: 1.5507, AE Loss: 0.5824\n",
            "Epoch 2, D Loss: 0.7727, G Loss: 1.6752, AE Loss: 0.4592\n",
            "Epoch 2, D Loss: 0.7182, G Loss: 1.6332, AE Loss: 0.5221\n",
            "Epoch 2, D Loss: 0.8409, G Loss: 1.6259, AE Loss: 0.5945\n",
            "Epoch 2, D Loss: 0.4563, G Loss: 1.6222, AE Loss: 0.5438\n",
            "Epoch 2, D Loss: 0.7347, G Loss: 1.6706, AE Loss: 0.4952\n",
            "Epoch 2, D Loss: 0.4768, G Loss: 1.7123, AE Loss: 0.6838\n",
            "Epoch 2, D Loss: 0.4852, G Loss: 1.7190, AE Loss: 0.4884\n",
            "Epoch 2, D Loss: 0.4262, G Loss: 1.6941, AE Loss: 0.6082\n",
            "Epoch 2, D Loss: 1.0014, G Loss: 1.8144, AE Loss: 0.5978\n",
            "Epoch 2, D Loss: 0.3016, G Loss: 1.7223, AE Loss: 0.4870\n",
            "Epoch 2, D Loss: 0.3587, G Loss: 1.7357, AE Loss: 0.4915\n",
            "Epoch 2, D Loss: 0.4959, G Loss: 1.8073, AE Loss: 0.5953\n",
            "Epoch 2, D Loss: 0.8995, G Loss: 1.8241, AE Loss: 0.5834\n",
            "Epoch 2, D Loss: 0.6973, G Loss: 1.7919, AE Loss: 0.5089\n",
            "Epoch 2, D Loss: 0.6538, G Loss: 1.9345, AE Loss: 0.4432\n",
            "Epoch 2, D Loss: 0.7675, G Loss: 1.9130, AE Loss: 0.3931\n",
            "Epoch 2, D Loss: 0.8460, G Loss: 1.8149, AE Loss: 0.5119\n",
            "Epoch 2, D Loss: 1.1459, G Loss: 1.8939, AE Loss: 0.4665\n",
            "Epoch 2, D Loss: 0.8900, G Loss: 1.9014, AE Loss: 0.5361\n",
            "Epoch 2, D Loss: 0.5860, G Loss: 1.8991, AE Loss: 0.4897\n",
            "Epoch 2, D Loss: 0.8029, G Loss: 1.9427, AE Loss: 0.5455\n",
            "Epoch 2, D Loss: 1.3249, G Loss: 1.9358, AE Loss: 0.5271\n",
            "Epoch 2, D Loss: 0.2085, G Loss: 1.9128, AE Loss: 0.5331\n",
            "Epoch 2, D Loss: 0.2120, G Loss: 1.9218, AE Loss: 0.6573\n",
            "Epoch 2, D Loss: 0.7577, G Loss: 1.9246, AE Loss: 0.6095\n",
            "Epoch 2, D Loss: 0.2898, G Loss: 1.8476, AE Loss: 0.5016\n",
            "Epoch 2, D Loss: 0.7776, G Loss: 1.8888, AE Loss: 0.5514\n",
            "Epoch 2, D Loss: 0.7146, G Loss: 1.9148, AE Loss: 0.5780\n",
            "Epoch 2, D Loss: 0.3026, G Loss: 1.9222, AE Loss: 0.6400\n",
            "Epoch 2, D Loss: 0.3236, G Loss: 1.9707, AE Loss: 0.5609\n",
            "Epoch 2, D Loss: 0.9527, G Loss: 1.9703, AE Loss: 0.4930\n",
            "Epoch 2, D Loss: 1.4318, G Loss: 1.9550, AE Loss: 0.3512\n",
            "Epoch 2, D Loss: 0.5082, G Loss: 1.9575, AE Loss: 0.4438\n",
            "Epoch 2, D Loss: 0.7126, G Loss: 1.9376, AE Loss: 0.5460\n",
            "Epoch 2, D Loss: 0.4738, G Loss: 1.9432, AE Loss: 0.5154\n",
            "Epoch 2, D Loss: 0.1785, G Loss: 1.9240, AE Loss: 0.4954\n",
            "Epoch 2, D Loss: 0.6245, G Loss: 1.9501, AE Loss: 0.6200\n",
            "Epoch 2, D Loss: 0.6219, G Loss: 1.9391, AE Loss: 0.6151\n",
            "Epoch 2, D Loss: 0.5314, G Loss: 1.9940, AE Loss: 0.5606\n",
            "Epoch 2, D Loss: 0.9131, G Loss: 1.9720, AE Loss: 0.5216\n",
            "Epoch 2, D Loss: 0.5266, G Loss: 2.0422, AE Loss: 0.5586\n",
            "Epoch 2, D Loss: 0.4479, G Loss: 2.0101, AE Loss: 0.5118\n",
            "Epoch 2, D Loss: 0.9270, G Loss: 1.9304, AE Loss: 0.4883\n",
            "Epoch 2, D Loss: 0.7207, G Loss: 1.7352, AE Loss: 0.6959\n",
            "Epoch 2, D Loss: 0.1970, G Loss: 1.9025, AE Loss: 0.6335\n",
            "Epoch 2, D Loss: 0.4637, G Loss: 1.7815, AE Loss: 0.4975\n",
            "Epoch 2, D Loss: 0.4140, G Loss: 1.8036, AE Loss: 0.5092\n",
            "Epoch 2, D Loss: 0.4827, G Loss: 1.7899, AE Loss: 0.5130\n",
            "Epoch 2, D Loss: 0.8670, G Loss: 1.6892, AE Loss: 0.5858\n",
            "Epoch 2, D Loss: 0.7260, G Loss: 1.8053, AE Loss: 0.5910\n",
            "Epoch 2, D Loss: 0.7542, G Loss: 1.7606, AE Loss: 0.6853\n",
            "Epoch 2, D Loss: 0.2138, G Loss: 1.9278, AE Loss: 0.6368\n",
            "Epoch 2, D Loss: 0.7114, G Loss: 1.8199, AE Loss: 0.4828\n",
            "Epoch 2, D Loss: 0.5343, G Loss: 1.7667, AE Loss: 0.6154\n",
            "Epoch 2, D Loss: 0.4398, G Loss: 1.9452, AE Loss: 0.5691\n",
            "Epoch 2, D Loss: 0.7358, G Loss: 1.7157, AE Loss: 0.5472\n",
            "Epoch 2, D Loss: 0.3823, G Loss: 1.7084, AE Loss: 0.5344\n",
            "Epoch 2, D Loss: 0.7087, G Loss: 1.6643, AE Loss: 0.5509\n",
            "Epoch 2, D Loss: 0.8043, G Loss: 1.5601, AE Loss: 0.4583\n",
            "Epoch 2, D Loss: 0.3207, G Loss: 1.6834, AE Loss: 0.4551\n",
            "Epoch 2, D Loss: 0.3958, G Loss: 1.8870, AE Loss: 0.4683\n",
            "Epoch 2, D Loss: 0.7379, G Loss: 1.6847, AE Loss: 0.5507\n",
            "Epoch 2, D Loss: 0.4035, G Loss: 1.7036, AE Loss: 0.5385\n",
            "Epoch 2, D Loss: 0.5868, G Loss: 1.7422, AE Loss: 0.5914\n",
            "Epoch 2, D Loss: 0.9739, G Loss: 1.9384, AE Loss: 0.5533\n",
            "Epoch 2, D Loss: 0.2360, G Loss: 1.9624, AE Loss: 0.5355\n",
            "Epoch 2, D Loss: 0.5210, G Loss: 1.5980, AE Loss: 0.5966\n",
            "Epoch 2, D Loss: 0.5033, G Loss: 1.7372, AE Loss: 0.5671\n",
            "Epoch 2, D Loss: 0.6031, G Loss: 2.0489, AE Loss: 0.5455\n",
            "Epoch 2, D Loss: 0.3290, G Loss: 1.7536, AE Loss: 0.5358\n",
            "Epoch 2, D Loss: 0.5626, G Loss: 1.8404, AE Loss: 0.5417\n",
            "Epoch 2, D Loss: 0.7059, G Loss: 1.8276, AE Loss: 0.4744\n",
            "Epoch 2, D Loss: 0.5154, G Loss: 1.7715, AE Loss: 0.5329\n",
            "Epoch 2, D Loss: 0.4975, G Loss: 1.8114, AE Loss: 0.6407\n",
            "Epoch 2, D Loss: 1.0483, G Loss: 1.8118, AE Loss: 0.5508\n",
            "Epoch 2, D Loss: 0.6093, G Loss: 1.9432, AE Loss: 0.6256\n",
            "Epoch 2, D Loss: 0.7156, G Loss: 1.7302, AE Loss: 0.4798\n",
            "Epoch 2, D Loss: 0.9208, G Loss: 1.7874, AE Loss: 0.6431\n",
            "Epoch 2, D Loss: 0.6422, G Loss: 1.6698, AE Loss: 0.6322\n",
            "Epoch 2, D Loss: 0.4255, G Loss: 1.8983, AE Loss: 0.5126\n",
            "Epoch 2, D Loss: 0.6123, G Loss: 1.9371, AE Loss: 0.5095\n",
            "Epoch 2, D Loss: 0.5671, G Loss: 1.7711, AE Loss: 0.6453\n",
            "Epoch 2, D Loss: 0.5028, G Loss: 1.8130, AE Loss: 0.5000\n",
            "Epoch 2, D Loss: 0.8726, G Loss: 1.8344, AE Loss: 0.5795\n",
            "Epoch 2, D Loss: 0.4801, G Loss: 1.7604, AE Loss: 0.6273\n",
            "Epoch 2, D Loss: 0.3399, G Loss: 1.7711, AE Loss: 0.4964\n",
            "Epoch 2, D Loss: 0.4249, G Loss: 1.9873, AE Loss: 0.5289\n",
            "Epoch 2, D Loss: 0.4128, G Loss: 2.0444, AE Loss: 0.5760\n",
            "Epoch 2, D Loss: 0.9761, G Loss: 1.7055, AE Loss: 0.5860\n",
            "Epoch 2, D Loss: 0.7158, G Loss: 1.9388, AE Loss: 0.5825\n",
            "Epoch 2, D Loss: 0.4262, G Loss: 1.9373, AE Loss: 0.5639\n",
            "Epoch 2, D Loss: 0.5563, G Loss: 2.0493, AE Loss: 0.5113\n",
            "Epoch 2, D Loss: 0.7594, G Loss: 1.8914, AE Loss: 0.5496\n",
            "Epoch 2, D Loss: 0.5109, G Loss: 1.9561, AE Loss: 0.6000\n",
            "Epoch 2, D Loss: 0.2290, G Loss: 2.0790, AE Loss: 0.4689\n",
            "Epoch 2, D Loss: 0.7466, G Loss: 2.0225, AE Loss: 0.5434\n",
            "Epoch 2, D Loss: 0.6243, G Loss: 1.9445, AE Loss: 0.6645\n",
            "Epoch 2, D Loss: 1.3116, G Loss: 1.8212, AE Loss: 0.6588\n",
            "Epoch 2, D Loss: 0.3171, G Loss: 1.8313, AE Loss: 0.5545\n",
            "Epoch 2, D Loss: 0.8831, G Loss: 1.8556, AE Loss: 0.4898\n",
            "Epoch 2, D Loss: 0.9210, G Loss: 1.8984, AE Loss: 0.6472\n",
            "Epoch 2, D Loss: 0.7867, G Loss: 1.8328, AE Loss: 0.6320\n",
            "Epoch 2, D Loss: 0.6259, G Loss: 1.9134, AE Loss: 0.6070\n",
            "Epoch 2, D Loss: 0.3896, G Loss: 1.8154, AE Loss: 0.5148\n",
            "Epoch 2, D Loss: 0.1789, G Loss: 2.2680, AE Loss: 0.4503\n",
            "Epoch 2, D Loss: 0.3516, G Loss: 2.0760, AE Loss: 0.5851\n",
            "Epoch 2, D Loss: 0.6916, G Loss: 1.9431, AE Loss: 0.4593\n",
            "Epoch 2, D Loss: 0.4657, G Loss: 1.9732, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 0.3461, G Loss: 2.0404, AE Loss: 0.6171\n",
            "Epoch 2, D Loss: 0.3192, G Loss: 2.3552, AE Loss: 0.5141\n",
            "Epoch 2, D Loss: 0.8708, G Loss: 2.0998, AE Loss: 0.4957\n",
            "Epoch 2, D Loss: 0.6100, G Loss: 1.9883, AE Loss: 0.6616\n",
            "Epoch 2, D Loss: 0.1967, G Loss: 2.0468, AE Loss: 0.5436\n",
            "Epoch 2, D Loss: 1.2053, G Loss: 2.0790, AE Loss: 0.5982\n",
            "Epoch 2, D Loss: 0.7250, G Loss: 1.8471, AE Loss: 0.5481\n",
            "Epoch 2, D Loss: 0.2654, G Loss: 2.0111, AE Loss: 0.6450\n",
            "Epoch 2, D Loss: 1.0164, G Loss: 2.1620, AE Loss: 0.4876\n",
            "Epoch 2, D Loss: 0.6478, G Loss: 1.9079, AE Loss: 0.5433\n",
            "Epoch 2, D Loss: 1.1956, G Loss: 1.9460, AE Loss: 0.5757\n",
            "Epoch 2, D Loss: 0.8118, G Loss: 1.9725, AE Loss: 0.5432\n",
            "Epoch 2, D Loss: 0.4662, G Loss: 1.8710, AE Loss: 0.5343\n",
            "Epoch 2, D Loss: 0.3367, G Loss: 2.0324, AE Loss: 0.7107\n",
            "Epoch 2, D Loss: 1.0087, G Loss: 2.2858, AE Loss: 0.5141\n",
            "Epoch 2, D Loss: 0.3418, G Loss: 2.1293, AE Loss: 0.6011\n",
            "Epoch 2, D Loss: 0.3757, G Loss: 2.0316, AE Loss: 0.5175\n",
            "Epoch 2, D Loss: 0.3992, G Loss: 1.9705, AE Loss: 0.5673\n",
            "Epoch 2, D Loss: 0.8481, G Loss: 2.0444, AE Loss: 0.5528\n",
            "Epoch 2, D Loss: 0.5316, G Loss: 2.2753, AE Loss: 0.5160\n",
            "Epoch 2, D Loss: 0.3768, G Loss: 2.4687, AE Loss: 0.6172\n",
            "Epoch 2, D Loss: 0.8454, G Loss: 2.2668, AE Loss: 0.6203\n",
            "Epoch 2, D Loss: 0.2851, G Loss: 2.4313, AE Loss: 0.5221\n",
            "Epoch 2, D Loss: 0.8304, G Loss: 2.1055, AE Loss: 0.5726\n",
            "Epoch 2, D Loss: 1.1394, G Loss: 2.1840, AE Loss: 0.5399\n",
            "Epoch 2, D Loss: 0.9671, G Loss: 2.3211, AE Loss: 0.4945\n",
            "Epoch 2, D Loss: 1.3885, G Loss: 2.3084, AE Loss: 0.5110\n",
            "Epoch 2, D Loss: 0.8122, G Loss: 2.1791, AE Loss: 0.5897\n",
            "Epoch 2, D Loss: 0.7120, G Loss: 2.3416, AE Loss: 0.4745\n",
            "Epoch 2, D Loss: 0.4814, G Loss: 2.1255, AE Loss: 0.5849\n",
            "Epoch 2, D Loss: 0.7242, G Loss: 2.1116, AE Loss: 0.5572\n",
            "Epoch 2, D Loss: 0.9227, G Loss: 2.2263, AE Loss: 0.5428\n",
            "Epoch 2, D Loss: 1.0780, G Loss: 2.2528, AE Loss: 0.3833\n",
            "Epoch 2, D Loss: 0.8602, G Loss: 2.1889, AE Loss: 0.6606\n",
            "Epoch 2, D Loss: 1.0230, G Loss: 1.8914, AE Loss: 0.6816\n",
            "Epoch 2, D Loss: 0.7105, G Loss: 2.0920, AE Loss: 0.5999\n",
            "Epoch 2, D Loss: 1.0196, G Loss: 2.2576, AE Loss: 0.4742\n",
            "Epoch 2, D Loss: 0.4286, G Loss: 2.1807, AE Loss: 0.6857\n",
            "Epoch 2, D Loss: 0.5026, G Loss: 1.6912, AE Loss: 0.5506\n",
            "Epoch 2, D Loss: 0.5695, G Loss: 2.1156, AE Loss: 0.7355\n",
            "Epoch 2, D Loss: 1.3675, G Loss: 2.1194, AE Loss: 0.5750\n",
            "Epoch 2, D Loss: 0.2724, G Loss: 2.1267, AE Loss: 0.5611\n",
            "Epoch 2, D Loss: 0.8667, G Loss: 2.0981, AE Loss: 0.6098\n",
            "Epoch 2, D Loss: 0.8613, G Loss: 2.2673, AE Loss: 0.5875\n",
            "Epoch 2, D Loss: 0.9587, G Loss: 2.1778, AE Loss: 0.5125\n",
            "Epoch 2, D Loss: 0.3018, G Loss: 2.0106, AE Loss: 0.4850\n",
            "Epoch 2, D Loss: 0.5763, G Loss: 2.5183, AE Loss: 0.5447\n",
            "Epoch 2, D Loss: 0.7966, G Loss: 1.8987, AE Loss: 0.5119\n",
            "Epoch 2, D Loss: 1.0261, G Loss: 2.0600, AE Loss: 0.7179\n",
            "Epoch 2, D Loss: 0.2760, G Loss: 2.2241, AE Loss: 0.5862\n",
            "Epoch 2, D Loss: 0.3777, G Loss: 2.2520, AE Loss: 0.4635\n",
            "Epoch 2, D Loss: 0.8714, G Loss: 2.0664, AE Loss: 0.6184\n",
            "Epoch 2, D Loss: 0.7000, G Loss: 2.0905, AE Loss: 0.5949\n",
            "Epoch 2, D Loss: 0.9140, G Loss: 1.9693, AE Loss: 0.6510\n",
            "Epoch 2, D Loss: 0.1691, G Loss: 2.2675, AE Loss: 0.4712\n",
            "Epoch 2, D Loss: 0.9981, G Loss: 2.0635, AE Loss: 0.5762\n",
            "Epoch 2, D Loss: 0.7173, G Loss: 2.0555, AE Loss: 0.5312\n",
            "Epoch 2, D Loss: 0.3168, G Loss: 2.0142, AE Loss: 0.7817\n",
            "Epoch 2, D Loss: 0.7809, G Loss: 2.0875, AE Loss: 0.6164\n",
            "Epoch 2, D Loss: 0.9639, G Loss: 2.0770, AE Loss: 0.4816\n",
            "Epoch 2, D Loss: 0.5395, G Loss: 2.2869, AE Loss: 0.6367\n",
            "Epoch 2, D Loss: 1.2702, G Loss: 2.2336, AE Loss: 0.5780\n",
            "Epoch 2, D Loss: 0.6314, G Loss: 2.0538, AE Loss: 0.6341\n",
            "Epoch 2, D Loss: 0.5715, G Loss: 2.4250, AE Loss: 0.5344\n",
            "Epoch 2, D Loss: 0.3708, G Loss: 2.1418, AE Loss: 0.5634\n",
            "Epoch 2, D Loss: 0.6539, G Loss: 2.4389, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 0.5997, G Loss: 2.1160, AE Loss: 0.6255\n",
            "Epoch 2, D Loss: 0.5749, G Loss: 2.4312, AE Loss: 0.5856\n",
            "Epoch 2, D Loss: 0.7636, G Loss: 2.1562, AE Loss: 0.5858\n",
            "Epoch 2, D Loss: 0.8923, G Loss: 2.1801, AE Loss: 0.5752\n",
            "Epoch 2, D Loss: 2.0483, G Loss: 2.0815, AE Loss: 0.6202\n",
            "Epoch 2, D Loss: 1.0609, G Loss: 2.1316, AE Loss: 0.5031\n",
            "Epoch 2, D Loss: 0.7533, G Loss: 2.0712, AE Loss: 0.6437\n",
            "Epoch 2, D Loss: 0.5970, G Loss: 2.1253, AE Loss: 0.6154\n",
            "Epoch 2, D Loss: 0.5602, G Loss: 1.9464, AE Loss: 0.5457\n",
            "Epoch 2, D Loss: 0.5064, G Loss: 2.1703, AE Loss: 0.6471\n",
            "Epoch 2, D Loss: 0.4973, G Loss: 1.8730, AE Loss: 0.4439\n",
            "Epoch 2, D Loss: 1.5327, G Loss: 1.9951, AE Loss: 0.4902\n",
            "Epoch 2, D Loss: 0.3918, G Loss: 2.0315, AE Loss: 0.5621\n",
            "Epoch 2, D Loss: 0.4711, G Loss: 1.8102, AE Loss: 0.6638\n",
            "Epoch 2, D Loss: 1.2339, G Loss: 1.6066, AE Loss: 0.4574\n",
            "Epoch 2, D Loss: 0.5345, G Loss: 1.7559, AE Loss: 0.5622\n",
            "Epoch 2, D Loss: 0.6171, G Loss: 1.7520, AE Loss: 0.8135\n",
            "Epoch 2, D Loss: 0.4077, G Loss: 1.7552, AE Loss: 0.5888\n",
            "Epoch 2, D Loss: 1.6285, G Loss: 1.9854, AE Loss: 0.6673\n",
            "Epoch 2, D Loss: 0.5530, G Loss: 2.2005, AE Loss: 0.5399\n",
            "Epoch 2, D Loss: 0.3977, G Loss: 1.9526, AE Loss: 0.5487\n",
            "Epoch 2, D Loss: 0.7077, G Loss: 2.1026, AE Loss: 0.6173\n",
            "Epoch 2, D Loss: 1.9222, G Loss: 1.7307, AE Loss: 0.6509\n",
            "Epoch 2, D Loss: 1.0570, G Loss: 1.7749, AE Loss: 0.5197\n",
            "Epoch 2, D Loss: 0.6021, G Loss: 1.9470, AE Loss: 0.5741\n",
            "Epoch 2, D Loss: 1.5719, G Loss: 1.9361, AE Loss: 0.5733\n",
            "Epoch 2, D Loss: 0.8336, G Loss: 1.4962, AE Loss: 0.7048\n",
            "Epoch 2, D Loss: 0.5261, G Loss: 2.0591, AE Loss: 0.6154\n",
            "Epoch 2, D Loss: 0.5692, G Loss: 1.7169, AE Loss: 0.4271\n",
            "Epoch 2, D Loss: 0.4177, G Loss: 2.1197, AE Loss: 0.5703\n",
            "Epoch 2, D Loss: 0.4011, G Loss: 1.9583, AE Loss: 0.3944\n",
            "Epoch 2, D Loss: 1.6115, G Loss: 1.9207, AE Loss: 0.6847\n",
            "Epoch 2, D Loss: 1.0932, G Loss: 1.8366, AE Loss: 0.6483\n",
            "Epoch 2, D Loss: 0.8054, G Loss: 1.4959, AE Loss: 0.7545\n",
            "Epoch 2, D Loss: 0.8685, G Loss: 1.5936, AE Loss: 0.5852\n",
            "Epoch 2, D Loss: 1.8915, G Loss: 1.7275, AE Loss: 0.5346\n",
            "Epoch 2, D Loss: 1.2159, G Loss: 1.8577, AE Loss: 0.5351\n",
            "Epoch 2, D Loss: 1.6311, G Loss: 2.1583, AE Loss: 0.5249\n",
            "Epoch 2, D Loss: 0.7161, G Loss: 1.6926, AE Loss: 0.6507\n",
            "Epoch 2, D Loss: 0.8969, G Loss: 1.9355, AE Loss: 0.4698\n",
            "Epoch 2, D Loss: 0.7483, G Loss: 1.6853, AE Loss: 0.5621\n",
            "Epoch 2, D Loss: 0.9251, G Loss: 1.8406, AE Loss: 0.5086\n",
            "Epoch 2, D Loss: 0.3037, G Loss: 1.7168, AE Loss: 0.5713\n",
            "Epoch 2, D Loss: 1.7294, G Loss: 2.0177, AE Loss: 0.5440\n",
            "Epoch 2, D Loss: 0.6953, G Loss: 2.0548, AE Loss: 0.5218\n",
            "Epoch 2, D Loss: 0.9649, G Loss: 1.7096, AE Loss: 0.5928\n",
            "Epoch 2, D Loss: 0.7866, G Loss: 1.7484, AE Loss: 0.4986\n",
            "Epoch 2, D Loss: 2.3278, G Loss: 1.8827, AE Loss: 0.4541\n",
            "Epoch 2, D Loss: 0.5991, G Loss: 1.6903, AE Loss: 0.5455\n",
            "Epoch 2, D Loss: 0.8836, G Loss: 1.8240, AE Loss: 0.6365\n",
            "Epoch 2, D Loss: 0.9516, G Loss: 1.6597, AE Loss: 0.6735\n",
            "Epoch 2, D Loss: 0.8447, G Loss: 1.7094, AE Loss: 0.6988\n",
            "Epoch 2, D Loss: 0.5033, G Loss: 1.9076, AE Loss: 0.5225\n",
            "Epoch 2, D Loss: 0.7352, G Loss: 1.8176, AE Loss: 0.5197\n",
            "Epoch 2, D Loss: 0.4558, G Loss: 1.6371, AE Loss: 0.4928\n",
            "Epoch 2, D Loss: 1.0968, G Loss: 1.7126, AE Loss: 0.4482\n",
            "Epoch 2, D Loss: 1.2337, G Loss: 1.6218, AE Loss: 0.5972\n",
            "Epoch 2, D Loss: 0.5132, G Loss: 1.6211, AE Loss: 0.5645\n",
            "Epoch 2, D Loss: 0.2919, G Loss: 1.5515, AE Loss: 0.6126\n",
            "Epoch 2, D Loss: 0.5843, G Loss: 1.5278, AE Loss: 0.8432\n",
            "Epoch 2, D Loss: 0.7982, G Loss: 1.5132, AE Loss: 0.5445\n",
            "Epoch 2, D Loss: 0.4395, G Loss: 1.5247, AE Loss: 0.6005\n",
            "Epoch 2, D Loss: 0.2888, G Loss: 1.6462, AE Loss: 0.6262\n",
            "Epoch 2, D Loss: 1.4453, G Loss: 1.6423, AE Loss: 0.5320\n",
            "Epoch 2, D Loss: 1.0040, G Loss: 1.6458, AE Loss: 0.4349\n",
            "Epoch 2, D Loss: 2.1245, G Loss: 1.5548, AE Loss: 0.5174\n",
            "Epoch 2, D Loss: 1.5317, G Loss: 1.5298, AE Loss: 0.6121\n",
            "Epoch 2, D Loss: 0.5076, G Loss: 1.5808, AE Loss: 0.5548\n",
            "Epoch 2, D Loss: 0.8527, G Loss: 1.8121, AE Loss: 0.5012\n",
            "Epoch 2, D Loss: 1.2540, G Loss: 1.5753, AE Loss: 0.5162\n",
            "Epoch 2, D Loss: 0.5829, G Loss: 1.4829, AE Loss: 0.5475\n",
            "Epoch 2, D Loss: 1.1783, G Loss: 1.5439, AE Loss: 0.5977\n",
            "Epoch 2, D Loss: 1.4382, G Loss: 1.3929, AE Loss: 0.5272\n",
            "Epoch 2, D Loss: 1.0236, G Loss: 1.6591, AE Loss: 0.5669\n",
            "Epoch 2, D Loss: 0.6621, G Loss: 1.3824, AE Loss: 0.5159\n",
            "Epoch 2, D Loss: 1.1905, G Loss: 1.3689, AE Loss: 0.5758\n",
            "Epoch 2, D Loss: 0.9402, G Loss: 1.4196, AE Loss: 0.4234\n",
            "Epoch 2, D Loss: 1.0911, G Loss: 1.5822, AE Loss: 0.4203\n",
            "Epoch 2, D Loss: 0.6579, G Loss: 1.2817, AE Loss: 0.4326\n",
            "Epoch 2, D Loss: 0.9344, G Loss: 1.1763, AE Loss: 0.4909\n",
            "Epoch 2, D Loss: 0.4798, G Loss: 1.2698, AE Loss: 0.5012\n",
            "Epoch 2, D Loss: 1.6011, G Loss: 1.2260, AE Loss: 0.4507\n",
            "Epoch 2, D Loss: 1.3798, G Loss: 1.1161, AE Loss: 0.5315\n",
            "Epoch 2, D Loss: 0.9552, G Loss: 1.1558, AE Loss: 0.5656\n",
            "Epoch 2, D Loss: 1.0433, G Loss: 1.0726, AE Loss: 0.5001\n",
            "Epoch 2, D Loss: 0.4715, G Loss: 1.3200, AE Loss: 0.6184\n",
            "Epoch 2, D Loss: 1.0260, G Loss: 1.1460, AE Loss: 0.5793\n",
            "Epoch 2, D Loss: 1.2302, G Loss: 0.9827, AE Loss: 0.5422\n",
            "Epoch 2, D Loss: 1.0617, G Loss: 0.9062, AE Loss: 0.4453\n",
            "Epoch 2, D Loss: 1.4394, G Loss: 0.8883, AE Loss: 0.4335\n",
            "Epoch 2, D Loss: 0.8690, G Loss: 0.9485, AE Loss: 0.5739\n",
            "Epoch 2, D Loss: 1.4133, G Loss: 0.9206, AE Loss: 0.7292\n",
            "Epoch 2, D Loss: 0.9489, G Loss: 0.8659, AE Loss: 0.6234\n",
            "Epoch 2, D Loss: 0.7514, G Loss: 1.2183, AE Loss: 0.5877\n",
            "Epoch 2, D Loss: 1.3176, G Loss: 0.7439, AE Loss: 0.5186\n",
            "Epoch 2, D Loss: 1.4299, G Loss: 0.9083, AE Loss: 0.5972\n",
            "Epoch 2, D Loss: 1.0624, G Loss: 0.7589, AE Loss: 0.6706\n",
            "Epoch 2, D Loss: 2.0557, G Loss: 0.9548, AE Loss: 0.4524\n",
            "Epoch 2, D Loss: 1.6023, G Loss: 1.0198, AE Loss: 0.5157\n",
            "Epoch 2, D Loss: 1.2078, G Loss: 0.9089, AE Loss: 0.5826\n",
            "Epoch 2, D Loss: 0.7176, G Loss: 0.8522, AE Loss: 0.5323\n",
            "Epoch 2, D Loss: 1.9297, G Loss: 0.8559, AE Loss: 0.6007\n",
            "Epoch 2, D Loss: 1.2767, G Loss: 0.7238, AE Loss: 0.7267\n",
            "Epoch 2, D Loss: 1.4893, G Loss: 0.8423, AE Loss: 0.5167\n",
            "Epoch 2, D Loss: 1.1210, G Loss: 0.9377, AE Loss: 0.6017\n",
            "Epoch 2, D Loss: 0.9936, G Loss: 1.0408, AE Loss: 0.5601\n",
            "Epoch 2, D Loss: 1.3545, G Loss: 1.0014, AE Loss: 0.5083\n",
            "Epoch 2, D Loss: 1.3714, G Loss: 1.0110, AE Loss: 0.5506\n",
            "Epoch 2, D Loss: 1.1018, G Loss: 0.9815, AE Loss: 0.5061\n",
            "Epoch 2, D Loss: 0.7012, G Loss: 1.0903, AE Loss: 0.7456\n",
            "Epoch 2, D Loss: 1.4681, G Loss: 1.0810, AE Loss: 0.5987\n",
            "Epoch 2, D Loss: 1.3083, G Loss: 1.0065, AE Loss: 0.6146\n",
            "Epoch 2, D Loss: 1.8312, G Loss: 1.1848, AE Loss: 0.6271\n",
            "Epoch 2, D Loss: 1.1473, G Loss: 1.0612, AE Loss: 0.5551\n",
            "Epoch 2, D Loss: 0.7061, G Loss: 1.1496, AE Loss: 0.5139\n",
            "Epoch 2, D Loss: 1.2609, G Loss: 0.9372, AE Loss: 0.4961\n",
            "Epoch 2, D Loss: 0.9505, G Loss: 1.0710, AE Loss: 0.5133\n",
            "Epoch 2, D Loss: 1.6380, G Loss: 1.2617, AE Loss: 0.4675\n",
            "Epoch 2, D Loss: 2.8367, G Loss: 1.0846, AE Loss: 0.6038\n",
            "Epoch 2, D Loss: 0.9671, G Loss: 1.1121, AE Loss: 0.4697\n",
            "Epoch 2, D Loss: 1.1763, G Loss: 1.2887, AE Loss: 0.4888\n",
            "Epoch 2, D Loss: 0.4807, G Loss: 1.1024, AE Loss: 0.4666\n",
            "Epoch 2, D Loss: 1.0143, G Loss: 1.2893, AE Loss: 0.5363\n",
            "Epoch 2, D Loss: 0.6527, G Loss: 1.1019, AE Loss: 0.5593\n",
            "Epoch 2, D Loss: 0.9514, G Loss: 1.1498, AE Loss: 0.5363\n",
            "Epoch 2, D Loss: 0.8412, G Loss: 1.1215, AE Loss: 0.4552\n",
            "Epoch 2, D Loss: 1.1721, G Loss: 1.1869, AE Loss: 0.4910\n",
            "Epoch 2, D Loss: 1.0046, G Loss: 1.1384, AE Loss: 0.5897\n",
            "Epoch 2, D Loss: 0.8712, G Loss: 1.0153, AE Loss: 0.5963\n",
            "Epoch 2, D Loss: 0.7185, G Loss: 1.2547, AE Loss: 0.5373\n",
            "Epoch 2, D Loss: 1.0045, G Loss: 1.1943, AE Loss: 0.4668\n",
            "Epoch 2, D Loss: 0.9321, G Loss: 1.3718, AE Loss: 0.3756\n",
            "Epoch 2, D Loss: 1.4960, G Loss: 1.1984, AE Loss: 0.5150\n",
            "Epoch 2, D Loss: 1.4503, G Loss: 1.0083, AE Loss: 0.3901\n",
            "Epoch 2, D Loss: 0.9805, G Loss: 1.2239, AE Loss: 0.5732\n",
            "Epoch 2, D Loss: 1.3312, G Loss: 1.2253, AE Loss: 0.6831\n",
            "Epoch 2, D Loss: 0.8719, G Loss: 1.1361, AE Loss: 0.5585\n",
            "Epoch 2, D Loss: 0.5096, G Loss: 1.2753, AE Loss: 0.4979\n",
            "Epoch 2, D Loss: 0.4171, G Loss: 1.1800, AE Loss: 0.5333\n",
            "Epoch 2, D Loss: 1.1811, G Loss: 1.1165, AE Loss: 0.6064\n",
            "Epoch 2, D Loss: 0.6723, G Loss: 1.1758, AE Loss: 0.4502\n",
            "Epoch 2, D Loss: 1.1239, G Loss: 1.2293, AE Loss: 0.6381\n",
            "Epoch 2, D Loss: 1.1981, G Loss: 1.1564, AE Loss: 0.4915\n",
            "Epoch 2, D Loss: 0.7027, G Loss: 1.1372, AE Loss: 0.5117\n",
            "Epoch 2, D Loss: 0.6443, G Loss: 1.0724, AE Loss: 0.4933\n",
            "Epoch 2, D Loss: 0.7308, G Loss: 1.0738, AE Loss: 0.5005\n",
            "Epoch 2, D Loss: 0.4833, G Loss: 1.1410, AE Loss: 0.3971\n",
            "Epoch 2, D Loss: 0.6704, G Loss: 1.1200, AE Loss: 0.5452\n",
            "Epoch 2, D Loss: 0.9170, G Loss: 1.2344, AE Loss: 0.5360\n",
            "Epoch 2, D Loss: 0.6912, G Loss: 1.1572, AE Loss: 0.5557\n",
            "Epoch 2, D Loss: 0.9253, G Loss: 1.2094, AE Loss: 0.7003\n",
            "Epoch 2, D Loss: 0.6071, G Loss: 1.2574, AE Loss: 0.6039\n",
            "Epoch 2, D Loss: 0.5156, G Loss: 1.2004, AE Loss: 0.6047\n",
            "Epoch 2, D Loss: 0.6613, G Loss: 1.2715, AE Loss: 0.6325\n",
            "Epoch 2, D Loss: 0.7093, G Loss: 1.2342, AE Loss: 0.5511\n",
            "Epoch 2, D Loss: 0.8126, G Loss: 1.2271, AE Loss: 0.5807\n",
            "Epoch 2, D Loss: 0.8795, G Loss: 1.2148, AE Loss: 0.5855\n",
            "Epoch 2, D Loss: 0.7318, G Loss: 1.0794, AE Loss: 0.4598\n",
            "Epoch 2, D Loss: 0.5069, G Loss: 1.2073, AE Loss: 0.5067\n",
            "Epoch 2, D Loss: 0.7675, G Loss: 1.2219, AE Loss: 0.6213\n",
            "Epoch 2, D Loss: 0.9153, G Loss: 1.3125, AE Loss: 0.6346\n",
            "Epoch 2, D Loss: 0.6351, G Loss: 1.3342, AE Loss: 0.4382\n",
            "Epoch 2, D Loss: 0.8449, G Loss: 1.2050, AE Loss: 0.6298\n",
            "Epoch 2, D Loss: 1.1437, G Loss: 1.2455, AE Loss: 0.5457\n",
            "Epoch 2, D Loss: 1.2391, G Loss: 1.3061, AE Loss: 0.5093\n",
            "Epoch 2, D Loss: 1.5694, G Loss: 1.2346, AE Loss: 0.5224\n",
            "Epoch 2, D Loss: 0.7743, G Loss: 1.3817, AE Loss: 0.4542\n",
            "Epoch 2, D Loss: 0.6328, G Loss: 1.2724, AE Loss: 0.5710\n",
            "Epoch 2, D Loss: 0.8927, G Loss: 1.3596, AE Loss: 0.5924\n",
            "Epoch 2, D Loss: 0.8973, G Loss: 1.2376, AE Loss: 0.5534\n",
            "Epoch 2, D Loss: 1.0443, G Loss: 1.4547, AE Loss: 0.5696\n",
            "Epoch 2, D Loss: 1.4797, G Loss: 1.3272, AE Loss: 0.4788\n",
            "Epoch 2, D Loss: 0.5117, G Loss: 1.2806, AE Loss: 0.5814\n",
            "Epoch 2, D Loss: 0.6544, G Loss: 1.2897, AE Loss: 0.6249\n",
            "Epoch 2, D Loss: 0.4850, G Loss: 1.3788, AE Loss: 0.5066\n",
            "Epoch 2, D Loss: 0.4069, G Loss: 1.3661, AE Loss: 0.6836\n",
            "Epoch 2, D Loss: 0.9822, G Loss: 1.2250, AE Loss: 0.6666\n",
            "Epoch 2, D Loss: 0.6864, G Loss: 1.3800, AE Loss: 0.5200\n",
            "Epoch 2, D Loss: 0.3495, G Loss: 1.3441, AE Loss: 0.6450\n",
            "Epoch 2, D Loss: 1.1405, G Loss: 1.3682, AE Loss: 0.5218\n",
            "Epoch 2, D Loss: 0.5103, G Loss: 1.2683, AE Loss: 0.5328\n",
            "Epoch 2, D Loss: 0.7741, G Loss: 1.3996, AE Loss: 0.4684\n",
            "Epoch 2, D Loss: 0.3476, G Loss: 1.3378, AE Loss: 0.7404\n",
            "Epoch 2, D Loss: 0.7548, G Loss: 1.3792, AE Loss: 0.4933\n",
            "Epoch 2, D Loss: 0.3942, G Loss: 1.3555, AE Loss: 0.5990\n",
            "Epoch 2, D Loss: 0.4565, G Loss: 1.4200, AE Loss: 0.5786\n",
            "Epoch 2, D Loss: 0.7195, G Loss: 1.3232, AE Loss: 0.5107\n",
            "Epoch 2, D Loss: 0.8739, G Loss: 1.2888, AE Loss: 0.5054\n",
            "Epoch 2, D Loss: 0.6446, G Loss: 1.3673, AE Loss: 0.6028\n",
            "Epoch 2, D Loss: 0.5678, G Loss: 1.3466, AE Loss: 0.4935\n",
            "Epoch 2, D Loss: 0.5090, G Loss: 1.6302, AE Loss: 0.5977\n",
            "Epoch 2, D Loss: 0.6438, G Loss: 1.5055, AE Loss: 0.5755\n",
            "Epoch 2, D Loss: 0.9165, G Loss: 1.5387, AE Loss: 0.5753\n",
            "Epoch 2, D Loss: 0.8795, G Loss: 1.3952, AE Loss: 0.4997\n",
            "Epoch 2, D Loss: 0.9061, G Loss: 1.5758, AE Loss: 0.6515\n",
            "Epoch 2, D Loss: 0.4297, G Loss: 1.5049, AE Loss: 0.5945\n",
            "Epoch 2, D Loss: 0.6223, G Loss: 1.5080, AE Loss: 0.5973\n",
            "Epoch 2, D Loss: 0.8242, G Loss: 1.4123, AE Loss: 0.5674\n",
            "Epoch 2, D Loss: 0.7602, G Loss: 1.4576, AE Loss: 0.4650\n",
            "Epoch 2, D Loss: 0.9159, G Loss: 1.4471, AE Loss: 0.5380\n",
            "Epoch 2, D Loss: 0.7837, G Loss: 1.4444, AE Loss: 0.5158\n",
            "Epoch 2, D Loss: 0.8849, G Loss: 1.5386, AE Loss: 0.5504\n",
            "Epoch 2, D Loss: 0.4799, G Loss: 1.5887, AE Loss: 0.5944\n",
            "Epoch 2, D Loss: 0.7979, G Loss: 1.5310, AE Loss: 0.4968\n",
            "Epoch 2, D Loss: 0.6829, G Loss: 1.4858, AE Loss: 0.6496\n",
            "Epoch 2, D Loss: 0.3061, G Loss: 1.5535, AE Loss: 0.6330\n",
            "Epoch 2, D Loss: 0.4257, G Loss: 1.5959, AE Loss: 0.5028\n",
            "Epoch 2, D Loss: 0.8140, G Loss: 1.4989, AE Loss: 0.5130\n",
            "Epoch 2, D Loss: 0.5914, G Loss: 1.5481, AE Loss: 0.5580\n",
            "Epoch 2, D Loss: 0.5703, G Loss: 1.5114, AE Loss: 0.5893\n",
            "Epoch 2, D Loss: 0.8599, G Loss: 1.5183, AE Loss: 0.5778\n",
            "Epoch 2, D Loss: 0.5254, G Loss: 1.6123, AE Loss: 0.5431\n",
            "Epoch 2, D Loss: 0.7328, G Loss: 1.5908, AE Loss: 0.5701\n",
            "Epoch 2, D Loss: 0.4061, G Loss: 1.6111, AE Loss: 0.5471\n",
            "Epoch 2, D Loss: 0.8430, G Loss: 1.6498, AE Loss: 0.5223\n",
            "Epoch 2, D Loss: 0.3600, G Loss: 1.6664, AE Loss: 0.5969\n",
            "Epoch 2, D Loss: 0.5991, G Loss: 1.7221, AE Loss: 0.5779\n",
            "Epoch 2, D Loss: 0.8249, G Loss: 1.6291, AE Loss: 0.5160\n",
            "Epoch 2, D Loss: 0.5723, G Loss: 1.7242, AE Loss: 0.4772\n",
            "Epoch 2, D Loss: 0.2583, G Loss: 1.7041, AE Loss: 0.5342\n",
            "Epoch 2, D Loss: 0.9186, G Loss: 1.7697, AE Loss: 0.5601\n",
            "Epoch 2, D Loss: 0.4745, G Loss: 1.7092, AE Loss: 0.6194\n",
            "Epoch 2, D Loss: 0.6910, G Loss: 1.7163, AE Loss: 0.5093\n",
            "Epoch 2, D Loss: 0.8415, G Loss: 1.7553, AE Loss: 0.4846\n",
            "Epoch 2, D Loss: 0.5257, G Loss: 1.7658, AE Loss: 0.5646\n",
            "Epoch 2, D Loss: 0.9762, G Loss: 1.7964, AE Loss: 0.6420\n",
            "Epoch 2, D Loss: 0.5286, G Loss: 1.7795, AE Loss: 0.5588\n",
            "Epoch 2, D Loss: 0.3862, G Loss: 1.7817, AE Loss: 0.5670\n",
            "Epoch 2, D Loss: 0.7017, G Loss: 1.8466, AE Loss: 0.4398\n",
            "Epoch 2, D Loss: 0.5966, G Loss: 1.7259, AE Loss: 0.5563\n",
            "Epoch 2, D Loss: 0.5082, G Loss: 1.6580, AE Loss: 0.5651\n",
            "Epoch 2, D Loss: 0.6457, G Loss: 1.7056, AE Loss: 0.6604\n",
            "Epoch 2, D Loss: 0.2036, G Loss: 1.7576, AE Loss: 0.5697\n",
            "Epoch 2, D Loss: 0.5822, G Loss: 1.7310, AE Loss: 0.5182\n",
            "Epoch 2, D Loss: 0.5374, G Loss: 1.6749, AE Loss: 0.4837\n",
            "Epoch 2, D Loss: 0.1992, G Loss: 1.8026, AE Loss: 0.5615\n",
            "Epoch 2, D Loss: 0.6695, G Loss: 1.7928, AE Loss: 0.5655\n",
            "Epoch 2, D Loss: 0.8450, G Loss: 1.7193, AE Loss: 0.6038\n",
            "Epoch 2, D Loss: 1.0363, G Loss: 1.6142, AE Loss: 0.6315\n",
            "Epoch 2, D Loss: 0.6820, G Loss: 1.6170, AE Loss: 0.5888\n",
            "Epoch 2, D Loss: 0.3820, G Loss: 1.6111, AE Loss: 0.5391\n",
            "Epoch 2, D Loss: 0.5421, G Loss: 1.5111, AE Loss: 0.6449\n",
            "Epoch 2, D Loss: 0.7815, G Loss: 1.5713, AE Loss: 0.6858\n",
            "Epoch 2, D Loss: 0.7126, G Loss: 1.5807, AE Loss: 0.5982\n",
            "Epoch 2, D Loss: 0.4766, G Loss: 1.4896, AE Loss: 0.5664\n",
            "Epoch 2, D Loss: 1.0808, G Loss: 1.4289, AE Loss: 0.5920\n",
            "Epoch 2, D Loss: 0.7439, G Loss: 1.4472, AE Loss: 0.4691\n",
            "Epoch 2, D Loss: 0.4006, G Loss: 1.3353, AE Loss: 0.5165\n",
            "Epoch 2, D Loss: 0.7283, G Loss: 1.3734, AE Loss: 0.5375\n",
            "Epoch 2, D Loss: 0.6356, G Loss: 1.2986, AE Loss: 0.5959\n",
            "Epoch 2, D Loss: 0.5189, G Loss: 1.3059, AE Loss: 0.5409\n",
            "Epoch 2, D Loss: 0.8798, G Loss: 1.3150, AE Loss: 0.5640\n",
            "Epoch 2, D Loss: 0.4476, G Loss: 1.1902, AE Loss: 0.5412\n",
            "Epoch 2, D Loss: 0.3967, G Loss: 1.2334, AE Loss: 0.6591\n",
            "Epoch 2, D Loss: 0.7804, G Loss: 1.1683, AE Loss: 0.6182\n",
            "Epoch 2, D Loss: 0.5318, G Loss: 1.4089, AE Loss: 0.4852\n",
            "Epoch 2, D Loss: 0.5003, G Loss: 1.1055, AE Loss: 0.5646\n",
            "Epoch 2, D Loss: 0.4869, G Loss: 1.2570, AE Loss: 0.5873\n",
            "Epoch 2, D Loss: 0.5987, G Loss: 1.2601, AE Loss: 0.5801\n",
            "Epoch 2, D Loss: 0.7530, G Loss: 1.3002, AE Loss: 0.4927\n",
            "Epoch 2, D Loss: 1.0244, G Loss: 1.2703, AE Loss: 0.6257\n",
            "Epoch 2, D Loss: 0.7633, G Loss: 1.1900, AE Loss: 0.5956\n",
            "Epoch 2, D Loss: 0.9554, G Loss: 1.2324, AE Loss: 0.5340\n",
            "Epoch 2, D Loss: 0.7953, G Loss: 1.2042, AE Loss: 0.4758\n",
            "Epoch 2, D Loss: 0.6015, G Loss: 1.1804, AE Loss: 0.6195\n",
            "Epoch 2, D Loss: 0.6940, G Loss: 1.1991, AE Loss: 0.6219\n",
            "Epoch 2, D Loss: 0.5359, G Loss: 1.3025, AE Loss: 0.5182\n",
            "Epoch 2, D Loss: 0.5574, G Loss: 1.2299, AE Loss: 0.6405\n",
            "Epoch 2, D Loss: 0.6638, G Loss: 1.2697, AE Loss: 0.5380\n",
            "Epoch 2, D Loss: 1.2290, G Loss: 1.1154, AE Loss: 0.6480\n",
            "Epoch 2, D Loss: 0.9108, G Loss: 1.2209, AE Loss: 0.4637\n",
            "Epoch 2, D Loss: 1.0090, G Loss: 1.3563, AE Loss: 0.4490\n",
            "Epoch 2, D Loss: 0.9994, G Loss: 1.4905, AE Loss: 0.4762\n",
            "Epoch 2, D Loss: 0.5770, G Loss: 1.4299, AE Loss: 0.5051\n",
            "Epoch 2, D Loss: 0.6143, G Loss: 1.2156, AE Loss: 0.4824\n",
            "Epoch 2, D Loss: 0.4449, G Loss: 1.3304, AE Loss: 0.5327\n",
            "Epoch 2, D Loss: 0.6071, G Loss: 1.3534, AE Loss: 0.4583\n",
            "Epoch 2, D Loss: 0.5521, G Loss: 1.2463, AE Loss: 0.5362\n",
            "Epoch 2, D Loss: 0.9148, G Loss: 1.3894, AE Loss: 0.6039\n",
            "Epoch 2, D Loss: 0.8311, G Loss: 1.2997, AE Loss: 0.3973\n",
            "Epoch 2, D Loss: 1.0559, G Loss: 1.2873, AE Loss: 0.5658\n",
            "Epoch 2, D Loss: 0.9395, G Loss: 1.1626, AE Loss: 0.6071\n",
            "Epoch 2, D Loss: 0.5967, G Loss: 1.3660, AE Loss: 0.5362\n",
            "Epoch 2, D Loss: 0.4674, G Loss: 1.3394, AE Loss: 0.4916\n",
            "Epoch 2, D Loss: 0.4328, G Loss: 1.2021, AE Loss: 0.6519\n",
            "Epoch 2, D Loss: 1.0632, G Loss: 1.2319, AE Loss: 0.6053\n",
            "Epoch 2, D Loss: 0.6016, G Loss: 1.2385, AE Loss: 0.5059\n",
            "Epoch 2, D Loss: 0.9768, G Loss: 1.4213, AE Loss: 0.5771\n",
            "Epoch 2, D Loss: 0.8268, G Loss: 1.2747, AE Loss: 0.5470\n",
            "Epoch 2, D Loss: 0.7380, G Loss: 1.4364, AE Loss: 0.5915\n",
            "Epoch 2, D Loss: 0.4268, G Loss: 1.3892, AE Loss: 0.5927\n",
            "Epoch 2, D Loss: 0.7116, G Loss: 1.3381, AE Loss: 0.7469\n",
            "Epoch 2, D Loss: 0.9187, G Loss: 1.3597, AE Loss: 0.5521\n",
            "Epoch 2, D Loss: 0.5702, G Loss: 1.3466, AE Loss: 0.4743\n",
            "Epoch 2, D Loss: 1.1363, G Loss: 1.2661, AE Loss: 0.4671\n",
            "Epoch 2, D Loss: 0.4333, G Loss: 1.2175, AE Loss: 0.4982\n",
            "Epoch 2, D Loss: 0.8772, G Loss: 1.2512, AE Loss: 0.5171\n",
            "Epoch 2, D Loss: 0.8722, G Loss: 1.2381, AE Loss: 0.6188\n",
            "Epoch 2, D Loss: 0.8126, G Loss: 1.3050, AE Loss: 0.4836\n",
            "Epoch 2, D Loss: 0.7671, G Loss: 1.3313, AE Loss: 0.6212\n",
            "Epoch 2, D Loss: 0.4809, G Loss: 1.3763, AE Loss: 0.4460\n",
            "Epoch 2, D Loss: 0.5404, G Loss: 1.3478, AE Loss: 0.4703\n",
            "Epoch 2, D Loss: 0.5694, G Loss: 1.3277, AE Loss: 0.6133\n",
            "Epoch 2, D Loss: 0.6589, G Loss: 1.3341, AE Loss: 0.6354\n",
            "Epoch 2, D Loss: 0.5777, G Loss: 1.3440, AE Loss: 0.5517\n",
            "Epoch 2, D Loss: 0.5371, G Loss: 1.4148, AE Loss: 0.3525\n",
            "Epoch 2, D Loss: 0.9568, G Loss: 1.3881, AE Loss: 0.5290\n",
            "Epoch 2, D Loss: 0.5032, G Loss: 1.3011, AE Loss: 0.5975\n",
            "Epoch 2, D Loss: 0.6326, G Loss: 1.4597, AE Loss: 0.5733\n",
            "Epoch 2, D Loss: 0.6865, G Loss: 1.4158, AE Loss: 0.6069\n",
            "Epoch 2, D Loss: 0.4587, G Loss: 1.4429, AE Loss: 0.5999\n",
            "Epoch 2, D Loss: 0.3584, G Loss: 1.3625, AE Loss: 0.5020\n",
            "Epoch 2, D Loss: 0.7944, G Loss: 1.3264, AE Loss: 0.5194\n",
            "Epoch 2, D Loss: 0.8020, G Loss: 1.6244, AE Loss: 0.5396\n",
            "Epoch 2, D Loss: 1.2809, G Loss: 1.3915, AE Loss: 0.6006\n",
            "Epoch 2, D Loss: 0.7397, G Loss: 1.6050, AE Loss: 0.5244\n",
            "Epoch 2, D Loss: 1.4656, G Loss: 1.4993, AE Loss: 0.6777\n",
            "Epoch 2, D Loss: 0.8822, G Loss: 1.4018, AE Loss: 0.6643\n",
            "Epoch 2, D Loss: 0.8642, G Loss: 1.5623, AE Loss: 0.7530\n",
            "Epoch 2, D Loss: 0.9268, G Loss: 1.5606, AE Loss: 0.5225\n",
            "Epoch 2, D Loss: 0.8885, G Loss: 1.5121, AE Loss: 0.5696\n",
            "Epoch 2, D Loss: 0.8128, G Loss: 1.4904, AE Loss: 0.5154\n",
            "Epoch 2, D Loss: 1.0254, G Loss: 1.5701, AE Loss: 0.4691\n",
            "Epoch 2, D Loss: 0.3173, G Loss: 1.4377, AE Loss: 0.4670\n",
            "Epoch 2, D Loss: 1.2975, G Loss: 1.4323, AE Loss: 0.5515\n",
            "Epoch 2, D Loss: 0.2766, G Loss: 1.5257, AE Loss: 0.4517\n",
            "Epoch 2, D Loss: 0.7331, G Loss: 1.5608, AE Loss: 0.5011\n",
            "Epoch 2, D Loss: 0.5789, G Loss: 1.5602, AE Loss: 0.5906\n",
            "Epoch 2, D Loss: 0.4222, G Loss: 1.5191, AE Loss: 0.4675\n",
            "Epoch 2, D Loss: 0.4700, G Loss: 1.6755, AE Loss: 0.6273\n",
            "Epoch 2, D Loss: 0.5912, G Loss: 1.5113, AE Loss: 0.6331\n",
            "Epoch 2, D Loss: 0.8218, G Loss: 1.6258, AE Loss: 0.5386\n",
            "Epoch 2, D Loss: 0.6311, G Loss: 1.5285, AE Loss: 0.6838\n",
            "Epoch 2, D Loss: 0.6296, G Loss: 1.7041, AE Loss: 0.5242\n",
            "Epoch 2, D Loss: 0.2549, G Loss: 1.6701, AE Loss: 0.5832\n",
            "Epoch 2, D Loss: 0.3706, G Loss: 1.6701, AE Loss: 0.5310\n",
            "Epoch 2, D Loss: 0.6597, G Loss: 1.6572, AE Loss: 0.6057\n",
            "Epoch 2, D Loss: 0.8470, G Loss: 1.7354, AE Loss: 0.5986\n",
            "Epoch 2, D Loss: 0.5696, G Loss: 1.6544, AE Loss: 0.5410\n",
            "Epoch 2, D Loss: 1.4043, G Loss: 1.7928, AE Loss: 0.5028\n",
            "Epoch 2, D Loss: 1.1413, G Loss: 1.8537, AE Loss: 0.5651\n",
            "Epoch 2, D Loss: 0.5365, G Loss: 1.7162, AE Loss: 0.6134\n",
            "Epoch 2, D Loss: 0.2727, G Loss: 1.8416, AE Loss: 0.5512\n",
            "Epoch 2, D Loss: 0.8782, G Loss: 1.8197, AE Loss: 0.5532\n",
            "Epoch 2, D Loss: 0.3430, G Loss: 1.8754, AE Loss: 0.5373\n",
            "Epoch 2, D Loss: 0.7556, G Loss: 1.8721, AE Loss: 0.5122\n",
            "Epoch 2, D Loss: 0.5704, G Loss: 1.7191, AE Loss: 0.4927\n",
            "Epoch 2, D Loss: 0.4326, G Loss: 1.9395, AE Loss: 0.4730\n",
            "Epoch 2, D Loss: 0.3582, G Loss: 1.9712, AE Loss: 0.5715\n",
            "Epoch 2, D Loss: 0.6085, G Loss: 1.8537, AE Loss: 0.5206\n",
            "Epoch 2, D Loss: 0.7970, G Loss: 1.8178, AE Loss: 0.6091\n",
            "Epoch 2, D Loss: 0.6116, G Loss: 1.8975, AE Loss: 0.6963\n",
            "Epoch 2, D Loss: 0.6319, G Loss: 1.8501, AE Loss: 0.5471\n",
            "Epoch 2, D Loss: 0.4090, G Loss: 1.7569, AE Loss: 0.6322\n",
            "Epoch 2, D Loss: 0.6316, G Loss: 1.8553, AE Loss: 0.5876\n",
            "Epoch 2, D Loss: 0.7326, G Loss: 1.7653, AE Loss: 0.5705\n",
            "Epoch 2, D Loss: 0.5156, G Loss: 1.8293, AE Loss: 0.5426\n",
            "Epoch 2, D Loss: 0.3609, G Loss: 1.8743, AE Loss: 0.6735\n",
            "Epoch 2, D Loss: 0.4683, G Loss: 1.7628, AE Loss: 0.4219\n",
            "Epoch 2, D Loss: 0.3336, G Loss: 1.8585, AE Loss: 0.5086\n",
            "Epoch 2, D Loss: 0.9131, G Loss: 1.8599, AE Loss: 0.6089\n",
            "Epoch 2, D Loss: 0.5387, G Loss: 1.9226, AE Loss: 0.5358\n",
            "Epoch 2, D Loss: 0.5207, G Loss: 1.8135, AE Loss: 0.5411\n",
            "Epoch 2, D Loss: 0.4546, G Loss: 1.9155, AE Loss: 0.4958\n",
            "Epoch 2, D Loss: 0.5259, G Loss: 1.9850, AE Loss: 0.5351\n",
            "Epoch 2, D Loss: 0.5164, G Loss: 1.9713, AE Loss: 0.5377\n",
            "Epoch 2, D Loss: 0.5571, G Loss: 1.8875, AE Loss: 0.5223\n",
            "Epoch 2, D Loss: 0.6788, G Loss: 1.9232, AE Loss: 0.5578\n",
            "Epoch 2, D Loss: 0.5735, G Loss: 1.7593, AE Loss: 0.4921\n",
            "Epoch 2, D Loss: 0.7104, G Loss: 1.8966, AE Loss: 0.5357\n",
            "Epoch 2, D Loss: 0.5631, G Loss: 1.8084, AE Loss: 0.7122\n",
            "Epoch 2, D Loss: 0.2253, G Loss: 1.8438, AE Loss: 0.4557\n",
            "Epoch 2, D Loss: 0.3573, G Loss: 1.8448, AE Loss: 0.4637\n",
            "Epoch 2, D Loss: 0.3091, G Loss: 1.7082, AE Loss: 0.5479\n",
            "Epoch 2, D Loss: 0.3317, G Loss: 1.9283, AE Loss: 0.4968\n",
            "Epoch 2, D Loss: 0.7066, G Loss: 1.7994, AE Loss: 0.4316\n",
            "Epoch 2, D Loss: 0.4484, G Loss: 1.8068, AE Loss: 0.5461\n",
            "Epoch 2, D Loss: 0.2493, G Loss: 1.8221, AE Loss: 0.6144\n",
            "Epoch 2, D Loss: 0.3680, G Loss: 1.6890, AE Loss: 0.5350\n",
            "Epoch 2, D Loss: 0.2331, G Loss: 1.8284, AE Loss: 0.4406\n",
            "Epoch 2, D Loss: 0.5956, G Loss: 1.8254, AE Loss: 0.5402\n",
            "Epoch 2, D Loss: 0.5782, G Loss: 1.8577, AE Loss: 0.4955\n",
            "Epoch 2, D Loss: 0.1922, G Loss: 1.8766, AE Loss: 0.5786\n",
            "Epoch 2, D Loss: 0.5464, G Loss: 1.5803, AE Loss: 0.5664\n",
            "Epoch 2, D Loss: 0.7254, G Loss: 1.7984, AE Loss: 0.4606\n",
            "Epoch 2, D Loss: 0.2727, G Loss: 1.8038, AE Loss: 0.6160\n",
            "Epoch 2, D Loss: 0.5473, G Loss: 1.9068, AE Loss: 0.5079\n",
            "Epoch 2, D Loss: 0.7082, G Loss: 1.9191, AE Loss: 0.5247\n",
            "Epoch 2, D Loss: 0.9219, G Loss: 1.8047, AE Loss: 0.5272\n",
            "Epoch 2, D Loss: 0.4932, G Loss: 1.7774, AE Loss: 0.5935\n",
            "Epoch 2, D Loss: 0.9585, G Loss: 1.9092, AE Loss: 0.5138\n",
            "Epoch 2, D Loss: 0.2859, G Loss: 1.8838, AE Loss: 0.6274\n",
            "Epoch 2, D Loss: 0.3465, G Loss: 1.9018, AE Loss: 0.6563\n",
            "Epoch 2, D Loss: 0.3121, G Loss: 1.8173, AE Loss: 0.4925\n",
            "Epoch 2, D Loss: 0.3835, G Loss: 1.7898, AE Loss: 0.6039\n",
            "Epoch 2, D Loss: 0.3900, G Loss: 1.7214, AE Loss: 0.5846\n",
            "Epoch 2, D Loss: 0.8511, G Loss: 1.8560, AE Loss: 0.6043\n",
            "Epoch 2, D Loss: 0.8360, G Loss: 1.9424, AE Loss: 0.5975\n",
            "Epoch 2, D Loss: 0.6776, G Loss: 1.8235, AE Loss: 0.5821\n",
            "Epoch 2, D Loss: 0.6656, G Loss: 1.7746, AE Loss: 0.5649\n",
            "Epoch 2, D Loss: 0.4584, G Loss: 1.9619, AE Loss: 0.4333\n",
            "Epoch 2, D Loss: 0.5884, G Loss: 1.8987, AE Loss: 0.6229\n",
            "Epoch 2, D Loss: 0.4086, G Loss: 1.7261, AE Loss: 0.6984\n",
            "Epoch 2, D Loss: 1.1759, G Loss: 1.6117, AE Loss: 0.5722\n",
            "Epoch 2, D Loss: 0.7163, G Loss: 1.8247, AE Loss: 0.4940\n",
            "Epoch 2, D Loss: 0.4469, G Loss: 1.7576, AE Loss: 0.5281\n",
            "Epoch 2, D Loss: 0.3795, G Loss: 1.7398, AE Loss: 0.5646\n",
            "Epoch 2, D Loss: 0.2213, G Loss: 1.7893, AE Loss: 0.5669\n",
            "Epoch 2, D Loss: 0.4181, G Loss: 1.9605, AE Loss: 0.4871\n",
            "Epoch 2, D Loss: 0.2448, G Loss: 1.9339, AE Loss: 0.5366\n",
            "Epoch 2, D Loss: 0.5411, G Loss: 1.8203, AE Loss: 0.5888\n",
            "Epoch 2, D Loss: 0.6513, G Loss: 1.7529, AE Loss: 0.6302\n",
            "Epoch 2, D Loss: 0.8438, G Loss: 1.6681, AE Loss: 0.4104\n",
            "Epoch 2, D Loss: 0.7280, G Loss: 1.6977, AE Loss: 0.6151\n",
            "Epoch 2, D Loss: 1.3563, G Loss: 1.8554, AE Loss: 0.5527\n",
            "Epoch 2, D Loss: 0.5593, G Loss: 1.6014, AE Loss: 0.4838\n",
            "Epoch 2, D Loss: 0.4833, G Loss: 1.7982, AE Loss: 0.6410\n",
            "Epoch 2, D Loss: 0.3332, G Loss: 1.7196, AE Loss: 0.4919\n",
            "Epoch 2, D Loss: 0.8151, G Loss: 1.6577, AE Loss: 0.5592\n",
            "Epoch 2, D Loss: 0.5133, G Loss: 1.6064, AE Loss: 0.5745\n",
            "Epoch 2, D Loss: 0.5146, G Loss: 1.5532, AE Loss: 0.4679\n",
            "Epoch 2, D Loss: 1.3331, G Loss: 1.7445, AE Loss: 0.5675\n",
            "Epoch 2, D Loss: 0.3268, G Loss: 1.8006, AE Loss: 0.4680\n",
            "Epoch 2, D Loss: 0.4757, G Loss: 1.8240, AE Loss: 0.6088\n",
            "Epoch 2, D Loss: 0.8096, G Loss: 2.0008, AE Loss: 0.5098\n",
            "Epoch 2, D Loss: 0.2859, G Loss: 1.6608, AE Loss: 0.5923\n",
            "Epoch 2, D Loss: 0.3588, G Loss: 1.9008, AE Loss: 0.5580\n",
            "Epoch 2, D Loss: 0.6426, G Loss: 1.7759, AE Loss: 0.6417\n",
            "Epoch 2, D Loss: 0.5847, G Loss: 1.9640, AE Loss: 0.5432\n",
            "Epoch 2, D Loss: 0.6131, G Loss: 1.9320, AE Loss: 0.6010\n",
            "Epoch 2, D Loss: 1.0285, G Loss: 2.0450, AE Loss: 0.5637\n",
            "Epoch 2, D Loss: 0.7691, G Loss: 2.2808, AE Loss: 0.4530\n",
            "Epoch 2, D Loss: 0.5178, G Loss: 2.0902, AE Loss: 0.6261\n",
            "Epoch 2, D Loss: 0.9144, G Loss: 2.4100, AE Loss: 0.5948\n",
            "Epoch 2, D Loss: 0.4328, G Loss: 2.1483, AE Loss: 0.5053\n",
            "Epoch 2, D Loss: 0.9040, G Loss: 2.2119, AE Loss: 0.6512\n",
            "Epoch 2, D Loss: 0.3951, G Loss: 2.2852, AE Loss: 0.5750\n",
            "Epoch 2, D Loss: 0.1321, G Loss: 2.3290, AE Loss: 0.6604\n",
            "Epoch 2, D Loss: 0.5263, G Loss: 2.3093, AE Loss: 0.5310\n",
            "Epoch 2, D Loss: 0.7595, G Loss: 2.2288, AE Loss: 0.5086\n",
            "Epoch 2, D Loss: 0.6919, G Loss: 2.3389, AE Loss: 0.6065\n",
            "Epoch 2, D Loss: 0.3036, G Loss: 2.1296, AE Loss: 0.5272\n",
            "Epoch 2, D Loss: 0.4614, G Loss: 2.1035, AE Loss: 0.4479\n",
            "Epoch 2, D Loss: 0.7844, G Loss: 2.2487, AE Loss: 0.5157\n",
            "Epoch 2, D Loss: 0.3312, G Loss: 2.2506, AE Loss: 0.5169\n",
            "Epoch 2, D Loss: 0.1888, G Loss: 2.2326, AE Loss: 0.4897\n",
            "Epoch 2, D Loss: 0.3593, G Loss: 2.2294, AE Loss: 0.5323\n",
            "Epoch 2, D Loss: 0.4337, G Loss: 2.3979, AE Loss: 0.5213\n",
            "Epoch 2, D Loss: 0.8453, G Loss: 2.3805, AE Loss: 0.4373\n",
            "Epoch 2, D Loss: 0.5292, G Loss: 2.3641, AE Loss: 0.5345\n",
            "Epoch 2, D Loss: 0.5304, G Loss: 2.1740, AE Loss: 0.4868\n",
            "Epoch 2, D Loss: 0.6473, G Loss: 2.1895, AE Loss: 0.5443\n",
            "Epoch 2, D Loss: 0.3634, G Loss: 2.3435, AE Loss: 0.5593\n",
            "Epoch 2, D Loss: 0.4238, G Loss: 2.3956, AE Loss: 0.6226\n",
            "Epoch 2, D Loss: 0.9458, G Loss: 2.2257, AE Loss: 0.4726\n",
            "Epoch 2, D Loss: 0.6534, G Loss: 2.2567, AE Loss: 0.5842\n",
            "Epoch 2, D Loss: 0.1483, G Loss: 2.2427, AE Loss: 0.5927\n",
            "Epoch 2, D Loss: 0.8203, G Loss: 2.0492, AE Loss: 0.6142\n",
            "Epoch 2, D Loss: 0.2120, G Loss: 2.0377, AE Loss: 0.5595\n",
            "Epoch 2, D Loss: 0.2484, G Loss: 2.1628, AE Loss: 0.5651\n",
            "Epoch 2, D Loss: 0.4154, G Loss: 2.0196, AE Loss: 0.4283\n",
            "Epoch 2, D Loss: 0.2520, G Loss: 2.1175, AE Loss: 0.5732\n",
            "Epoch 2, D Loss: 0.6115, G Loss: 2.0214, AE Loss: 0.5681\n",
            "Epoch 2, D Loss: 0.2054, G Loss: 1.9774, AE Loss: 0.5748\n",
            "Epoch 2, D Loss: 0.2748, G Loss: 1.9233, AE Loss: 0.6097\n",
            "Epoch 2, D Loss: 0.5900, G Loss: 1.9654, AE Loss: 0.5373\n",
            "Epoch 2, D Loss: 0.8792, G Loss: 1.9232, AE Loss: 0.5161\n",
            "Epoch 2, D Loss: 0.2336, G Loss: 1.9363, AE Loss: 0.6857\n",
            "Epoch 2, D Loss: 0.7056, G Loss: 2.0352, AE Loss: 0.7025\n",
            "Epoch 2, D Loss: 0.5519, G Loss: 1.9353, AE Loss: 0.5955\n",
            "Epoch 2, D Loss: 0.7795, G Loss: 1.9468, AE Loss: 0.6524\n",
            "Epoch 2, D Loss: 1.1968, G Loss: 1.8309, AE Loss: 0.5910\n",
            "Epoch 2, D Loss: 0.5689, G Loss: 1.9724, AE Loss: 0.5311\n",
            "Epoch 2, D Loss: 1.3490, G Loss: 1.7115, AE Loss: 0.5376\n",
            "Epoch 2, D Loss: 0.8390, G Loss: 1.7786, AE Loss: 0.5748\n",
            "Epoch 2, D Loss: 0.8309, G Loss: 1.8024, AE Loss: 0.4658\n",
            "Epoch 2, D Loss: 0.3689, G Loss: 1.7449, AE Loss: 0.4919\n",
            "Epoch 2, D Loss: 0.7305, G Loss: 2.0034, AE Loss: 0.5857\n",
            "Epoch 2, D Loss: 0.3470, G Loss: 1.8540, AE Loss: 0.6407\n",
            "Epoch 2, D Loss: 0.2719, G Loss: 1.8550, AE Loss: 0.6266\n",
            "Epoch 2, D Loss: 0.2318, G Loss: 1.9296, AE Loss: 0.5319\n",
            "Epoch 2, D Loss: 0.5353, G Loss: 1.9191, AE Loss: 0.6290\n",
            "Epoch 2, D Loss: 0.5581, G Loss: 1.8644, AE Loss: 0.5749\n",
            "Epoch 2, D Loss: 0.5621, G Loss: 1.8927, AE Loss: 0.6492\n",
            "Epoch 2, D Loss: 0.4921, G Loss: 1.9472, AE Loss: 0.4365\n",
            "Epoch 2, D Loss: 1.1551, G Loss: 1.8451, AE Loss: 0.6049\n",
            "Epoch 2, D Loss: 0.3544, G Loss: 2.0099, AE Loss: 0.5927\n",
            "Epoch 2, D Loss: 0.2661, G Loss: 2.0944, AE Loss: 0.4913\n",
            "Epoch 2, D Loss: 0.6253, G Loss: 2.0269, AE Loss: 0.6779\n",
            "Epoch 2, D Loss: 0.3318, G Loss: 2.0525, AE Loss: 0.5653\n",
            "Epoch 2, D Loss: 0.2643, G Loss: 1.8495, AE Loss: 0.5613\n",
            "Epoch 2, D Loss: 0.6952, G Loss: 1.9525, AE Loss: 0.4890\n",
            "Epoch 2, D Loss: 0.5776, G Loss: 2.0114, AE Loss: 0.5477\n",
            "Epoch 2, D Loss: 0.1878, G Loss: 2.1254, AE Loss: 0.4815\n",
            "Epoch 2, D Loss: 0.4925, G Loss: 1.9717, AE Loss: 0.6284\n",
            "Epoch 2, D Loss: 0.3900, G Loss: 2.1794, AE Loss: 0.5885\n",
            "Epoch 2, D Loss: 0.4226, G Loss: 2.0131, AE Loss: 0.6409\n",
            "Epoch 2, D Loss: 0.4486, G Loss: 1.9078, AE Loss: 0.6022\n",
            "Epoch 2, D Loss: 0.4614, G Loss: 1.8746, AE Loss: 0.4586\n",
            "Epoch 2, D Loss: 0.6868, G Loss: 1.8605, AE Loss: 0.5114\n",
            "Epoch 2, D Loss: 0.4041, G Loss: 1.9064, AE Loss: 0.3903\n",
            "Epoch 2, D Loss: 0.2469, G Loss: 1.8734, AE Loss: 0.4785\n",
            "Epoch 2, D Loss: 0.6508, G Loss: 1.8740, AE Loss: 0.6142\n",
            "Epoch 2, D Loss: 0.8526, G Loss: 1.9536, AE Loss: 0.5440\n",
            "Epoch 2, D Loss: 0.4387, G Loss: 2.0258, AE Loss: 0.5843\n",
            "Epoch 2, D Loss: 1.2378, G Loss: 1.7488, AE Loss: 0.5582\n",
            "Epoch 2, D Loss: 0.3364, G Loss: 2.0040, AE Loss: 0.5395\n",
            "Epoch 2, D Loss: 1.2879, G Loss: 1.9414, AE Loss: 0.5306\n",
            "Epoch 2, D Loss: 0.5820, G Loss: 1.9353, AE Loss: 0.5057\n",
            "Epoch 2, D Loss: 1.2074, G Loss: 1.7880, AE Loss: 0.5925\n",
            "Epoch 2, D Loss: 0.4062, G Loss: 1.9152, AE Loss: 0.4810\n",
            "Epoch 2, D Loss: 0.1866, G Loss: 2.0769, AE Loss: 0.5978\n",
            "Epoch 2, D Loss: 1.0233, G Loss: 1.9161, AE Loss: 0.5103\n",
            "Epoch 2, D Loss: 0.9861, G Loss: 1.8330, AE Loss: 0.4878\n",
            "Epoch 2, D Loss: 0.3714, G Loss: 2.1532, AE Loss: 0.5167\n",
            "Epoch 2, D Loss: 0.1794, G Loss: 2.0191, AE Loss: 0.5322\n",
            "Epoch 2, D Loss: 0.7545, G Loss: 1.9199, AE Loss: 0.6650\n",
            "Epoch 2, D Loss: 0.2283, G Loss: 2.0142, AE Loss: 0.5440\n",
            "Epoch 2, D Loss: 0.1977, G Loss: 1.9536, AE Loss: 0.5483\n",
            "Epoch 2, D Loss: 0.6169, G Loss: 2.0225, AE Loss: 0.6538\n",
            "Epoch 2, D Loss: 0.5358, G Loss: 1.9573, AE Loss: 0.4775\n",
            "Epoch 2, D Loss: 0.3678, G Loss: 2.0052, AE Loss: 0.5916\n",
            "Epoch 2, D Loss: 0.2482, G Loss: 2.0825, AE Loss: 0.6534\n",
            "Epoch 2, D Loss: 0.5545, G Loss: 2.1281, AE Loss: 0.6132\n",
            "Epoch 2, D Loss: 0.1893, G Loss: 2.0250, AE Loss: 0.5078\n",
            "Epoch 2, D Loss: 0.1933, G Loss: 2.1135, AE Loss: 0.5268\n",
            "Epoch 2, D Loss: 0.7387, G Loss: 2.0815, AE Loss: 0.5551\n",
            "Epoch 2, D Loss: 1.4476, G Loss: 2.0742, AE Loss: 0.5941\n",
            "Epoch 2, D Loss: 0.3192, G Loss: 2.0170, AE Loss: 0.4958\n",
            "Epoch 2, D Loss: 0.6731, G Loss: 2.2225, AE Loss: 0.6668\n",
            "Epoch 2, D Loss: 0.1936, G Loss: 2.0274, AE Loss: 0.5554\n",
            "Epoch 2, D Loss: 0.7201, G Loss: 1.9492, AE Loss: 0.5248\n",
            "Epoch 2, D Loss: 0.1635, G Loss: 2.0994, AE Loss: 0.5577\n",
            "Epoch 2, D Loss: 0.2551, G Loss: 1.9925, AE Loss: 0.5208\n",
            "Epoch 2, D Loss: 0.6974, G Loss: 1.9838, AE Loss: 0.5056\n",
            "Epoch 2, D Loss: 0.4929, G Loss: 2.0225, AE Loss: 0.4582\n",
            "Epoch 2, D Loss: 0.5935, G Loss: 2.1409, AE Loss: 0.5001\n",
            "Epoch 2, D Loss: 0.8483, G Loss: 2.0530, AE Loss: 0.4440\n",
            "Epoch 2, D Loss: 0.2998, G Loss: 2.0776, AE Loss: 0.5680\n",
            "Epoch 2, D Loss: 0.2936, G Loss: 1.9248, AE Loss: 0.5339\n",
            "Epoch 2, D Loss: 0.3516, G Loss: 1.8604, AE Loss: 0.5138\n",
            "Epoch 2, D Loss: 0.8115, G Loss: 1.8795, AE Loss: 0.5227\n",
            "Epoch 2, D Loss: 0.2826, G Loss: 1.9226, AE Loss: 0.5405\n",
            "Epoch 2, D Loss: 1.6980, G Loss: 2.0291, AE Loss: 0.5813\n",
            "Epoch 2, D Loss: 0.8577, G Loss: 1.9742, AE Loss: 0.4593\n",
            "Epoch 2, D Loss: 0.5521, G Loss: 1.8923, AE Loss: 0.4335\n",
            "Epoch 2, D Loss: 0.7342, G Loss: 1.9545, AE Loss: 0.6358\n",
            "Epoch 2, D Loss: 0.5564, G Loss: 1.9342, AE Loss: 0.4915\n",
            "Epoch 2, D Loss: 0.5167, G Loss: 1.8578, AE Loss: 0.4782\n",
            "Epoch 2, D Loss: 0.4758, G Loss: 1.8468, AE Loss: 0.5345\n",
            "Epoch 2, D Loss: 0.3640, G Loss: 1.6471, AE Loss: 0.5936\n",
            "Epoch 2, D Loss: 1.3320, G Loss: 1.8192, AE Loss: 0.4950\n",
            "Epoch 2, D Loss: 0.8422, G Loss: 1.9426, AE Loss: 0.5006\n",
            "Epoch 2, D Loss: 0.5183, G Loss: 1.6680, AE Loss: 0.5092\n",
            "Epoch 2, D Loss: 1.0797, G Loss: 1.6486, AE Loss: 0.5189\n",
            "Epoch 2, D Loss: 0.5934, G Loss: 1.6010, AE Loss: 0.5948\n",
            "Epoch 2, D Loss: 0.2793, G Loss: 1.7304, AE Loss: 0.4722\n",
            "Epoch 2, D Loss: 0.9852, G Loss: 1.5890, AE Loss: 0.5728\n",
            "Epoch 2, D Loss: 0.7882, G Loss: 1.5200, AE Loss: 0.7300\n",
            "Epoch 2, D Loss: 1.1576, G Loss: 1.4822, AE Loss: 0.7528\n",
            "Epoch 2, D Loss: 0.5700, G Loss: 1.5285, AE Loss: 0.5094\n",
            "Epoch 2, D Loss: 1.7617, G Loss: 1.7598, AE Loss: 0.4770\n",
            "Epoch 2, D Loss: 1.1698, G Loss: 1.8679, AE Loss: 0.4753\n",
            "Epoch 2, D Loss: 1.1713, G Loss: 1.6055, AE Loss: 0.6131\n",
            "Epoch 2, D Loss: 0.5508, G Loss: 1.6844, AE Loss: 0.5358\n",
            "Epoch 2, D Loss: 1.0121, G Loss: 1.6420, AE Loss: 0.5341\n",
            "Epoch 2, D Loss: 1.2135, G Loss: 1.8548, AE Loss: 0.6273\n",
            "Epoch 2, D Loss: 0.7937, G Loss: 1.8092, AE Loss: 0.4293\n",
            "Epoch 2, D Loss: 1.7099, G Loss: 1.8201, AE Loss: 0.5583\n",
            "Epoch 2, D Loss: 0.8765, G Loss: 1.5111, AE Loss: 0.5286\n",
            "Epoch 2, D Loss: 1.0209, G Loss: 1.7091, AE Loss: 0.4603\n",
            "Epoch 2, D Loss: 0.5262, G Loss: 1.7214, AE Loss: 0.3930\n",
            "Epoch 2, D Loss: 0.7937, G Loss: 1.9244, AE Loss: 0.6756\n",
            "Epoch 2, D Loss: 1.1424, G Loss: 1.7614, AE Loss: 0.5619\n",
            "Epoch 2, D Loss: 0.5586, G Loss: 1.7652, AE Loss: 0.6500\n",
            "Epoch 2, D Loss: 0.3485, G Loss: 1.9937, AE Loss: 0.6223\n",
            "Epoch 2, D Loss: 1.0077, G Loss: 1.6526, AE Loss: 0.5804\n",
            "Epoch 2, D Loss: 1.0970, G Loss: 1.9765, AE Loss: 0.4884\n",
            "Epoch 2, D Loss: 0.8565, G Loss: 1.8891, AE Loss: 0.5553\n",
            "Epoch 2, D Loss: 1.3785, G Loss: 1.8187, AE Loss: 0.5454\n",
            "Epoch 2, D Loss: 0.8903, G Loss: 1.5820, AE Loss: 0.5210\n",
            "Epoch 2, D Loss: 1.8587, G Loss: 1.6268, AE Loss: 0.4930\n",
            "Epoch 2, D Loss: 0.7888, G Loss: 1.7278, AE Loss: 0.5737\n",
            "Epoch 2, D Loss: 2.3416, G Loss: 1.7339, AE Loss: 0.7553\n",
            "Epoch 2, D Loss: 0.7290, G Loss: 1.6626, AE Loss: 0.5564\n",
            "Epoch 2, D Loss: 0.4110, G Loss: 1.5450, AE Loss: 0.4030\n",
            "Epoch 2, D Loss: 1.5229, G Loss: 1.4546, AE Loss: 0.4764\n",
            "Epoch 2, D Loss: 0.3757, G Loss: 1.6512, AE Loss: 0.5695\n",
            "Epoch 2, D Loss: 0.9204, G Loss: 1.5819, AE Loss: 0.4933\n",
            "Epoch 2, D Loss: 0.6687, G Loss: 1.5553, AE Loss: 0.5127\n",
            "Epoch 2, D Loss: 1.7205, G Loss: 1.5338, AE Loss: 0.6423\n",
            "Epoch 2, D Loss: 1.2067, G Loss: 1.6724, AE Loss: 0.5903\n",
            "Epoch 2, D Loss: 2.0251, G Loss: 1.4831, AE Loss: 0.6260\n",
            "Epoch 2, D Loss: 1.3622, G Loss: 1.6928, AE Loss: 0.4898\n",
            "Epoch 2, D Loss: 1.1611, G Loss: 1.2451, AE Loss: 0.5080\n",
            "Epoch 2, D Loss: 0.7224, G Loss: 1.8119, AE Loss: 0.5923\n",
            "Epoch 2, D Loss: 1.1050, G Loss: 1.4077, AE Loss: 0.3936\n",
            "Epoch 2, D Loss: 0.7227, G Loss: 1.5777, AE Loss: 0.5373\n",
            "Epoch 2, D Loss: 1.9357, G Loss: 1.6572, AE Loss: 0.6112\n",
            "Epoch 2, D Loss: 0.9560, G Loss: 1.6326, AE Loss: 0.6075\n",
            "Epoch 2, D Loss: 1.5352, G Loss: 1.7342, AE Loss: 0.4612\n",
            "Epoch 2, D Loss: 0.9478, G Loss: 2.0144, AE Loss: 0.4143\n",
            "Epoch 2, D Loss: 0.6084, G Loss: 1.9675, AE Loss: 0.4028\n",
            "Epoch 2, D Loss: 1.1205, G Loss: 1.3263, AE Loss: 0.5648\n",
            "Epoch 2, D Loss: 1.9877, G Loss: 1.3075, AE Loss: 0.5842\n",
            "Epoch 2, D Loss: 0.8198, G Loss: 1.7778, AE Loss: 0.4887\n",
            "Epoch 2, D Loss: 1.3700, G Loss: 1.8491, AE Loss: 0.6437\n",
            "Epoch 2, D Loss: 1.3825, G Loss: 1.9163, AE Loss: 0.5618\n",
            "Epoch 2, D Loss: 1.7200, G Loss: 1.8080, AE Loss: 0.5233\n",
            "Epoch 2, D Loss: 0.5658, G Loss: 1.6236, AE Loss: 0.5184\n",
            "Epoch 2, D Loss: 0.7175, G Loss: 1.5637, AE Loss: 0.6905\n",
            "Epoch 2, D Loss: 1.8976, G Loss: 1.1016, AE Loss: 0.5412\n",
            "Epoch 2, D Loss: 0.6243, G Loss: 1.6915, AE Loss: 0.4929\n",
            "Epoch 2, D Loss: 1.0622, G Loss: 1.6998, AE Loss: 0.6897\n",
            "Epoch 2, D Loss: 0.5669, G Loss: 1.4091, AE Loss: 0.4866\n",
            "Epoch 2, D Loss: 0.8894, G Loss: 1.5846, AE Loss: 0.6395\n",
            "Epoch 2, D Loss: 1.2296, G Loss: 1.4805, AE Loss: 0.5695\n",
            "Epoch 2, D Loss: 0.9244, G Loss: 1.5244, AE Loss: 0.4811\n",
            "Epoch 2, D Loss: 1.7606, G Loss: 1.2611, AE Loss: 0.9645\n",
            "Epoch 2, D Loss: 1.2657, G Loss: 1.3645, AE Loss: 0.6192\n",
            "Epoch 2, D Loss: 0.6096, G Loss: 1.5404, AE Loss: 0.5106\n",
            "Epoch 2, D Loss: 0.5405, G Loss: 1.6936, AE Loss: 0.4992\n",
            "Epoch 2, D Loss: 0.9789, G Loss: 1.3604, AE Loss: 0.6754\n",
            "Epoch 2, D Loss: 1.2444, G Loss: 1.3817, AE Loss: 0.5729\n",
            "Epoch 2, D Loss: 1.3887, G Loss: 1.6985, AE Loss: 0.5469\n",
            "Epoch 2, D Loss: 0.6370, G Loss: 1.4092, AE Loss: 0.5355\n",
            "Epoch 2, D Loss: 1.0244, G Loss: 1.5976, AE Loss: 0.7955\n",
            "Epoch 2, D Loss: 0.4400, G Loss: 1.4671, AE Loss: 0.4147\n",
            "Epoch 2, D Loss: 0.9372, G Loss: 1.5870, AE Loss: 0.4569\n",
            "Epoch 2, D Loss: 0.5733, G Loss: 1.7098, AE Loss: 0.5396\n",
            "Epoch 2, D Loss: 0.8443, G Loss: 1.3827, AE Loss: 0.4302\n",
            "Epoch 2, D Loss: 0.7522, G Loss: 1.4618, AE Loss: 0.5178\n",
            "Epoch 2, D Loss: 1.0275, G Loss: 1.5437, AE Loss: 0.6639\n",
            "Epoch 2, D Loss: 1.1155, G Loss: 1.6921, AE Loss: 0.5590\n",
            "Epoch 2, D Loss: 0.4696, G Loss: 1.5262, AE Loss: 0.6530\n",
            "Epoch 2, D Loss: 0.8041, G Loss: 1.7135, AE Loss: 0.6142\n",
            "Epoch 2, D Loss: 1.9171, G Loss: 1.6488, AE Loss: 0.7006\n",
            "Epoch 2, D Loss: 0.6031, G Loss: 1.5368, AE Loss: 0.4533\n",
            "Epoch 2, D Loss: 1.1320, G Loss: 1.6507, AE Loss: 0.5244\n",
            "Epoch 2, D Loss: 1.3612, G Loss: 1.8617, AE Loss: 0.5806\n",
            "Epoch 2, D Loss: 1.7258, G Loss: 1.4879, AE Loss: 0.5253\n",
            "Epoch 2, D Loss: 1.7283, G Loss: 1.7273, AE Loss: 0.5471\n",
            "Epoch 2, D Loss: 1.0784, G Loss: 1.6141, AE Loss: 0.4794\n",
            "Epoch 2, D Loss: 1.0473, G Loss: 1.6746, AE Loss: 0.6487\n",
            "Epoch 2, D Loss: 1.1775, G Loss: 1.6145, AE Loss: 0.5338\n",
            "Epoch 2, D Loss: 2.6716, G Loss: 1.3054, AE Loss: 0.5349\n",
            "Epoch 2, D Loss: 0.5597, G Loss: 1.7540, AE Loss: 0.5463\n",
            "Epoch 2, D Loss: 1.0550, G Loss: 1.7303, AE Loss: 0.5618\n",
            "Epoch 2, D Loss: 1.1297, G Loss: 1.4484, AE Loss: 0.5769\n",
            "Epoch 2, D Loss: 1.4486, G Loss: 1.5595, AE Loss: 0.5978\n",
            "Epoch 2, D Loss: 2.4207, G Loss: 1.5778, AE Loss: 0.5871\n",
            "Epoch 2, D Loss: 1.0580, G Loss: 1.9482, AE Loss: 0.7105\n",
            "Epoch 2, D Loss: 1.1026, G Loss: 1.3557, AE Loss: 0.5949\n",
            "Epoch 2, D Loss: 0.4089, G Loss: 1.5032, AE Loss: 0.4415\n",
            "Epoch 2, D Loss: 1.7937, G Loss: 1.3957, AE Loss: 0.5863\n",
            "Epoch 2, D Loss: 2.3488, G Loss: 1.2911, AE Loss: 0.5556\n",
            "Epoch 2, D Loss: 1.5173, G Loss: 1.3266, AE Loss: 0.5584\n",
            "Epoch 2, D Loss: 1.2447, G Loss: 1.3042, AE Loss: 0.5499\n",
            "Epoch 2, D Loss: 1.0490, G Loss: 1.2976, AE Loss: 0.6808\n",
            "Epoch 2, D Loss: 1.3507, G Loss: 1.4781, AE Loss: 0.6159\n",
            "Epoch 2, D Loss: 0.6839, G Loss: 1.3003, AE Loss: 0.5346\n",
            "Epoch 2, D Loss: 1.6164, G Loss: 1.3044, AE Loss: 0.6433\n",
            "Epoch 2, D Loss: 1.0372, G Loss: 1.1691, AE Loss: 0.4158\n",
            "Epoch 2, D Loss: 1.0478, G Loss: 1.2033, AE Loss: 0.5693\n",
            "Epoch 2, D Loss: 1.0616, G Loss: 1.6048, AE Loss: 0.5479\n",
            "Epoch 2, D Loss: 0.5842, G Loss: 1.2065, AE Loss: 0.4900\n",
            "Epoch 2, D Loss: 1.0915, G Loss: 1.3902, AE Loss: 0.6418\n",
            "Epoch 2, D Loss: 1.9464, G Loss: 1.2530, AE Loss: 0.5585\n",
            "Epoch 2, D Loss: 1.0834, G Loss: 1.6589, AE Loss: 0.5880\n",
            "Epoch 2, D Loss: 0.8911, G Loss: 1.7001, AE Loss: 0.5425\n",
            "Epoch 2, D Loss: 0.8829, G Loss: 1.9147, AE Loss: 0.5279\n",
            "Epoch 2, D Loss: 0.5905, G Loss: 2.0657, AE Loss: 0.5142\n",
            "Epoch 2, D Loss: 1.1521, G Loss: 2.0513, AE Loss: 0.5373\n",
            "Epoch 2, D Loss: 0.3775, G Loss: 1.9468, AE Loss: 0.5225\n",
            "Epoch 2, D Loss: 1.3901, G Loss: 1.9118, AE Loss: 0.5694\n",
            "Epoch 2, D Loss: 0.8326, G Loss: 1.9277, AE Loss: 0.5610\n",
            "Epoch 2, D Loss: 0.8724, G Loss: 1.8663, AE Loss: 0.4905\n",
            "Epoch 2, D Loss: 0.9369, G Loss: 1.9070, AE Loss: 0.5477\n",
            "Epoch 2, D Loss: 1.8239, G Loss: 1.7088, AE Loss: 0.5463\n",
            "Epoch 2, D Loss: 1.3090, G Loss: 1.8425, AE Loss: 0.5125\n",
            "Epoch 2, D Loss: 0.4285, G Loss: 1.6720, AE Loss: 0.6472\n",
            "Epoch 2, D Loss: 0.9948, G Loss: 1.4265, AE Loss: 0.5425\n",
            "Epoch 2, D Loss: 1.3562, G Loss: 1.4833, AE Loss: 0.4791\n",
            "Epoch 2, D Loss: 0.7744, G Loss: 1.3543, AE Loss: 0.6111\n",
            "Epoch 2, D Loss: 0.5384, G Loss: 1.6413, AE Loss: 0.7071\n",
            "Epoch 2, D Loss: 2.6815, G Loss: 1.5831, AE Loss: 0.6825\n",
            "Epoch 2, D Loss: 1.6325, G Loss: 1.5676, AE Loss: 0.5040\n",
            "Epoch 2, D Loss: 1.2970, G Loss: 1.3658, AE Loss: 0.5547\n",
            "Epoch 2, D Loss: 1.5416, G Loss: 1.3672, AE Loss: 0.5666\n",
            "Epoch 2, D Loss: 0.7943, G Loss: 1.2542, AE Loss: 0.6838\n",
            "Epoch 2, D Loss: 0.9092, G Loss: 1.3239, AE Loss: 0.4972\n",
            "Epoch 2, D Loss: 2.2231, G Loss: 1.2963, AE Loss: 0.5313\n",
            "Epoch 2, D Loss: 0.8748, G Loss: 1.3043, AE Loss: 0.5679\n",
            "Epoch 2, D Loss: 1.7853, G Loss: 1.5719, AE Loss: 0.6670\n",
            "Epoch 2, D Loss: 0.3866, G Loss: 1.6094, AE Loss: 0.4908\n",
            "Epoch 2, D Loss: 0.7314, G Loss: 1.4709, AE Loss: 0.7642\n",
            "Epoch 2, D Loss: 0.6805, G Loss: 1.4584, AE Loss: 0.5358\n",
            "Epoch 2, D Loss: 0.7414, G Loss: 1.6330, AE Loss: 0.5300\n",
            "Epoch 2, D Loss: 1.7436, G Loss: 1.3496, AE Loss: 0.4050\n",
            "Epoch 2, D Loss: 1.0390, G Loss: 1.4935, AE Loss: 0.5175\n",
            "Epoch 2, D Loss: 1.4267, G Loss: 1.6150, AE Loss: 0.5260\n",
            "Epoch 2, D Loss: 1.4476, G Loss: 1.6148, AE Loss: 0.5688\n",
            "Epoch 2, D Loss: 1.5017, G Loss: 1.6576, AE Loss: 0.6679\n",
            "Epoch 2, D Loss: 1.4268, G Loss: 1.7893, AE Loss: 0.4521\n",
            "Epoch 2, D Loss: 0.3569, G Loss: 1.5159, AE Loss: 0.5697\n",
            "Epoch 2, D Loss: 0.3181, G Loss: 1.9168, AE Loss: 0.5616\n",
            "Epoch 2, D Loss: 1.8103, G Loss: 1.7550, AE Loss: 0.4700\n",
            "Epoch 2, D Loss: 0.7104, G Loss: 1.5057, AE Loss: 0.5831\n",
            "Epoch 2, D Loss: 0.7615, G Loss: 1.3223, AE Loss: 0.5522\n",
            "Epoch 2, D Loss: 1.6366, G Loss: 1.5262, AE Loss: 0.6078\n",
            "Epoch 2, D Loss: 0.7782, G Loss: 1.4396, AE Loss: 0.4424\n",
            "Epoch 2, D Loss: 1.3807, G Loss: 1.8556, AE Loss: 0.5487\n",
            "Epoch 2, D Loss: 0.8052, G Loss: 1.7155, AE Loss: 0.5801\n",
            "Epoch 2, D Loss: 1.3510, G Loss: 1.5091, AE Loss: 0.5118\n",
            "Epoch 2, D Loss: 2.0158, G Loss: 1.5507, AE Loss: 0.5908\n",
            "Epoch 2, D Loss: 1.3431, G Loss: 1.5297, AE Loss: 0.5971\n",
            "Epoch 2, D Loss: 1.3098, G Loss: 1.5718, AE Loss: 0.4663\n",
            "Epoch 2, D Loss: 0.7097, G Loss: 1.4432, AE Loss: 0.6066\n",
            "Epoch 2, D Loss: 0.8468, G Loss: 1.5958, AE Loss: 0.5276\n",
            "Epoch 2, D Loss: 0.9402, G Loss: 1.5628, AE Loss: 0.6907\n",
            "Epoch 2, D Loss: 0.8326, G Loss: 1.5814, AE Loss: 0.5818\n",
            "Epoch 2, D Loss: 1.0241, G Loss: 1.6652, AE Loss: 0.4942\n",
            "Epoch 2, D Loss: 0.5116, G Loss: 1.7193, AE Loss: 0.5333\n",
            "Epoch 2, D Loss: 1.2997, G Loss: 1.5420, AE Loss: 0.5466\n",
            "Epoch 2, D Loss: 1.4264, G Loss: 1.6228, AE Loss: 0.5479\n",
            "Epoch 2, D Loss: 1.0516, G Loss: 1.5071, AE Loss: 0.5816\n",
            "Epoch 2, D Loss: 1.2647, G Loss: 1.5791, AE Loss: 0.6142\n",
            "Epoch 2, D Loss: 2.0749, G Loss: 1.6715, AE Loss: 0.4797\n",
            "Epoch 2, D Loss: 0.7855, G Loss: 1.5138, AE Loss: 0.6101\n",
            "Epoch 2, D Loss: 0.9157, G Loss: 1.8376, AE Loss: 0.4864\n",
            "Epoch 2, D Loss: 0.8707, G Loss: 1.7310, AE Loss: 0.4868\n",
            "Epoch 2, D Loss: 0.6423, G Loss: 1.7129, AE Loss: 0.4994\n",
            "Epoch 2, D Loss: 1.0031, G Loss: 1.5394, AE Loss: 0.5346\n",
            "Epoch 2, D Loss: 0.7768, G Loss: 1.6926, AE Loss: 0.5135\n",
            "Epoch 2, D Loss: 0.9976, G Loss: 1.5549, AE Loss: 0.3721\n",
            "Epoch 2, D Loss: 0.8801, G Loss: 1.7862, AE Loss: 0.4485\n",
            "Epoch 2, D Loss: 0.9436, G Loss: 1.5075, AE Loss: 0.5389\n",
            "Epoch 2, D Loss: 0.5899, G Loss: 1.8678, AE Loss: 0.5116\n",
            "Epoch 2, D Loss: 1.4373, G Loss: 1.6911, AE Loss: 0.4813\n",
            "Epoch 2, D Loss: 1.1043, G Loss: 1.8264, AE Loss: 0.4216\n",
            "Epoch 2, D Loss: 0.7988, G Loss: 1.6794, AE Loss: 0.6463\n",
            "Epoch 2, D Loss: 0.4509, G Loss: 1.5927, AE Loss: 0.6364\n",
            "Epoch 2, D Loss: 0.6363, G Loss: 1.5723, AE Loss: 0.5615\n",
            "Epoch 2, D Loss: 1.0561, G Loss: 1.4902, AE Loss: 0.5694\n",
            "Epoch 2, D Loss: 1.1334, G Loss: 1.6407, AE Loss: 0.5302\n",
            "Epoch 2, D Loss: 1.2837, G Loss: 1.6873, AE Loss: 0.5778\n",
            "Epoch 2, D Loss: 0.2925, G Loss: 1.7958, AE Loss: 0.4132\n",
            "Epoch 2, D Loss: 0.6115, G Loss: 1.8468, AE Loss: 0.5618\n",
            "Epoch 2, D Loss: 1.2022, G Loss: 1.6455, AE Loss: 0.5080\n",
            "Epoch 2, D Loss: 0.6022, G Loss: 1.8377, AE Loss: 0.4725\n",
            "Epoch 2, D Loss: 0.6562, G Loss: 1.7441, AE Loss: 0.5844\n",
            "Epoch 2, D Loss: 0.6472, G Loss: 1.7492, AE Loss: 0.6403\n",
            "Epoch 2, D Loss: 0.4823, G Loss: 1.7732, AE Loss: 0.4716\n",
            "Epoch 2, D Loss: 0.8604, G Loss: 1.8328, AE Loss: 0.7004\n",
            "Epoch 2, D Loss: 0.4989, G Loss: 1.8992, AE Loss: 0.6912\n",
            "Epoch 2, D Loss: 0.2538, G Loss: 1.8440, AE Loss: 0.5717\n",
            "Epoch 2, D Loss: 0.6140, G Loss: 1.9081, AE Loss: 0.5073\n",
            "Epoch 2, D Loss: 1.8862, G Loss: 1.8297, AE Loss: 0.4636\n",
            "Epoch 2, D Loss: 0.5384, G Loss: 1.8180, AE Loss: 0.5500\n",
            "Epoch 2, D Loss: 0.7534, G Loss: 1.8887, AE Loss: 0.5041\n",
            "Epoch 2, D Loss: 0.2385, G Loss: 1.9740, AE Loss: 0.4698\n",
            "Epoch 2, D Loss: 0.9176, G Loss: 1.9000, AE Loss: 0.5158\n",
            "Epoch 2, D Loss: 0.5253, G Loss: 1.8913, AE Loss: 0.6118\n",
            "Epoch 2, D Loss: 1.1646, G Loss: 1.9245, AE Loss: 0.5740\n",
            "Epoch 2, D Loss: 0.8297, G Loss: 1.9067, AE Loss: 0.3713\n",
            "Epoch 2, D Loss: 0.3698, G Loss: 1.9219, AE Loss: 0.5843\n",
            "Epoch 2, D Loss: 0.7621, G Loss: 1.8497, AE Loss: 0.5605\n",
            "Epoch 2, D Loss: 1.0951, G Loss: 1.8692, AE Loss: 0.5174\n",
            "Epoch 2, D Loss: 0.7202, G Loss: 1.8732, AE Loss: 0.4743\n",
            "Epoch 2, D Loss: 0.4983, G Loss: 1.8635, AE Loss: 0.5034\n",
            "Epoch 2, D Loss: 0.5503, G Loss: 1.8945, AE Loss: 0.5470\n",
            "Epoch 2, D Loss: 0.3299, G Loss: 1.8500, AE Loss: 0.6313\n",
            "Epoch 2, D Loss: 0.9141, G Loss: 1.8121, AE Loss: 0.5187\n",
            "Epoch 2, D Loss: 0.7715, G Loss: 1.7737, AE Loss: 0.6098\n",
            "Epoch 2, D Loss: 0.6205, G Loss: 1.9147, AE Loss: 0.5732\n",
            "Epoch 2, D Loss: 0.3969, G Loss: 1.8610, AE Loss: 0.5882\n",
            "Epoch 2, D Loss: 0.8515, G Loss: 1.7196, AE Loss: 0.4601\n",
            "Epoch 2, D Loss: 0.4331, G Loss: 1.8284, AE Loss: 0.5175\n",
            "Epoch 2, D Loss: 0.3975, G Loss: 1.8631, AE Loss: 0.5617\n",
            "Epoch 2, D Loss: 1.3951, G Loss: 1.8094, AE Loss: 0.5736\n",
            "Epoch 2, D Loss: 0.2296, G Loss: 1.8875, AE Loss: 0.5068\n",
            "Epoch 2, D Loss: 0.3590, G Loss: 1.9739, AE Loss: 0.5759\n",
            "Epoch 2, D Loss: 0.5515, G Loss: 2.0883, AE Loss: 0.4806\n",
            "Epoch 2, D Loss: 0.3273, G Loss: 1.9318, AE Loss: 0.4645\n",
            "Epoch 2, D Loss: 0.3713, G Loss: 1.9372, AE Loss: 0.4286\n",
            "Epoch 2, D Loss: 0.4084, G Loss: 1.9172, AE Loss: 0.4869\n",
            "Epoch 2, D Loss: 0.9703, G Loss: 1.8246, AE Loss: 0.5431\n",
            "Epoch 2, D Loss: 0.6278, G Loss: 1.8897, AE Loss: 0.6427\n",
            "Epoch 2, D Loss: 0.5383, G Loss: 1.7480, AE Loss: 0.5372\n",
            "Epoch 2, D Loss: 0.4960, G Loss: 1.7551, AE Loss: 0.5569\n",
            "Epoch 2, D Loss: 0.3270, G Loss: 2.0147, AE Loss: 0.4960\n",
            "Epoch 2, D Loss: 0.7105, G Loss: 1.7877, AE Loss: 0.5977\n",
            "Epoch 2, D Loss: 1.4739, G Loss: 1.9567, AE Loss: 0.5496\n",
            "Epoch 2, D Loss: 0.4088, G Loss: 1.8945, AE Loss: 0.5165\n",
            "Epoch 2, D Loss: 0.6844, G Loss: 1.8950, AE Loss: 0.6354\n",
            "Epoch 2, D Loss: 0.7491, G Loss: 1.8767, AE Loss: 0.4882\n",
            "Epoch 2, D Loss: 0.5976, G Loss: 1.8612, AE Loss: 0.5023\n",
            "Epoch 2, D Loss: 0.5743, G Loss: 1.7615, AE Loss: 0.4934\n",
            "Epoch 2, D Loss: 0.2379, G Loss: 1.8577, AE Loss: 0.5178\n",
            "Epoch 2, D Loss: 0.1973, G Loss: 2.0441, AE Loss: 0.6362\n",
            "Epoch 2, D Loss: 0.4757, G Loss: 1.7507, AE Loss: 0.5406\n",
            "Epoch 2, D Loss: 0.3499, G Loss: 1.8488, AE Loss: 0.7072\n",
            "Epoch 2, D Loss: 0.4080, G Loss: 1.7320, AE Loss: 0.5490\n",
            "Epoch 2, D Loss: 0.5178, G Loss: 1.7221, AE Loss: 0.5755\n",
            "Epoch 2, D Loss: 0.2801, G Loss: 1.8478, AE Loss: 0.4923\n",
            "Epoch 2, D Loss: 0.6562, G Loss: 1.8254, AE Loss: 0.6099\n",
            "Epoch 2, D Loss: 0.2222, G Loss: 1.8725, AE Loss: 0.5201\n",
            "Epoch 2, D Loss: 0.3636, G Loss: 1.5708, AE Loss: 0.4293\n",
            "Epoch 2, D Loss: 1.0659, G Loss: 1.6139, AE Loss: 0.5467\n",
            "Epoch 2, D Loss: 0.9019, G Loss: 1.7213, AE Loss: 0.5807\n",
            "Epoch 2, D Loss: 0.2193, G Loss: 1.8035, AE Loss: 0.5700\n",
            "Epoch 2, D Loss: 1.1721, G Loss: 1.6727, AE Loss: 0.5881\n",
            "Epoch 2, D Loss: 0.3741, G Loss: 1.5383, AE Loss: 0.5433\n",
            "Epoch 2, D Loss: 1.1128, G Loss: 1.6550, AE Loss: 0.5338\n",
            "Epoch 2, D Loss: 0.3710, G Loss: 1.5318, AE Loss: 0.5827\n",
            "Epoch 2, D Loss: 0.3795, G Loss: 1.3281, AE Loss: 0.5210\n",
            "Epoch 2, D Loss: 0.4174, G Loss: 1.2346, AE Loss: 0.5732\n",
            "Epoch 2, D Loss: 0.6145, G Loss: 1.2563, AE Loss: 0.6413\n",
            "Epoch 2, D Loss: 0.8558, G Loss: 1.3470, AE Loss: 0.5285\n",
            "Epoch 2, D Loss: 1.0704, G Loss: 1.4986, AE Loss: 0.5558\n",
            "Epoch 2, D Loss: 0.3650, G Loss: 1.4636, AE Loss: 0.5947\n",
            "Epoch 2, D Loss: 0.8587, G Loss: 1.3564, AE Loss: 0.4950\n",
            "Epoch 2, D Loss: 1.0101, G Loss: 1.2813, AE Loss: 0.4908\n",
            "Epoch 2, D Loss: 0.6173, G Loss: 1.2375, AE Loss: 0.5479\n",
            "Epoch 2, D Loss: 0.8840, G Loss: 1.3704, AE Loss: 0.6087\n",
            "Epoch 2, D Loss: 0.9677, G Loss: 1.1386, AE Loss: 0.5210\n",
            "Epoch 2, D Loss: 0.7918, G Loss: 1.5993, AE Loss: 0.6152\n",
            "Epoch 2, D Loss: 1.0666, G Loss: 1.3925, AE Loss: 0.4282\n",
            "Epoch 2, D Loss: 1.4028, G Loss: 1.6670, AE Loss: 0.5823\n",
            "Epoch 2, D Loss: 0.8322, G Loss: 1.4106, AE Loss: 0.5913\n",
            "Epoch 2, D Loss: 0.7826, G Loss: 1.2558, AE Loss: 0.5044\n",
            "Epoch 2, D Loss: 0.6862, G Loss: 1.4236, AE Loss: 0.5187\n",
            "Epoch 2, D Loss: 0.7665, G Loss: 1.2363, AE Loss: 0.4887\n",
            "Epoch 2, D Loss: 0.4763, G Loss: 1.4291, AE Loss: 0.5682\n",
            "Epoch 2, D Loss: 0.5188, G Loss: 1.3821, AE Loss: 0.4768\n",
            "Epoch 2, D Loss: 0.6866, G Loss: 1.5569, AE Loss: 0.5182\n",
            "Epoch 2, D Loss: 0.6603, G Loss: 1.5080, AE Loss: 0.4490\n",
            "Epoch 2, D Loss: 0.3326, G Loss: 1.6084, AE Loss: 0.5496\n",
            "Epoch 2, D Loss: 0.9975, G Loss: 1.5901, AE Loss: 0.5040\n",
            "Epoch 2, D Loss: 0.3656, G Loss: 1.8823, AE Loss: 0.5027\n",
            "Epoch 2, D Loss: 0.5788, G Loss: 1.5809, AE Loss: 0.4246\n",
            "Epoch 2, D Loss: 0.9200, G Loss: 1.6365, AE Loss: 0.6229\n",
            "Epoch 2, D Loss: 0.4200, G Loss: 1.6529, AE Loss: 0.5442\n",
            "Epoch 2, D Loss: 0.4722, G Loss: 1.6691, AE Loss: 0.7400\n",
            "Epoch 2, D Loss: 0.7565, G Loss: 1.6599, AE Loss: 0.6015\n",
            "Epoch 2, D Loss: 0.8861, G Loss: 1.6766, AE Loss: 0.6284\n",
            "Epoch 2, D Loss: 0.4579, G Loss: 1.6737, AE Loss: 0.4272\n",
            "Epoch 2, D Loss: 1.0114, G Loss: 1.7145, AE Loss: 0.4969\n",
            "Epoch 2, D Loss: 0.3059, G Loss: 1.7308, AE Loss: 0.6327\n",
            "Epoch 2, D Loss: 0.7658, G Loss: 1.9157, AE Loss: 0.5193\n",
            "Epoch 2, D Loss: 0.7895, G Loss: 1.8361, AE Loss: 0.6861\n",
            "Epoch 2, D Loss: 0.9105, G Loss: 1.7740, AE Loss: 0.5321\n",
            "Epoch 2, D Loss: 0.3955, G Loss: 1.8199, AE Loss: 0.5989\n",
            "Epoch 2, D Loss: 0.5726, G Loss: 1.7224, AE Loss: 0.5947\n",
            "Epoch 2, D Loss: 0.6052, G Loss: 1.7457, AE Loss: 0.6091\n",
            "Epoch 2, D Loss: 0.7371, G Loss: 1.7887, AE Loss: 0.6274\n",
            "Epoch 2, D Loss: 0.2695, G Loss: 1.9356, AE Loss: 0.6532\n",
            "Epoch 2, D Loss: 0.3056, G Loss: 1.7646, AE Loss: 0.4842\n",
            "Epoch 2, D Loss: 0.9190, G Loss: 1.8127, AE Loss: 0.5157\n",
            "Epoch 2, D Loss: 0.8058, G Loss: 1.8106, AE Loss: 0.5465\n",
            "Epoch 2, D Loss: 0.3689, G Loss: 1.8634, AE Loss: 0.5567\n",
            "Epoch 2, D Loss: 0.3325, G Loss: 1.8999, AE Loss: 0.5407\n",
            "Epoch 2, D Loss: 0.4240, G Loss: 1.9303, AE Loss: 0.5087\n",
            "Epoch 2, D Loss: 0.7515, G Loss: 2.0719, AE Loss: 0.4709\n",
            "Epoch 2, D Loss: 0.4754, G Loss: 2.1549, AE Loss: 0.5712\n",
            "Epoch 2, D Loss: 0.4714, G Loss: 2.0269, AE Loss: 0.4919\n",
            "Epoch 2, D Loss: 0.5299, G Loss: 2.2487, AE Loss: 0.7291\n",
            "Epoch 2, D Loss: 0.5525, G Loss: 1.9053, AE Loss: 0.5653\n",
            "Epoch 2, D Loss: 0.2402, G Loss: 2.1529, AE Loss: 0.5679\n",
            "Epoch 2, D Loss: 0.3038, G Loss: 1.8289, AE Loss: 0.5843\n",
            "Epoch 2, D Loss: 0.5330, G Loss: 1.9001, AE Loss: 0.4579\n",
            "Epoch 2, D Loss: 0.2561, G Loss: 2.1342, AE Loss: 0.4430\n",
            "Epoch 2, D Loss: 0.4171, G Loss: 1.8795, AE Loss: 0.5148\n",
            "Epoch 2, D Loss: 0.9010, G Loss: 2.1118, AE Loss: 0.5955\n",
            "Epoch 2, D Loss: 0.5749, G Loss: 2.1430, AE Loss: 0.4641\n",
            "Epoch 2, D Loss: 0.3432, G Loss: 1.9661, AE Loss: 0.5909\n",
            "Epoch 2, D Loss: 0.3766, G Loss: 2.1440, AE Loss: 0.6139\n",
            "Epoch 2, D Loss: 0.6223, G Loss: 1.9411, AE Loss: 0.6547\n",
            "Epoch 2, D Loss: 0.7697, G Loss: 1.8176, AE Loss: 0.4936\n",
            "Epoch 2, D Loss: 0.7871, G Loss: 2.1299, AE Loss: 0.6678\n",
            "Epoch 2, D Loss: 0.5316, G Loss: 1.8889, AE Loss: 0.5886\n",
            "Epoch 2, D Loss: 0.5811, G Loss: 2.2197, AE Loss: 0.5166\n",
            "Epoch 2, D Loss: 0.3677, G Loss: 2.2650, AE Loss: 0.5684\n",
            "Epoch 2, D Loss: 0.4874, G Loss: 2.1709, AE Loss: 0.6081\n",
            "Epoch 2, D Loss: 0.7141, G Loss: 2.2083, AE Loss: 0.5296\n",
            "Epoch 2, D Loss: 0.4879, G Loss: 2.1569, AE Loss: 0.4471\n",
            "Epoch 2, D Loss: 0.5218, G Loss: 2.2736, AE Loss: 0.5472\n",
            "Epoch 2, D Loss: 0.7919, G Loss: 2.2167, AE Loss: 0.6079\n",
            "Epoch 2, D Loss: 1.0283, G Loss: 2.2934, AE Loss: 0.4494\n",
            "Epoch 2, D Loss: 0.1810, G Loss: 2.2755, AE Loss: 0.5855\n",
            "Epoch 2, D Loss: 0.9110, G Loss: 2.1705, AE Loss: 0.5941\n",
            "Epoch 2, D Loss: 0.2946, G Loss: 2.2949, AE Loss: 0.5323\n",
            "Epoch 2, D Loss: 0.3153, G Loss: 2.5921, AE Loss: 0.6247\n",
            "Epoch 2, D Loss: 0.6137, G Loss: 2.4897, AE Loss: 0.5840\n",
            "Epoch 2, D Loss: 0.4455, G Loss: 2.2732, AE Loss: 0.5641\n",
            "Epoch 2, D Loss: 0.3640, G Loss: 2.2401, AE Loss: 0.7031\n",
            "Epoch 2, D Loss: 0.3244, G Loss: 2.3797, AE Loss: 0.5055\n",
            "Epoch 2, D Loss: 0.4845, G Loss: 2.1617, AE Loss: 0.5362\n",
            "Epoch 2, D Loss: 0.1532, G Loss: 2.6241, AE Loss: 0.5336\n",
            "Epoch 2, D Loss: 0.2408, G Loss: 2.3718, AE Loss: 0.5496\n",
            "Epoch 2, D Loss: 0.7144, G Loss: 2.4012, AE Loss: 0.5386\n",
            "Epoch 2, D Loss: 0.2257, G Loss: 2.4493, AE Loss: 0.5181\n",
            "Epoch 2, D Loss: 0.5375, G Loss: 2.5617, AE Loss: 0.6067\n",
            "Epoch 2, D Loss: 0.3567, G Loss: 2.3542, AE Loss: 0.5652\n",
            "Epoch 2, D Loss: 0.6631, G Loss: 2.5452, AE Loss: 0.5801\n",
            "Epoch 2, D Loss: 0.2827, G Loss: 2.6381, AE Loss: 0.6068\n",
            "Epoch 2, D Loss: 0.4898, G Loss: 2.4279, AE Loss: 0.6045\n",
            "Epoch 2, D Loss: 0.2331, G Loss: 2.4103, AE Loss: 0.5544\n",
            "Epoch 2, D Loss: 0.3175, G Loss: 2.4653, AE Loss: 0.6486\n",
            "Epoch 2, D Loss: 0.4675, G Loss: 2.3795, AE Loss: 0.4105\n",
            "Epoch 2, D Loss: 0.8991, G Loss: 2.4071, AE Loss: 0.5436\n",
            "Epoch 2, D Loss: 0.5927, G Loss: 2.2034, AE Loss: 0.6088\n",
            "Epoch 2, D Loss: 0.4736, G Loss: 2.3944, AE Loss: 0.5469\n",
            "Epoch 2, D Loss: 0.2269, G Loss: 2.5748, AE Loss: 0.6028\n",
            "Epoch 2, D Loss: 0.7789, G Loss: 2.2902, AE Loss: 0.6104\n",
            "Epoch 2, D Loss: 0.2963, G Loss: 2.5747, AE Loss: 0.5102\n",
            "Epoch 2, D Loss: 0.3231, G Loss: 2.2889, AE Loss: 0.5403\n",
            "Epoch 2, D Loss: 0.2603, G Loss: 2.2125, AE Loss: 0.4162\n",
            "Epoch 2, D Loss: 0.4151, G Loss: 2.2782, AE Loss: 0.5322\n",
            "Epoch 2, D Loss: 0.3252, G Loss: 2.5677, AE Loss: 0.4743\n",
            "Epoch 2, D Loss: 0.5688, G Loss: 2.1940, AE Loss: 0.5163\n",
            "Epoch 2, D Loss: 0.1851, G Loss: 2.5848, AE Loss: 0.6725\n",
            "Epoch 2, D Loss: 0.4671, G Loss: 2.2727, AE Loss: 0.5512\n",
            "Epoch 2, D Loss: 0.7623, G Loss: 2.5755, AE Loss: 0.5258\n",
            "Epoch 2, D Loss: 0.4842, G Loss: 2.3637, AE Loss: 0.5100\n",
            "Epoch 2, D Loss: 0.2415, G Loss: 2.3850, AE Loss: 0.5270\n",
            "Epoch 2, D Loss: 0.5770, G Loss: 2.6271, AE Loss: 0.5433\n",
            "Epoch 2, D Loss: 0.3688, G Loss: 2.5257, AE Loss: 0.4739\n",
            "Epoch 2, D Loss: 0.8571, G Loss: 2.3666, AE Loss: 0.5229\n",
            "Epoch 2, D Loss: 0.3270, G Loss: 2.4754, AE Loss: 0.5428\n",
            "Epoch 2, D Loss: 0.6132, G Loss: 2.1564, AE Loss: 0.6024\n",
            "Epoch 2, D Loss: 0.3863, G Loss: 2.1766, AE Loss: 0.5702\n",
            "Epoch 2, D Loss: 0.7374, G Loss: 2.2540, AE Loss: 0.5049\n",
            "Epoch 2, D Loss: 0.6282, G Loss: 2.2013, AE Loss: 0.5767\n",
            "Epoch 2, D Loss: 0.3883, G Loss: 2.0930, AE Loss: 0.5644\n",
            "Epoch 2, D Loss: 0.6206, G Loss: 2.0961, AE Loss: 0.5457\n",
            "Epoch 2, D Loss: 0.2949, G Loss: 2.0704, AE Loss: 0.6976\n",
            "Epoch 2, D Loss: 0.5153, G Loss: 2.2926, AE Loss: 0.5403\n",
            "Epoch 2, D Loss: 0.5888, G Loss: 2.3189, AE Loss: 0.5919\n",
            "Epoch 2, D Loss: 0.7930, G Loss: 2.3646, AE Loss: 0.6775\n",
            "Epoch 2, D Loss: 0.6947, G Loss: 2.4449, AE Loss: 0.6691\n",
            "Epoch 2, D Loss: 0.2470, G Loss: 2.1784, AE Loss: 0.6589\n",
            "Epoch 2, D Loss: 0.4133, G Loss: 2.2703, AE Loss: 0.5315\n",
            "Epoch 2, D Loss: 0.2394, G Loss: 2.1776, AE Loss: 0.6704\n",
            "Epoch 2, D Loss: 0.2313, G Loss: 2.4236, AE Loss: 0.5099\n",
            "Epoch 2, D Loss: 0.1953, G Loss: 2.2767, AE Loss: 0.6038\n",
            "Epoch 2, D Loss: 0.2482, G Loss: 2.1542, AE Loss: 0.4697\n",
            "Epoch 2, D Loss: 0.3435, G Loss: 2.0413, AE Loss: 0.4386\n",
            "Epoch 2, D Loss: 0.6883, G Loss: 2.1234, AE Loss: 0.4982\n",
            "Epoch 2, D Loss: 0.7601, G Loss: 2.1717, AE Loss: 0.5039\n",
            "Epoch 2, D Loss: 0.4878, G Loss: 2.1556, AE Loss: 0.5234\n",
            "Epoch 2, D Loss: 0.2870, G Loss: 2.1885, AE Loss: 0.4767\n",
            "Epoch 2, D Loss: 0.2950, G Loss: 2.3495, AE Loss: 0.5415\n",
            "Epoch 2, D Loss: 1.0418, G Loss: 1.9029, AE Loss: 0.6304\n",
            "Epoch 2, D Loss: 0.9469, G Loss: 2.1669, AE Loss: 0.7612\n",
            "Epoch 2, D Loss: 1.0351, G Loss: 2.1411, AE Loss: 0.4778\n",
            "Epoch 2, D Loss: 0.4159, G Loss: 1.9579, AE Loss: 0.4532\n",
            "Epoch 2, D Loss: 0.7959, G Loss: 2.1756, AE Loss: 0.4912\n",
            "Epoch 2, D Loss: 0.3507, G Loss: 1.9199, AE Loss: 0.5017\n",
            "Epoch 2, D Loss: 0.2466, G Loss: 2.1033, AE Loss: 0.6259\n",
            "Epoch 2, D Loss: 1.0522, G Loss: 2.0494, AE Loss: 0.5417\n",
            "Epoch 2, D Loss: 1.1417, G Loss: 2.0362, AE Loss: 0.6341\n",
            "Epoch 2, D Loss: 0.2946, G Loss: 1.8418, AE Loss: 0.4999\n",
            "Epoch 2, D Loss: 0.3797, G Loss: 2.1169, AE Loss: 0.5666\n",
            "Epoch 2, D Loss: 0.6641, G Loss: 2.1664, AE Loss: 0.5519\n",
            "Epoch 2, D Loss: 0.2569, G Loss: 1.9854, AE Loss: 0.5751\n",
            "Epoch 2, D Loss: 1.1792, G Loss: 1.9055, AE Loss: 0.4359\n",
            "Epoch 2, D Loss: 0.3211, G Loss: 2.0298, AE Loss: 0.6126\n",
            "Epoch 2, D Loss: 0.2905, G Loss: 1.7679, AE Loss: 0.6645\n",
            "Epoch 2, D Loss: 0.4187, G Loss: 2.1380, AE Loss: 0.4387\n",
            "Epoch 2, D Loss: 0.7801, G Loss: 1.9424, AE Loss: 0.5911\n",
            "Epoch 2, D Loss: 0.3791, G Loss: 1.9909, AE Loss: 0.5701\n",
            "Epoch 2, D Loss: 1.9714, G Loss: 1.9461, AE Loss: 0.4468\n",
            "Epoch 2, D Loss: 0.4462, G Loss: 2.0528, AE Loss: 0.5739\n",
            "Epoch 2, D Loss: 0.3233, G Loss: 1.9587, AE Loss: 0.8108\n",
            "Epoch 2, D Loss: 0.2645, G Loss: 2.0829, AE Loss: 0.5998\n",
            "Epoch 2, D Loss: 1.1095, G Loss: 1.9100, AE Loss: 0.5241\n",
            "Epoch 2, D Loss: 0.3255, G Loss: 1.9306, AE Loss: 0.5768\n",
            "Epoch 2, D Loss: 0.2773, G Loss: 2.0525, AE Loss: 0.6036\n",
            "Epoch 2, D Loss: 0.9130, G Loss: 2.1971, AE Loss: 0.5846\n",
            "Epoch 2, D Loss: 0.3410, G Loss: 2.3040, AE Loss: 0.5411\n",
            "Epoch 2, D Loss: 0.4953, G Loss: 2.0496, AE Loss: 0.4957\n",
            "Epoch 2, D Loss: 0.5163, G Loss: 1.9968, AE Loss: 0.6859\n",
            "Epoch 2, D Loss: 1.0562, G Loss: 2.1385, AE Loss: 0.7860\n",
            "Epoch 2, D Loss: 0.7355, G Loss: 2.0671, AE Loss: 0.5330\n",
            "Epoch 2, D Loss: 0.5767, G Loss: 1.9455, AE Loss: 0.5998\n",
            "Epoch 2, D Loss: 0.9896, G Loss: 2.0746, AE Loss: 0.5607\n",
            "Epoch 2, D Loss: 0.3450, G Loss: 1.8603, AE Loss: 0.5207\n",
            "Epoch 2, D Loss: 0.5556, G Loss: 1.7611, AE Loss: 0.6013\n",
            "Epoch 2, D Loss: 0.8387, G Loss: 1.7253, AE Loss: 0.5754\n",
            "Epoch 2, D Loss: 1.9070, G Loss: 1.9027, AE Loss: 0.4889\n",
            "Epoch 2, D Loss: 0.3039, G Loss: 1.8505, AE Loss: 0.5568\n",
            "Epoch 2, D Loss: 1.0182, G Loss: 1.7439, AE Loss: 0.7341\n",
            "Epoch 2, D Loss: 0.2934, G Loss: 1.8369, AE Loss: 0.6184\n",
            "Epoch 2, D Loss: 0.3010, G Loss: 1.8233, AE Loss: 0.5110\n",
            "Epoch 2, D Loss: 0.3632, G Loss: 1.8759, AE Loss: 0.7297\n",
            "Epoch 2, D Loss: 0.4971, G Loss: 1.9296, AE Loss: 0.5200\n",
            "Epoch 2, D Loss: 0.7845, G Loss: 2.0215, AE Loss: 0.5461\n",
            "Epoch 2, D Loss: 0.5985, G Loss: 1.9938, AE Loss: 0.6240\n",
            "Epoch 2, D Loss: 0.3425, G Loss: 1.8571, AE Loss: 0.4662\n",
            "Epoch 2, D Loss: 0.8731, G Loss: 1.9613, AE Loss: 0.4758\n",
            "Epoch 2, D Loss: 1.6291, G Loss: 1.6693, AE Loss: 0.5314\n",
            "Epoch 2, D Loss: 0.4044, G Loss: 2.1204, AE Loss: 0.5968\n",
            "Epoch 2, D Loss: 0.6186, G Loss: 2.0364, AE Loss: 0.5776\n",
            "Epoch 2, D Loss: 0.3945, G Loss: 1.9106, AE Loss: 0.4706\n",
            "Epoch 2, D Loss: 1.5233, G Loss: 2.0746, AE Loss: 0.5072\n",
            "Epoch 2, D Loss: 0.3587, G Loss: 1.9584, AE Loss: 0.6675\n",
            "Epoch 2, D Loss: 1.4044, G Loss: 2.0010, AE Loss: 0.4223\n",
            "Epoch 2, D Loss: 1.0724, G Loss: 1.7733, AE Loss: 0.4464\n",
            "Epoch 2, D Loss: 0.2284, G Loss: 2.0259, AE Loss: 0.4746\n",
            "Epoch 2, D Loss: 0.6164, G Loss: 1.7793, AE Loss: 0.6921\n",
            "Epoch 2, D Loss: 1.2833, G Loss: 1.8191, AE Loss: 0.6290\n",
            "Epoch 2, D Loss: 0.4142, G Loss: 2.0757, AE Loss: 0.5626\n",
            "Epoch 2, D Loss: 0.6276, G Loss: 1.9627, AE Loss: 0.7655\n",
            "Epoch 2, D Loss: 0.6423, G Loss: 1.9661, AE Loss: 0.5227\n",
            "Epoch 2, D Loss: 1.0117, G Loss: 2.0589, AE Loss: 0.5378\n",
            "Epoch 2, D Loss: 1.5539, G Loss: 2.1213, AE Loss: 0.5614\n",
            "Epoch 2, D Loss: 1.6876, G Loss: 1.9761, AE Loss: 0.5855\n",
            "Epoch 2, D Loss: 0.4863, G Loss: 1.8034, AE Loss: 0.4686\n",
            "Epoch 2, D Loss: 0.6736, G Loss: 1.8523, AE Loss: 0.6462\n",
            "Epoch 2, D Loss: 0.8188, G Loss: 2.1019, AE Loss: 0.5331\n",
            "Epoch 2, D Loss: 1.0722, G Loss: 2.2290, AE Loss: 0.5384\n",
            "Epoch 2, D Loss: 0.7680, G Loss: 2.0138, AE Loss: 0.5692\n",
            "Epoch 2, D Loss: 1.6532, G Loss: 2.0816, AE Loss: 0.5560\n",
            "Epoch 2, D Loss: 1.0372, G Loss: 1.8732, AE Loss: 0.4941\n",
            "Epoch 2, D Loss: 1.1529, G Loss: 2.1302, AE Loss: 0.5789\n",
            "Epoch 2, D Loss: 1.0201, G Loss: 1.9775, AE Loss: 0.5315\n",
            "Epoch 2, D Loss: 1.0100, G Loss: 2.0797, AE Loss: 0.5059\n",
            "Epoch 2, D Loss: 0.5746, G Loss: 1.8200, AE Loss: 0.4693\n",
            "Epoch 2, D Loss: 0.6663, G Loss: 1.8876, AE Loss: 0.6023\n",
            "Epoch 2, D Loss: 1.3329, G Loss: 1.9031, AE Loss: 0.5291\n",
            "Epoch 2, D Loss: 0.7863, G Loss: 1.9559, AE Loss: 0.5805\n",
            "Epoch 2, D Loss: 0.3762, G Loss: 1.8174, AE Loss: 0.7554\n",
            "Epoch 2, D Loss: 0.5893, G Loss: 1.9326, AE Loss: 0.5549\n",
            "Epoch 2, D Loss: 1.0701, G Loss: 1.7894, AE Loss: 0.6743\n",
            "Epoch 2, D Loss: 0.4783, G Loss: 1.9789, AE Loss: 0.6516\n",
            "Epoch 2, D Loss: 0.4014, G Loss: 1.9326, AE Loss: 0.6124\n",
            "Epoch 2, D Loss: 0.3992, G Loss: 1.9538, AE Loss: 0.4944\n",
            "Epoch 2, D Loss: 0.6188, G Loss: 2.1135, AE Loss: 0.4808\n",
            "Epoch 2, D Loss: 1.1160, G Loss: 2.4066, AE Loss: 0.5944\n",
            "Epoch 2, D Loss: 0.2868, G Loss: 2.3039, AE Loss: 0.5739\n",
            "Epoch 2, D Loss: 1.1723, G Loss: 2.6192, AE Loss: 0.5884\n",
            "Epoch 2, D Loss: 0.4003, G Loss: 2.5585, AE Loss: 0.5377\n",
            "Epoch 2, D Loss: 0.6074, G Loss: 2.3533, AE Loss: 0.5878\n",
            "Epoch 2, D Loss: 0.3058, G Loss: 2.4876, AE Loss: 0.4649\n",
            "Epoch 2, D Loss: 0.2036, G Loss: 2.4518, AE Loss: 0.5624\n",
            "Epoch 2, D Loss: 1.0436, G Loss: 2.4791, AE Loss: 0.5123\n",
            "Epoch 2, D Loss: 0.2317, G Loss: 2.7200, AE Loss: 0.6366\n",
            "Epoch 2, D Loss: 0.4794, G Loss: 2.3841, AE Loss: 0.5350\n",
            "Epoch 2, D Loss: 0.4227, G Loss: 2.2256, AE Loss: 0.6657\n",
            "Epoch 2, D Loss: 0.7018, G Loss: 2.8511, AE Loss: 0.6886\n",
            "Epoch 2, D Loss: 0.3002, G Loss: 2.4506, AE Loss: 0.4249\n",
            "Epoch 2, D Loss: 0.3202, G Loss: 2.2925, AE Loss: 0.5871\n",
            "Epoch 2, D Loss: 0.5109, G Loss: 2.1220, AE Loss: 0.6165\n",
            "Epoch 2, D Loss: 0.3467, G Loss: 2.3651, AE Loss: 0.4832\n",
            "Epoch 2, D Loss: 0.4874, G Loss: 2.6233, AE Loss: 0.5223\n",
            "Epoch 2, D Loss: 0.7275, G Loss: 2.2833, AE Loss: 0.5366\n",
            "Epoch 2, D Loss: 0.8605, G Loss: 2.6499, AE Loss: 0.5123\n",
            "Epoch 2, D Loss: 0.3975, G Loss: 2.5241, AE Loss: 0.5535\n",
            "Epoch 2, D Loss: 0.7541, G Loss: 2.3042, AE Loss: 0.6481\n",
            "Epoch 2, D Loss: 2.5758, G Loss: 2.5896, AE Loss: 0.4803\n",
            "Epoch 2, D Loss: 0.2887, G Loss: 2.3383, AE Loss: 0.4305\n",
            "Epoch 2, D Loss: 0.4116, G Loss: 2.2443, AE Loss: 0.5146\n",
            "Epoch 2, D Loss: 1.3661, G Loss: 2.3761, AE Loss: 0.6408\n",
            "Epoch 2, D Loss: 0.2696, G Loss: 2.3821, AE Loss: 0.4804\n",
            "Epoch 2, D Loss: 0.9763, G Loss: 2.5086, AE Loss: 0.6348\n",
            "Epoch 2, D Loss: 0.2976, G Loss: 2.4364, AE Loss: 0.5514\n",
            "Epoch 2, D Loss: 0.5508, G Loss: 2.3871, AE Loss: 0.5821\n",
            "Epoch 2, D Loss: 0.8008, G Loss: 2.4358, AE Loss: 0.5333\n",
            "Epoch 2, D Loss: 1.0265, G Loss: 2.4065, AE Loss: 0.5657\n",
            "Epoch 2, D Loss: 0.2888, G Loss: 2.5517, AE Loss: 0.4654\n",
            "Epoch 2, D Loss: 0.3765, G Loss: 2.5526, AE Loss: 0.5217\n",
            "Epoch 2, D Loss: 0.7971, G Loss: 2.2693, AE Loss: 0.4650\n",
            "Epoch 2, D Loss: 1.1522, G Loss: 2.3472, AE Loss: 0.5532\n",
            "Epoch 2, D Loss: 0.3363, G Loss: 2.0621, AE Loss: 0.6323\n",
            "Epoch 2, D Loss: 0.2294, G Loss: 2.2250, AE Loss: 0.5373\n",
            "Epoch 2, D Loss: 0.3546, G Loss: 2.3112, AE Loss: 0.5786\n",
            "Epoch 2, D Loss: 0.5917, G Loss: 2.3313, AE Loss: 0.5468\n",
            "Epoch 2, D Loss: 0.4627, G Loss: 2.3161, AE Loss: 0.5929\n",
            "Epoch 2, D Loss: 0.1859, G Loss: 2.5187, AE Loss: 0.4068\n",
            "Epoch 2, D Loss: 1.1754, G Loss: 2.3356, AE Loss: 0.4917\n",
            "Epoch 2, D Loss: 0.9576, G Loss: 2.8708, AE Loss: 0.5839\n",
            "Epoch 2, D Loss: 0.8993, G Loss: 2.5970, AE Loss: 0.6025\n",
            "Epoch 2, D Loss: 0.1526, G Loss: 2.4228, AE Loss: 0.5223\n",
            "Epoch 2, D Loss: 0.1491, G Loss: 2.5174, AE Loss: 0.5841\n",
            "Epoch 2, D Loss: 1.9910, G Loss: 2.8028, AE Loss: 0.5970\n",
            "Epoch 2, D Loss: 0.5612, G Loss: 2.4497, AE Loss: 0.5313\n",
            "Epoch 2, D Loss: 0.5742, G Loss: 2.4633, AE Loss: 0.5304\n",
            "Epoch 2, D Loss: 0.1887, G Loss: 2.8578, AE Loss: 0.6206\n",
            "Epoch 2, D Loss: 0.2252, G Loss: 2.9670, AE Loss: 0.4604\n",
            "Epoch 2, D Loss: 0.3748, G Loss: 2.4902, AE Loss: 0.4814\n",
            "Epoch 2, D Loss: 0.1176, G Loss: 2.7071, AE Loss: 0.5074\n",
            "Epoch 2, D Loss: 0.6527, G Loss: 2.7513, AE Loss: 0.4691\n",
            "Epoch 2, D Loss: 0.3593, G Loss: 2.9320, AE Loss: 0.4662\n",
            "Epoch 2, D Loss: 1.3049, G Loss: 2.5988, AE Loss: 0.6090\n",
            "Epoch 2, D Loss: 0.2543, G Loss: 2.7453, AE Loss: 0.6879\n",
            "Epoch 2, D Loss: 0.3067, G Loss: 3.1874, AE Loss: 0.4804\n",
            "Epoch 2, D Loss: 1.4646, G Loss: 2.8052, AE Loss: 0.6372\n",
            "Epoch 2, D Loss: 0.2053, G Loss: 2.5816, AE Loss: 0.4717\n",
            "Epoch 2, D Loss: 0.3975, G Loss: 3.0057, AE Loss: 0.4369\n",
            "Epoch 2, D Loss: 0.8723, G Loss: 2.4807, AE Loss: 0.7273\n",
            "Epoch 2, D Loss: 0.4431, G Loss: 2.3972, AE Loss: 0.5997\n",
            "Epoch 2, D Loss: 0.5506, G Loss: 2.5589, AE Loss: 0.5988\n",
            "Epoch 2, D Loss: 0.1511, G Loss: 2.5836, AE Loss: 0.7367\n",
            "Epoch 2, D Loss: 0.3807, G Loss: 2.4155, AE Loss: 0.4366\n",
            "Epoch 2, D Loss: 0.1479, G Loss: 2.7073, AE Loss: 0.5673\n",
            "Epoch 2, D Loss: 0.1848, G Loss: 2.6108, AE Loss: 0.4478\n",
            "Epoch 2, D Loss: 0.1939, G Loss: 2.2637, AE Loss: 0.5385\n",
            "Epoch 2, D Loss: 0.2855, G Loss: 2.4835, AE Loss: 0.5639\n",
            "Epoch 2, D Loss: 1.0007, G Loss: 2.6643, AE Loss: 0.3894\n",
            "Epoch 2, D Loss: 0.3346, G Loss: 2.3156, AE Loss: 0.5214\n",
            "Epoch 2, D Loss: 0.4246, G Loss: 2.5732, AE Loss: 0.4790\n",
            "Epoch 2, D Loss: 0.5583, G Loss: 2.2823, AE Loss: 0.5508\n",
            "Epoch 2, D Loss: 0.2258, G Loss: 2.6160, AE Loss: 0.5273\n",
            "Epoch 2, D Loss: 0.9995, G Loss: 2.6749, AE Loss: 0.4762\n",
            "Epoch 2, D Loss: 0.1370, G Loss: 2.7406, AE Loss: 0.5697\n",
            "Epoch 2, D Loss: 0.6933, G Loss: 2.3040, AE Loss: 0.6123\n",
            "Epoch 2, D Loss: 0.6062, G Loss: 2.7188, AE Loss: 0.6268\n",
            "Epoch 2, D Loss: 0.9815, G Loss: 2.5009, AE Loss: 0.4111\n",
            "Epoch 2, D Loss: 0.2753, G Loss: 2.9978, AE Loss: 0.5647\n",
            "Epoch 2, D Loss: 0.2191, G Loss: 2.6255, AE Loss: 0.5956\n",
            "Epoch 2, D Loss: 0.6323, G Loss: 2.3890, AE Loss: 0.6209\n",
            "Epoch 2, D Loss: 0.7456, G Loss: 2.5780, AE Loss: 0.6183\n",
            "Epoch 2, D Loss: 0.2489, G Loss: 2.5766, AE Loss: 0.4948\n",
            "Epoch 2, D Loss: 0.2268, G Loss: 2.9013, AE Loss: 0.5244\n",
            "Epoch 2, D Loss: 1.0011, G Loss: 3.3051, AE Loss: 0.4717\n",
            "Epoch 2, D Loss: 0.1406, G Loss: 3.0482, AE Loss: 0.5471\n",
            "Epoch 2, D Loss: 1.1358, G Loss: 2.5845, AE Loss: 0.5527\n",
            "Epoch 2, D Loss: 0.1942, G Loss: 2.8690, AE Loss: 0.6732\n",
            "Epoch 2, D Loss: 0.2292, G Loss: 2.5195, AE Loss: 0.6400\n",
            "Epoch 2, D Loss: 0.5105, G Loss: 2.3711, AE Loss: 0.4707\n",
            "Epoch 2, D Loss: 0.5297, G Loss: 2.6704, AE Loss: 0.4536\n",
            "Epoch 2, D Loss: 0.9658, G Loss: 1.8974, AE Loss: 0.5197\n",
            "Epoch 2, D Loss: 0.3977, G Loss: 2.2252, AE Loss: 0.7566\n",
            "Epoch 2, D Loss: 1.0081, G Loss: 2.6007, AE Loss: 0.4981\n",
            "Epoch 2, D Loss: 0.3587, G Loss: 2.6707, AE Loss: 0.6287\n",
            "Epoch 2, D Loss: 1.3419, G Loss: 2.7733, AE Loss: 0.5818\n",
            "Epoch 2, D Loss: 0.7734, G Loss: 1.9041, AE Loss: 0.7428\n",
            "Epoch 2, D Loss: 0.5608, G Loss: 2.1342, AE Loss: 0.7037\n",
            "Epoch 2, D Loss: 0.5601, G Loss: 3.1402, AE Loss: 0.5835\n",
            "Epoch 2, D Loss: 0.8654, G Loss: 2.8394, AE Loss: 0.4851\n",
            "Epoch 2, D Loss: 0.4564, G Loss: 3.0931, AE Loss: 0.5285\n",
            "Epoch 2, D Loss: 0.4617, G Loss: 3.4340, AE Loss: 0.4826\n",
            "Epoch 2, D Loss: 1.0684, G Loss: 2.4195, AE Loss: 0.7600\n",
            "Epoch 2, D Loss: 0.2014, G Loss: 3.0744, AE Loss: 0.6432\n",
            "Epoch 2, D Loss: 0.3155, G Loss: 2.7330, AE Loss: 0.5805\n",
            "Epoch 2, D Loss: 0.6868, G Loss: 2.6087, AE Loss: 0.6637\n",
            "Epoch 2, D Loss: 0.3015, G Loss: 2.7847, AE Loss: 0.4334\n",
            "Epoch 2, D Loss: 0.9426, G Loss: 2.8922, AE Loss: 0.7999\n",
            "Epoch 2, D Loss: 0.7318, G Loss: 2.7234, AE Loss: 0.4352\n",
            "Epoch 2, D Loss: 0.3709, G Loss: 2.9944, AE Loss: 0.8908\n",
            "Epoch 2, D Loss: 0.3357, G Loss: 2.7648, AE Loss: 0.7958\n",
            "Epoch 2, D Loss: 0.3805, G Loss: 2.7717, AE Loss: 0.5188\n",
            "Epoch 2, D Loss: 0.1300, G Loss: 2.7404, AE Loss: 0.5338\n",
            "Epoch 2, D Loss: 1.7973, G Loss: 2.7197, AE Loss: 0.5541\n",
            "Epoch 2, D Loss: 0.3191, G Loss: 3.1633, AE Loss: 0.5520\n",
            "Epoch 2, D Loss: 0.3166, G Loss: 3.0528, AE Loss: 0.7055\n",
            "Epoch 2, D Loss: 0.5370, G Loss: 3.3230, AE Loss: 0.4908\n",
            "Epoch 2, D Loss: 0.3554, G Loss: 3.1592, AE Loss: 0.5448\n",
            "Epoch 2, D Loss: 0.3313, G Loss: 3.2740, AE Loss: 0.3950\n",
            "Epoch 2, D Loss: 0.3181, G Loss: 3.3644, AE Loss: 0.5342\n",
            "Epoch 2, D Loss: 0.1768, G Loss: 2.6439, AE Loss: 0.7691\n",
            "Epoch 2, D Loss: 0.2112, G Loss: 2.5899, AE Loss: 0.5398\n",
            "Epoch 2, D Loss: 0.5984, G Loss: 2.9827, AE Loss: 0.4819\n",
            "Epoch 2, D Loss: 0.5796, G Loss: 2.8842, AE Loss: 0.5114\n",
            "Epoch 2, D Loss: 0.1493, G Loss: 2.6926, AE Loss: 0.5725\n",
            "Epoch 2, D Loss: 0.1451, G Loss: 3.1495, AE Loss: 0.6072\n",
            "Epoch 2, D Loss: 0.2058, G Loss: 2.3592, AE Loss: 0.6672\n",
            "Epoch 2, D Loss: 1.1483, G Loss: 2.7192, AE Loss: 0.5660\n",
            "Epoch 2, D Loss: 0.3177, G Loss: 2.6949, AE Loss: 0.4588\n",
            "Epoch 2, D Loss: 0.8656, G Loss: 2.7134, AE Loss: 0.6123\n",
            "Epoch 2, D Loss: 0.8329, G Loss: 2.9019, AE Loss: 0.6348\n",
            "Epoch 2, D Loss: 0.3649, G Loss: 2.5888, AE Loss: 0.5226\n",
            "Epoch 2, D Loss: 0.4147, G Loss: 2.5744, AE Loss: 0.6295\n",
            "Epoch 2, D Loss: 0.2304, G Loss: 3.0385, AE Loss: 0.4373\n",
            "Epoch 2, D Loss: 0.6537, G Loss: 2.7225, AE Loss: 0.5857\n",
            "Epoch 2, D Loss: 0.9689, G Loss: 3.2124, AE Loss: 0.5589\n",
            "Epoch 2, D Loss: 0.6583, G Loss: 2.3675, AE Loss: 0.6697\n",
            "Epoch 2, D Loss: 1.1623, G Loss: 2.5106, AE Loss: 0.5822\n",
            "Epoch 2, D Loss: 1.3381, G Loss: 2.4029, AE Loss: 0.6257\n",
            "Epoch 2, D Loss: 0.3351, G Loss: 2.6695, AE Loss: 0.6747\n",
            "Epoch 2, D Loss: 0.2093, G Loss: 2.6544, AE Loss: 0.5898\n",
            "Epoch 2, D Loss: 0.2055, G Loss: 2.6857, AE Loss: 0.5092\n",
            "Epoch 2, D Loss: 0.2514, G Loss: 2.6314, AE Loss: 0.5892\n",
            "Epoch 2, D Loss: 0.1228, G Loss: 2.6880, AE Loss: 0.4791\n",
            "Epoch 2, D Loss: 1.0289, G Loss: 2.7260, AE Loss: 0.5049\n",
            "Epoch 2, D Loss: 0.2906, G Loss: 2.6198, AE Loss: 0.6325\n",
            "Epoch 2, D Loss: 1.0874, G Loss: 2.7602, AE Loss: 0.5824\n",
            "Epoch 2, D Loss: 0.9657, G Loss: 2.6365, AE Loss: 0.6672\n",
            "Epoch 2, D Loss: 0.2288, G Loss: 2.2894, AE Loss: 0.4983\n",
            "Epoch 2, D Loss: 0.7646, G Loss: 2.4805, AE Loss: 0.5257\n",
            "Epoch 2, D Loss: 1.2315, G Loss: 2.5232, AE Loss: 0.5456\n",
            "Epoch 2, D Loss: 0.2146, G Loss: 2.3952, AE Loss: 0.5540\n",
            "Epoch 2, D Loss: 0.2250, G Loss: 2.7034, AE Loss: 0.4634\n",
            "Epoch 2, D Loss: 0.2245, G Loss: 2.4566, AE Loss: 0.6869\n",
            "Epoch 2, D Loss: 0.2429, G Loss: 2.1295, AE Loss: 0.5146\n",
            "Epoch 2, D Loss: 0.5254, G Loss: 2.8784, AE Loss: 0.5811\n",
            "Epoch 2, D Loss: 0.9994, G Loss: 2.2437, AE Loss: 0.5878\n",
            "Epoch 2, D Loss: 0.2673, G Loss: 2.5071, AE Loss: 0.5903\n",
            "Epoch 2, D Loss: 0.1652, G Loss: 2.4617, AE Loss: 0.7174\n",
            "Epoch 2, D Loss: 0.0966, G Loss: 2.8966, AE Loss: 0.4122\n",
            "Epoch 2, D Loss: 0.8668, G Loss: 2.3337, AE Loss: 0.7088\n",
            "Epoch 2, D Loss: 0.6613, G Loss: 2.1886, AE Loss: 0.6013\n",
            "Epoch 2, D Loss: 0.3098, G Loss: 2.6166, AE Loss: 0.6468\n",
            "Epoch 2, D Loss: 0.7958, G Loss: 2.3479, AE Loss: 0.5519\n",
            "Epoch 2, D Loss: 0.1539, G Loss: 2.5797, AE Loss: 0.6827\n",
            "Epoch 2, D Loss: 0.3500, G Loss: 2.5335, AE Loss: 0.5126\n",
            "Epoch 2, D Loss: 0.7552, G Loss: 2.9520, AE Loss: 0.5462\n",
            "Epoch 2, D Loss: 1.9472, G Loss: 2.5337, AE Loss: 0.6295\n",
            "Epoch 2, D Loss: 0.1435, G Loss: 2.5550, AE Loss: 0.5969\n",
            "Epoch 2, D Loss: 1.7789, G Loss: 2.5209, AE Loss: 0.5279\n",
            "Epoch 2, D Loss: 0.2112, G Loss: 2.5525, AE Loss: 0.6298\n",
            "Epoch 2, D Loss: 0.2052, G Loss: 2.4902, AE Loss: 0.4645\n",
            "Epoch 2, D Loss: 1.1577, G Loss: 2.2574, AE Loss: 0.5951\n",
            "Epoch 2, D Loss: 1.0296, G Loss: 2.5272, AE Loss: 0.5475\n",
            "Epoch 2, D Loss: 0.3007, G Loss: 2.1341, AE Loss: 0.5552\n",
            "Epoch 2, D Loss: 0.1815, G Loss: 2.2490, AE Loss: 0.4822\n",
            "Epoch 2, D Loss: 1.2498, G Loss: 2.0106, AE Loss: 0.5218\n",
            "Epoch 2, D Loss: 0.2316, G Loss: 2.3733, AE Loss: 0.5685\n",
            "Epoch 2, D Loss: 0.3275, G Loss: 2.1464, AE Loss: 0.6596\n",
            "Epoch 2, D Loss: 0.9964, G Loss: 2.1202, AE Loss: 0.5634\n",
            "Epoch 2, D Loss: 0.3310, G Loss: 2.0033, AE Loss: 0.6208\n",
            "Epoch 2, D Loss: 0.6852, G Loss: 2.0857, AE Loss: 0.4684\n",
            "Epoch 2, D Loss: 0.4761, G Loss: 1.8587, AE Loss: 0.4542\n",
            "Epoch 2, D Loss: 0.2631, G Loss: 2.0167, AE Loss: 0.9494\n",
            "Epoch 2, D Loss: 0.5284, G Loss: 1.8460, AE Loss: 0.6618\n",
            "Epoch 2, D Loss: 1.0568, G Loss: 1.7880, AE Loss: 0.4367\n",
            "Epoch 2, D Loss: 0.7039, G Loss: 1.5938, AE Loss: 0.5168\n",
            "Epoch 2, D Loss: 0.5603, G Loss: 1.7124, AE Loss: 0.5727\n",
            "Epoch 2, D Loss: 0.6630, G Loss: 1.4598, AE Loss: 0.6356\n",
            "Epoch 2, D Loss: 0.6063, G Loss: 1.2640, AE Loss: 0.5924\n",
            "Epoch 2, D Loss: 0.7430, G Loss: 1.2175, AE Loss: 0.7033\n",
            "Epoch 2, D Loss: 0.5745, G Loss: 1.1973, AE Loss: 0.5924\n",
            "Epoch 2, D Loss: 0.6166, G Loss: 1.6304, AE Loss: 0.5564\n",
            "Epoch 2, D Loss: 0.6397, G Loss: 1.3648, AE Loss: 0.5045\n",
            "Epoch 2, D Loss: 1.8320, G Loss: 1.5621, AE Loss: 0.5828\n",
            "Epoch 2, D Loss: 0.9342, G Loss: 1.2025, AE Loss: 0.5084\n",
            "Epoch 2, D Loss: 0.5700, G Loss: 1.0674, AE Loss: 0.4496\n",
            "Epoch 2, D Loss: 0.6826, G Loss: 1.1458, AE Loss: 0.6512\n",
            "Epoch 2, D Loss: 1.8643, G Loss: 1.1115, AE Loss: 0.5594\n",
            "Epoch 2, D Loss: 0.8181, G Loss: 1.1989, AE Loss: 0.4789\n",
            "Epoch 2, D Loss: 0.7951, G Loss: 0.8238, AE Loss: 0.6104\n",
            "Epoch 2, D Loss: 1.4432, G Loss: 0.9308, AE Loss: 0.5884\n",
            "Epoch 2, D Loss: 0.6441, G Loss: 1.0875, AE Loss: 0.5449\n",
            "Epoch 2, D Loss: 1.3428, G Loss: 0.5212, AE Loss: 0.4805\n",
            "Epoch 2, D Loss: 0.5291, G Loss: 1.3012, AE Loss: 0.5933\n",
            "Epoch 2, D Loss: 0.9569, G Loss: 0.8150, AE Loss: 0.5445\n",
            "Epoch 2, D Loss: 0.8663, G Loss: 1.0139, AE Loss: 0.4684\n",
            "Epoch 2, D Loss: 1.0257, G Loss: 0.9271, AE Loss: 0.5387\n",
            "Epoch 2, D Loss: 0.8081, G Loss: 1.0499, AE Loss: 0.6063\n",
            "Epoch 2, D Loss: 1.2402, G Loss: 0.7571, AE Loss: 0.5816\n",
            "Epoch 2, D Loss: 1.0586, G Loss: 0.6855, AE Loss: 0.5815\n",
            "Epoch 2, D Loss: 2.1769, G Loss: 0.9180, AE Loss: 0.6123\n",
            "Epoch 2, D Loss: 1.4070, G Loss: 1.2728, AE Loss: 0.6140\n",
            "Epoch 2, D Loss: 0.9537, G Loss: 0.8315, AE Loss: 0.3526\n",
            "Epoch 2, D Loss: 1.7179, G Loss: 0.8464, AE Loss: 0.5613\n",
            "Epoch 2, D Loss: 0.8315, G Loss: 1.0166, AE Loss: 0.4940\n",
            "Epoch 2, D Loss: 1.2746, G Loss: 0.7733, AE Loss: 0.5970\n",
            "Epoch 2, D Loss: 0.9830, G Loss: 0.9261, AE Loss: 0.6042\n",
            "Epoch 2, D Loss: 1.4385, G Loss: 0.5784, AE Loss: 0.5261\n",
            "Epoch 2, D Loss: 0.9856, G Loss: 0.8705, AE Loss: 0.5852\n",
            "Epoch 2, D Loss: 1.8566, G Loss: 0.8070, AE Loss: 0.5910\n",
            "Epoch 2, D Loss: 0.9921, G Loss: 0.7166, AE Loss: 0.5634\n",
            "Epoch 2, D Loss: 2.6480, G Loss: 0.5233, AE Loss: 0.5509\n",
            "Epoch 2, D Loss: 0.8484, G Loss: 0.7636, AE Loss: 0.5352\n",
            "Epoch 2, D Loss: 0.9306, G Loss: 0.7663, AE Loss: 0.5794\n",
            "Epoch 2, D Loss: 1.1577, G Loss: 0.7960, AE Loss: 0.4717\n",
            "Epoch 2, D Loss: 1.1759, G Loss: 0.9110, AE Loss: 0.5709\n",
            "Epoch 2, D Loss: 0.8301, G Loss: 0.7329, AE Loss: 0.5173\n",
            "Epoch 2, D Loss: 0.9315, G Loss: 0.8008, AE Loss: 0.5440\n",
            "Epoch 2, D Loss: 0.8370, G Loss: 0.8821, AE Loss: 0.6327\n",
            "Epoch 2, D Loss: 1.2677, G Loss: 1.0287, AE Loss: 0.6102\n",
            "Epoch 2, D Loss: 0.7829, G Loss: 1.0213, AE Loss: 0.6412\n",
            "Epoch 2, D Loss: 0.8542, G Loss: 1.0795, AE Loss: 0.6191\n",
            "Epoch 2, D Loss: 1.8886, G Loss: 1.1587, AE Loss: 0.4985\n",
            "Epoch 2, D Loss: 0.7562, G Loss: 1.1350, AE Loss: 0.5544\n",
            "Epoch 2, D Loss: 1.6085, G Loss: 1.2776, AE Loss: 0.5035\n",
            "Epoch 2, D Loss: 0.8602, G Loss: 1.2470, AE Loss: 0.5357\n",
            "Epoch 2, D Loss: 0.4651, G Loss: 1.2627, AE Loss: 0.5312\n",
            "Epoch 2, D Loss: 0.5601, G Loss: 1.2281, AE Loss: 0.4314\n",
            "Epoch 2, D Loss: 1.2092, G Loss: 1.2493, AE Loss: 0.4705\n",
            "Epoch 2, D Loss: 1.1720, G Loss: 1.3603, AE Loss: 0.5957\n",
            "Epoch 2, D Loss: 0.6539, G Loss: 1.3132, AE Loss: 0.5033\n",
            "Epoch 2, D Loss: 0.7749, G Loss: 1.3697, AE Loss: 0.5643\n",
            "Epoch 2, D Loss: 0.4566, G Loss: 1.3744, AE Loss: 0.6997\n",
            "Epoch 2, D Loss: 1.1634, G Loss: 1.3428, AE Loss: 0.6236\n",
            "Epoch 2, D Loss: 0.3863, G Loss: 1.4789, AE Loss: 0.5210\n",
            "Epoch 2, D Loss: 0.3881, G Loss: 1.4457, AE Loss: 0.9237\n",
            "Epoch 2, D Loss: 0.4167, G Loss: 1.4192, AE Loss: 0.6801\n",
            "Epoch 2, D Loss: 1.0215, G Loss: 1.5863, AE Loss: 0.5796\n",
            "Epoch 2, D Loss: 0.7576, G Loss: 1.5730, AE Loss: 0.5961\n",
            "Epoch 2, D Loss: 0.5473, G Loss: 1.5330, AE Loss: 0.5106\n",
            "Epoch 2, D Loss: 0.4685, G Loss: 1.4376, AE Loss: 0.6350\n",
            "Epoch 2, D Loss: 1.4244, G Loss: 1.4396, AE Loss: 0.4817\n",
            "Epoch 2, D Loss: 1.1409, G Loss: 1.5863, AE Loss: 0.5234\n",
            "Epoch 2, D Loss: 0.4393, G Loss: 1.5950, AE Loss: 0.5524\n",
            "Epoch 2, D Loss: 1.6239, G Loss: 1.6340, AE Loss: 0.5442\n",
            "Epoch 2, D Loss: 2.0615, G Loss: 1.5008, AE Loss: 0.4612\n",
            "Epoch 2, D Loss: 0.3835, G Loss: 1.4688, AE Loss: 0.5524\n",
            "Epoch 2, D Loss: 0.7327, G Loss: 1.4381, AE Loss: 0.4822\n",
            "Epoch 2, D Loss: 0.2710, G Loss: 1.5417, AE Loss: 0.5416\n",
            "Epoch 2, D Loss: 2.1074, G Loss: 1.4580, AE Loss: 0.5233\n",
            "Epoch 2, D Loss: 1.8433, G Loss: 1.3630, AE Loss: 0.5086\n",
            "Epoch 2, D Loss: 0.3810, G Loss: 1.3217, AE Loss: 0.5302\n",
            "Epoch 2, D Loss: 0.4337, G Loss: 1.3696, AE Loss: 0.5039\n",
            "Epoch 2, D Loss: 0.5649, G Loss: 1.4608, AE Loss: 0.5944\n",
            "Epoch 2, D Loss: 1.4307, G Loss: 1.4765, AE Loss: 0.5031\n",
            "Epoch 2, D Loss: 1.3432, G Loss: 1.4359, AE Loss: 0.5200\n",
            "Epoch 2, D Loss: 0.7849, G Loss: 1.4881, AE Loss: 0.6360\n",
            "Epoch 2, D Loss: 0.7415, G Loss: 1.4057, AE Loss: 0.5587\n",
            "Epoch 2, D Loss: 0.4924, G Loss: 1.4959, AE Loss: 0.4907\n",
            "Epoch 2, D Loss: 0.9768, G Loss: 1.4592, AE Loss: 0.4568\n",
            "Epoch 2, D Loss: 0.6399, G Loss: 1.4517, AE Loss: 0.5670\n",
            "Epoch 2, D Loss: 0.4710, G Loss: 1.2210, AE Loss: 0.6089\n",
            "Epoch 2, D Loss: 0.5127, G Loss: 1.4106, AE Loss: 0.5927\n",
            "Epoch 2, D Loss: 0.6620, G Loss: 1.3598, AE Loss: 0.4928\n",
            "Epoch 2, D Loss: 0.7284, G Loss: 1.4069, AE Loss: 0.5159\n",
            "Epoch 2, D Loss: 0.6063, G Loss: 1.4761, AE Loss: 0.4999\n",
            "Epoch 2, D Loss: 0.5858, G Loss: 1.2275, AE Loss: 0.5986\n",
            "Epoch 2, D Loss: 1.0716, G Loss: 1.3058, AE Loss: 0.4495\n",
            "Epoch 2, D Loss: 0.7551, G Loss: 1.3642, AE Loss: 0.7524\n",
            "Epoch 2, D Loss: 1.2293, G Loss: 1.3774, AE Loss: 0.5245\n",
            "Epoch 2, D Loss: 0.4702, G Loss: 1.2587, AE Loss: 0.5975\n",
            "Epoch 2, D Loss: 1.1439, G Loss: 1.2605, AE Loss: 0.5487\n",
            "Epoch 2, D Loss: 0.4095, G Loss: 1.3726, AE Loss: 0.5864\n",
            "Epoch 2, D Loss: 0.4691, G Loss: 1.2802, AE Loss: 0.6564\n",
            "Epoch 2, D Loss: 0.8474, G Loss: 1.4042, AE Loss: 0.5055\n",
            "Epoch 2, D Loss: 0.3534, G Loss: 1.3364, AE Loss: 0.4533\n",
            "Epoch 2, D Loss: 0.6833, G Loss: 1.2879, AE Loss: 0.5500\n",
            "Epoch 2, D Loss: 0.4790, G Loss: 1.4310, AE Loss: 0.5629\n",
            "Epoch 2, D Loss: 0.5579, G Loss: 1.2694, AE Loss: 0.6278\n",
            "Epoch 2, D Loss: 0.9571, G Loss: 1.3388, AE Loss: 0.4466\n",
            "Epoch 2, D Loss: 0.7790, G Loss: 1.2844, AE Loss: 0.4855\n",
            "Epoch 2, D Loss: 0.4381, G Loss: 1.2777, AE Loss: 0.5235\n",
            "Epoch 2, D Loss: 0.6138, G Loss: 1.3662, AE Loss: 0.5036\n",
            "Epoch 2, D Loss: 1.2592, G Loss: 1.3328, AE Loss: 0.5607\n",
            "Epoch 2, D Loss: 1.1592, G Loss: 1.1854, AE Loss: 0.5594\n",
            "Epoch 2, D Loss: 0.4709, G Loss: 1.2665, AE Loss: 0.6771\n",
            "Epoch 2, D Loss: 0.4131, G Loss: 1.2115, AE Loss: 0.5540\n",
            "Epoch 2, D Loss: 0.6844, G Loss: 1.2592, AE Loss: 0.5797\n",
            "Epoch 2, D Loss: 0.6449, G Loss: 1.1946, AE Loss: 0.5738\n",
            "Epoch 2, D Loss: 1.4304, G Loss: 1.2752, AE Loss: 0.4461\n",
            "Epoch 2, D Loss: 0.7038, G Loss: 1.1681, AE Loss: 0.5160\n",
            "Epoch 2, D Loss: 0.5715, G Loss: 1.2407, AE Loss: 0.4816\n",
            "Epoch 2, D Loss: 0.6432, G Loss: 1.2294, AE Loss: 0.5236\n",
            "Epoch 2, D Loss: 1.0729, G Loss: 1.2746, AE Loss: 0.5577\n",
            "Epoch 2, D Loss: 0.8568, G Loss: 1.2340, AE Loss: 0.5170\n",
            "Epoch 2, D Loss: 0.5132, G Loss: 1.3868, AE Loss: 0.5909\n",
            "Epoch 2, D Loss: 0.7107, G Loss: 1.3646, AE Loss: 0.4105\n",
            "Epoch 2, D Loss: 0.5099, G Loss: 1.3150, AE Loss: 0.5059\n",
            "Epoch 2, D Loss: 0.5096, G Loss: 1.3408, AE Loss: 0.5978\n",
            "Epoch 2, D Loss: 0.7663, G Loss: 1.4219, AE Loss: 0.5795\n",
            "Epoch 2, D Loss: 0.8707, G Loss: 1.4306, AE Loss: 0.4845\n",
            "Epoch 2, D Loss: 0.5216, G Loss: 1.5259, AE Loss: 0.5134\n",
            "Epoch 2, D Loss: 0.7648, G Loss: 1.6656, AE Loss: 0.5169\n",
            "Epoch 2, D Loss: 0.4806, G Loss: 1.5352, AE Loss: 0.6582\n",
            "Epoch 2, D Loss: 1.0650, G Loss: 1.5969, AE Loss: 0.5592\n",
            "Epoch 2, D Loss: 0.2875, G Loss: 1.7717, AE Loss: 0.6147\n",
            "Epoch 2, D Loss: 0.4238, G Loss: 1.6645, AE Loss: 0.4859\n",
            "Epoch 2, D Loss: 1.0356, G Loss: 1.7390, AE Loss: 0.5308\n",
            "Epoch 2, D Loss: 0.2939, G Loss: 1.7582, AE Loss: 0.4535\n",
            "Epoch 2, D Loss: 0.6820, G Loss: 1.7414, AE Loss: 0.5180\n",
            "Epoch 2, D Loss: 0.6642, G Loss: 1.7425, AE Loss: 0.5824\n",
            "Epoch 2, D Loss: 0.6055, G Loss: 1.6528, AE Loss: 0.6310\n",
            "Epoch 2, D Loss: 0.3132, G Loss: 1.7633, AE Loss: 0.5229\n",
            "Epoch 2, D Loss: 0.6991, G Loss: 1.7037, AE Loss: 0.6300\n",
            "Epoch 2, D Loss: 0.8043, G Loss: 1.7176, AE Loss: 0.5659\n",
            "Epoch 2, D Loss: 0.4837, G Loss: 1.6614, AE Loss: 0.5199\n",
            "Epoch 2, D Loss: 0.9043, G Loss: 1.6439, AE Loss: 0.6754\n",
            "Epoch 2, D Loss: 0.3818, G Loss: 1.6354, AE Loss: 0.5538\n",
            "Epoch 2, D Loss: 0.3777, G Loss: 1.5502, AE Loss: 0.5989\n",
            "Epoch 2, D Loss: 0.9146, G Loss: 1.6351, AE Loss: 0.4834\n",
            "Epoch 2, D Loss: 0.3318, G Loss: 1.6629, AE Loss: 0.6274\n",
            "Epoch 2, D Loss: 0.7870, G Loss: 1.5924, AE Loss: 0.5846\n",
            "Epoch 2, D Loss: 0.7133, G Loss: 1.6018, AE Loss: 0.6521\n",
            "Epoch 2, D Loss: 0.9685, G Loss: 1.4457, AE Loss: 0.4855\n",
            "Epoch 2, D Loss: 1.0312, G Loss: 1.5211, AE Loss: 0.6021\n",
            "Epoch 2, D Loss: 0.9604, G Loss: 1.5685, AE Loss: 0.5091\n",
            "Epoch 2, D Loss: 1.3239, G Loss: 1.4432, AE Loss: 0.5166\n",
            "Epoch 2, D Loss: 0.6037, G Loss: 1.3957, AE Loss: 0.6051\n",
            "Epoch 2, D Loss: 0.6423, G Loss: 1.4674, AE Loss: 0.5359\n",
            "Epoch 2, D Loss: 0.7864, G Loss: 1.4920, AE Loss: 0.4467\n",
            "Epoch 2, D Loss: 0.8144, G Loss: 1.4939, AE Loss: 0.5497\n",
            "Epoch 2, D Loss: 0.3787, G Loss: 1.4186, AE Loss: 0.4963\n",
            "Epoch 2, D Loss: 0.3789, G Loss: 1.4261, AE Loss: 0.5329\n",
            "Epoch 2, D Loss: 0.5036, G Loss: 1.3190, AE Loss: 0.5502\n",
            "Epoch 2, D Loss: 0.5791, G Loss: 1.3830, AE Loss: 0.6203\n",
            "Epoch 2, D Loss: 0.6276, G Loss: 1.3141, AE Loss: 0.5003\n",
            "Epoch 2, D Loss: 0.7547, G Loss: 1.5185, AE Loss: 0.5363\n",
            "Epoch 2, D Loss: 0.5074, G Loss: 1.4935, AE Loss: 0.5647\n",
            "Epoch 2, D Loss: 0.6149, G Loss: 1.4389, AE Loss: 0.4395\n",
            "Epoch 2, D Loss: 0.4813, G Loss: 1.4684, AE Loss: 0.5520\n",
            "Epoch 2, D Loss: 0.5119, G Loss: 1.4789, AE Loss: 0.4777\n",
            "Epoch 2, D Loss: 0.3978, G Loss: 1.4404, AE Loss: 0.5416\n",
            "Epoch 2, D Loss: 0.5050, G Loss: 1.5118, AE Loss: 0.5980\n",
            "Epoch 2, D Loss: 0.7686, G Loss: 1.4940, AE Loss: 0.6044\n",
            "Epoch 2, D Loss: 0.5552, G Loss: 1.5122, AE Loss: 0.5246\n",
            "Epoch 2, D Loss: 0.2797, G Loss: 1.5541, AE Loss: 0.5036\n",
            "Epoch 2, D Loss: 0.3353, G Loss: 1.6395, AE Loss: 0.4900\n",
            "Epoch 2, D Loss: 0.2475, G Loss: 1.6607, AE Loss: 0.5789\n",
            "Epoch 2, D Loss: 0.5677, G Loss: 1.6157, AE Loss: 0.5420\n",
            "Epoch 2, D Loss: 0.6869, G Loss: 1.6917, AE Loss: 0.5133\n",
            "Epoch 2, D Loss: 0.4421, G Loss: 1.6079, AE Loss: 0.5477\n",
            "Epoch 2, D Loss: 0.5695, G Loss: 1.6502, AE Loss: 0.7118\n",
            "Epoch 2, D Loss: 0.6655, G Loss: 1.6019, AE Loss: 0.5563\n",
            "Epoch 2, D Loss: 0.3358, G Loss: 1.6959, AE Loss: 0.5472\n",
            "Epoch 2, D Loss: 0.4922, G Loss: 1.6864, AE Loss: 0.4292\n",
            "Epoch 2, D Loss: 0.5771, G Loss: 1.5177, AE Loss: 0.4919\n",
            "Epoch 2, D Loss: 0.2583, G Loss: 1.6306, AE Loss: 0.6217\n",
            "Epoch 2, D Loss: 0.9362, G Loss: 1.6399, AE Loss: 0.5959\n",
            "Epoch 2, D Loss: 0.3778, G Loss: 1.6915, AE Loss: 0.6444\n",
            "Epoch 2, D Loss: 0.4350, G Loss: 1.6779, AE Loss: 0.6173\n",
            "Epoch 2, D Loss: 0.7974, G Loss: 1.7125, AE Loss: 0.4903\n",
            "Epoch 2, D Loss: 0.5538, G Loss: 1.6461, AE Loss: 0.5803\n",
            "Epoch 2, D Loss: 0.3265, G Loss: 1.6593, AE Loss: 0.4580\n",
            "Epoch 2, D Loss: 0.4294, G Loss: 1.6145, AE Loss: 0.6229\n",
            "Epoch 2, D Loss: 0.6448, G Loss: 1.7179, AE Loss: 0.5071\n",
            "Epoch 2, D Loss: 0.3572, G Loss: 1.7005, AE Loss: 0.5856\n",
            "Epoch 2, D Loss: 0.9187, G Loss: 1.7589, AE Loss: 0.4967\n",
            "Epoch 2, D Loss: 0.7193, G Loss: 1.6266, AE Loss: 0.5239\n",
            "Epoch 2, D Loss: 0.7366, G Loss: 1.6022, AE Loss: 0.5505\n",
            "Epoch 2, D Loss: 0.4810, G Loss: 1.6099, AE Loss: 0.4869\n",
            "Epoch 2, D Loss: 1.1939, G Loss: 1.6621, AE Loss: 0.5267\n",
            "Epoch 2, D Loss: 0.3041, G Loss: 1.6230, AE Loss: 0.4607\n",
            "Epoch 2, D Loss: 0.6884, G Loss: 1.6091, AE Loss: 0.4692\n",
            "Epoch 2, D Loss: 0.7514, G Loss: 1.4137, AE Loss: 0.5684\n",
            "Epoch 2, D Loss: 0.4219, G Loss: 1.5274, AE Loss: 0.4571\n",
            "Epoch 2, D Loss: 0.7763, G Loss: 1.5462, AE Loss: 0.5205\n",
            "Epoch 2, D Loss: 0.6363, G Loss: 1.4982, AE Loss: 0.4675\n",
            "Epoch 2, D Loss: 0.7230, G Loss: 1.4724, AE Loss: 0.5795\n",
            "Epoch 2, D Loss: 0.7271, G Loss: 1.4353, AE Loss: 0.6518\n",
            "Epoch 2, D Loss: 1.0518, G Loss: 1.4927, AE Loss: 0.6204\n",
            "Epoch 2, D Loss: 1.2326, G Loss: 1.4355, AE Loss: 0.5981\n",
            "Epoch 2, D Loss: 0.5470, G Loss: 1.6546, AE Loss: 0.5149\n",
            "Epoch 2, D Loss: 0.8668, G Loss: 1.5321, AE Loss: 0.4095\n",
            "Epoch 2, D Loss: 0.8146, G Loss: 1.4318, AE Loss: 0.6003\n",
            "Epoch 2, D Loss: 0.8269, G Loss: 1.4881, AE Loss: 0.5955\n",
            "Epoch 2, D Loss: 0.3654, G Loss: 1.5771, AE Loss: 0.4794\n",
            "Epoch 2, D Loss: 0.8549, G Loss: 1.5844, AE Loss: 0.4373\n",
            "Epoch 2, D Loss: 0.3681, G Loss: 1.5128, AE Loss: 0.5981\n",
            "Epoch 2, D Loss: 0.6044, G Loss: 1.6093, AE Loss: 0.4621\n",
            "Epoch 2, D Loss: 0.7471, G Loss: 1.7830, AE Loss: 0.5273\n",
            "Epoch 2, D Loss: 1.1388, G Loss: 1.5620, AE Loss: 0.4376\n",
            "Epoch 2, D Loss: 0.6529, G Loss: 1.6366, AE Loss: 0.5036\n",
            "Epoch 2, D Loss: 0.7076, G Loss: 1.6669, AE Loss: 0.5068\n",
            "Epoch 2, D Loss: 0.5015, G Loss: 1.4886, AE Loss: 0.6516\n",
            "Epoch 2, D Loss: 0.9954, G Loss: 1.6111, AE Loss: 0.5403\n",
            "Epoch 2, D Loss: 0.5741, G Loss: 1.5789, AE Loss: 0.5359\n",
            "Epoch 2, D Loss: 0.7082, G Loss: 1.7155, AE Loss: 0.4856\n",
            "Epoch 2, D Loss: 0.3935, G Loss: 1.7208, AE Loss: 0.5547\n",
            "Epoch 2, D Loss: 0.6379, G Loss: 1.6378, AE Loss: 0.5432\n",
            "Epoch 2, D Loss: 1.1746, G Loss: 1.7094, AE Loss: 0.5870\n"
          ]
        }
      ]
    }
  ]
}